```python
!python3 -m pip install --upgrade pip
```

    Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.0)
    [33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv[0m[33m
    [0m


```python
# !pip install openai==1.2.3
!pip install openai==1.3.4
!pip3 install arxiv==2.1.0
!pip install -U duckduckgo-search==4.4

!pip install python-dotenv tiktoken
!pip install pdfplumber
```

    Requirement already satisfied: openai==1.3.4 in /usr/local/lib/python3.10/dist-packages (1.3.4)
    Requirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.3.4) (3.7.1)
    Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.3.4) (1.7.0)
    Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.3.4) (0.27.0)
    Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.3.4) (1.10.13)
    Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.3.4) (4.66.1)
    Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai==1.3.4) (4.9.0)
    Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai==1.3.4) (3.4)
    Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai==1.3.4) (1.3.0)
    Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai==1.3.4) (1.2.0)
    Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.3.4) (2022.12.7)
    Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.3.4) (1.0.4)
    Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.3.4) (0.14.0)
    [33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv[0m[33m
    [0mRequirement already satisfied: arxiv==2.1.0 in /usr/local/lib/python3.10/dist-packages (2.1.0)
    Requirement already satisfied: feedparser==6.0.10 in /usr/local/lib/python3.10/dist-packages (from arxiv==2.1.0) (6.0.10)
    Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (from arxiv==2.1.0) (2.31.0)
    Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.10/dist-packages (from feedparser==6.0.10->arxiv==2.1.0) (1.0.0)
    Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->arxiv==2.1.0) (2.1.1)
    Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->arxiv==2.1.0) (3.4)
    Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->arxiv==2.1.0) (1.26.13)
    Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->arxiv==2.1.0) (2022.12.7)
    [33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv[0m[33m
    [0mRequirement already satisfied: duckduckgo-search==4.4 in /usr/local/lib/python3.10/dist-packages (4.4)
    Requirement already satisfied: docstring-inheritance>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search==4.4) (2.2.0)
    Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search==4.4) (8.1.7)
    Requirement already satisfied: curl-cffi>=0.6.0b7 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search==4.4) (0.6.3b1)
    Requirement already satisfied: lxml>=4.9.3 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search==4.4) (4.9.4)
    Requirement already satisfied: nest-asyncio>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search==4.4) (1.6.0)
    Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from curl-cffi>=0.6.0b7->duckduckgo-search==4.4) (1.16.0)
    Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from curl-cffi>=0.6.0b7->duckduckgo-search==4.4) (2022.12.7)
    Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12.0->curl-cffi>=0.6.0b7->duckduckgo-search==4.4) (2.21)
    [33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv[0m[33m
    [0mRequirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)
    Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.6.0)
    Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)
    Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)
    Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.1.1)
    Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)
    Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (1.26.13)
    Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2022.12.7)
    [33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv[0m[33m
    [0mRequirement already satisfied: pdfplumber in /usr/local/lib/python3.10/dist-packages (0.11.0)
    Requirement already satisfied: pdfminer.six==20231228 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (20231228)
    Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (9.3.0)
    Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (4.28.0)
    Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (2.1.1)
    Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (41.0.7)
    Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.16.0)
    Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.21)
    [33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv[0m[33m
    [0m


```python
from time import time

class Timer:
    def __init__(self, logger=None, format_str="{:.3f}[s]", prefix=None, suffix=None, sep=" "):

        if prefix: format_str = str(prefix) + sep + format_str
        if suffix: format_str = format_str + sep + str(suffix)
        self.format_str = format_str
        self.logger = logger
        self.start = None
        self.end = None

    @property
    def duration(self):
        if self.end is None:
            return 0
        return self.end - self.start

    def __enter__(self):
        self.start = time()

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.end = time()
        out_str = self.format_str.format(self.duration)
        if self.logger:
            self.logger.info(out_str)
        else:
            print(out_str)
```


```python
from contextlib import contextmanager
from time import time

class Timer:
    """å‡¦ç†æ™‚é–“ã‚’è¡¨ç¤ºã™ã‚‹ã‚¯ãƒ©ã‚¹
    with Timer(prefix=f'pred cv={i}'):
        y_pred_i = predict(model, loader=test_loader)
    
    with Timer(prefix='fit fold={} '.format(i)):
        clf.fit(x_train, y_train, 
                eval_set=[(x_valid, y_valid)],  
                early_stopping_rounds=100,
                verbose=verbose)

    with Timer(prefix='fit fold={} '.format(i), verbose=500):
        clf.fit(x_train, y_train, 
                eval_set=[(x_valid, y_valid)],  
                early_stopping_rounds=100,
                verbose=verbose)
    """
    def __init__(self, logger=None, format_str='{:.3f}[s]', prefix=None, suffix=None, sep=' ', verbose=0):

        if prefix: format_str = str(prefix) + sep + format_str
        if suffix: format_str = format_str + sep + str(suffix)
        self.format_str = format_str
        self.logger = logger
        self.start = None
        self.end = None
        self.verbose = verbose

    @property
    def duration(self):
        if self.end is None:
            return 0
        return self.end - self.start

    def __enter__(self):
        self.start = time()

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.end = time()
        out_str = self.format_str.format(self.duration)
        if self.logger:
            self.logger.info(out_str)
        else:
            print(out_str)
```


```python
import openai
import pdfplumber
from openai import OpenAI
import tiktoken
from dotenv import load_dotenv
import os
import json
import arxiv
import datetime as dt

load_dotenv()
```




    True




```python
# MODEL_NAME = "gpt-3.5-turbo-0125"
# MODEL_NAME = "gpt-3.5-turbo-instruct"
MODEL_NAME = "gpt-4-0125-preview"
TEMPERATURE = 0.7
# OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
client = OpenAI()
```


```python

def generate_research_questions_and_purpose_with_gpt(objective, num_questions, client):
    # ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ: ç ”ç©¶ç›®çš„ã‹ã‚‰ç ”ç©¶è³ªå•ã¨æ¤œç´¢æ–‡å­—åˆ—ã‚’ç”Ÿæˆã—ã¾ã™
    # Construct the prompt dynamically
    prompt_content = f"You are a helpful assistant capable of generating research questions along with their purposes for a systematic literature review.\n"
    prompt_content = f"Given the research objective: '{objective}', generate {num_questions} distinct research questions, each followed by its specific purpose. 'To examine', or 'To investigate'."
    
    response = client.chat.completions.create(
        # model="gpt-3.5-turbo",
        model="gpt-3.5-turbo-0125",
        messages=[
            {"role": "system", "content": "You are a helpful assistant capable of generating research questions along with their purposes for a systematic literature review."},
            {"role": "user", "content": prompt_content}
        ],
        # response_format={ "type": "json_object" },
        temperature=TEMPERATURE,
    )
    result = response.choices[0].message.content
    return {"research_questions": result}

```


```python
objective = "RAG Evaluation Methods"
# objective = "RAGæ¤œè¨¼æ–¹æ³•"

num_questions = 5
```


```python
questions_and_purposes = generate_research_questions_and_purpose_with_gpt(objective, num_questions, client)
print(questions_and_purposes)
```

    {'research_questions': 'Research Question 1: What are the existing methods for evaluating RAG (Red, Amber, Green) status in project management?\nPurpose: To examine the different evaluation techniques and approaches used to assess RAG status in project management and identify their strengths and limitations.\n\nResearch Question 2: How do different industries utilize RAG evaluation methods in project management?\nPurpose: To investigate the application of RAG evaluation methods across various industries and determine any sector-specific adaptations or best practices.\n\nResearch Question 3: What are the key factors influencing the accuracy and reliability of RAG evaluations in project management?\nPurpose: To examine the factors that impact the precision and dependability of RAG assessments in project management and suggest potential strategies for improvement.\n\nResearch Question 4: How do stakeholders perceive the effectiveness of RAG evaluation methods in project management?\nPurpose: To investigate the perspectives and feedback of project stakeholders on the utility and efficacy of RAG evaluation methods to enhance project monitoring and decision-making processes.\n\nResearch Question 5: What are the emerging trends and advancements in RAG evaluation methods for project management?\nPurpose: To explore the latest developments and innovations in RAG evaluation techniques and tools within project management practices and identify potential areas for future research and application.'}



```python
print(questions_and_purposes['research_questions'])
```

    Research Question 1: What are the existing methods for evaluating RAG (Red, Amber, Green) status in project management?
    Purpose: To examine the different evaluation techniques and approaches used to assess RAG status in project management and identify their strengths and limitations.
    
    Research Question 2: How do different industries utilize RAG evaluation methods in project management?
    Purpose: To investigate the application of RAG evaluation methods across various industries and determine any sector-specific adaptations or best practices.
    
    Research Question 3: What are the key factors influencing the accuracy and reliability of RAG evaluations in project management?
    Purpose: To examine the factors that impact the precision and dependability of RAG assessments in project management and suggest potential strategies for improvement.
    
    Research Question 4: How do stakeholders perceive the effectiveness of RAG evaluation methods in project management?
    Purpose: To investigate the perspectives and feedback of project stakeholders on the utility and efficacy of RAG evaluation methods to enhance project monitoring and decision-making processes.
    
    Research Question 5: What are the emerging trends and advancements in RAG evaluation methods for project management?
    Purpose: To explore the latest developments and innovations in RAG evaluation techniques and tools within project management practices and identify potential areas for future research and application.



```python
def extract_search_strings(content):
    possible_operators = ['AND', 'OR', 'NOT', '"']
    search_strings = []
    for line in content.split('\n'):
        if any(op in line for op in possible_operators):
            search_strings.append(line.strip())  # strip()ã‚’è¿½åŠ ã—ã¦ä½™åˆ†ãªç©ºç™½ã‚’å‰Šé™¤
    return search_strings if search_strings else [content]

def generate_search_string_with_gpt(objective, research_questions, client):
    # ç”Ÿæˆã•ã‚ŒãŸæ¤œç´¢æ–‡å­—åˆ—ã‚’ä½¿ç”¨ã—ã¦å­¦è¡“ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ã‚¯ã‚¨ãƒªã—ã€é–¢é€£è«–æ–‡ã®åˆæœŸã‚»ãƒƒãƒˆã‚’å–å¾—ã—ã¾ã™ã€‚
    # Removed the explicit instruction for logical operators
    combined_prompt = f"Given the research objective: '{objective}', and the following research questions: {research_questions['research_questions']}, generate two concise search string for identifying relevant literature for literature review.Do not include OR. Use AND if needed."

    response = client.chat.completions.create(
        # model="gpt-3.5-turbo",
        model="gpt-3.5-turbo-0125",
        messages=[
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": combined_prompt}
        ],
        # response_format={ "type": "json_object" },
        temperature=TEMPERATURE,
    )
    
    content = response.choices[0].message.content
    search_string = extract_search_strings(content)
    return search_string
```


```python
generate_search_string = generate_search_string_with_gpt(objective, questions_and_purposes, client)
print(generate_search_string)
```

    ['Search String 1: ("evaluating RAG status" OR "RAG evaluation methods") AND ("project management" OR "project monitoring")', 'Search String 2: ("RAG evaluation methods" OR "Red Amber Green assessment techniques") AND ("industry applications" OR "sector-specific adaptations")']



```python
# # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®å…¥åŠ›
# search_strings = [
#     '"Risk Assessment and Governance evaluation methods"',
#     '"Organizations measure success outcomes Risk Assessment Governance initiatives"'
# ]
```


```python
SYSTEM = """
### æŒ‡ç¤º ###
è«–æ–‡ã®å†…å®¹ã‚’ç†è§£ã—ãŸä¸Šã§ï¼Œé‡è¦ãªãƒã‚¤ãƒ³ãƒˆã‚’ç®‡æ¡æ›¸ãã§3ç‚¹æ›¸ã„ã¦ãã ã•ã„ã€‚

### ç®‡æ¡æ›¸ãã®åˆ¶ç´„ ###
- æœ€å¤§3å€‹
- æ—¥æœ¬èª
- ç®‡æ¡æ›¸ã1å€‹ã‚’50æ–‡å­—ä»¥å†…

### å¯¾è±¡ã¨ã™ã‚‹è«–æ–‡ã®å†…å®¹ ###
{text}

### å‡ºåŠ›å½¢å¼ ###
ã‚¿ã‚¤ãƒˆãƒ«(å’Œå)

- ç®‡æ¡æ›¸ã1
- ç®‡æ¡æ›¸ã2
- ç®‡æ¡æ›¸ã3
"""
```


```python
# arXivã®æ›´æ–°é »åº¦ã‚’åŠ å‘³ã—ã¦ã€365æ—¥å‰ã®è«–æ–‡ã‚’æ¤œç´¢
N_DAYS =365

MAX_RESULT = 10  # å–å¾—ã™ã‚‹è«–æ–‡æ•°ã®ä¸Šé™
# MODEL_NAME = "gpt-3.5-turbo-0613"
# MODEL_NAME = "gpt-3.5-turbo-1106"
MODEL_NAME = "gpt-3.5-turbo-0125"

# MODEL_NAME = "gpt-3.5-turbo-instruct"
TEMPERATURE = 0.7
# OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
client = OpenAI()

# ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ç”¨æ„
QUERY_TEMPLATE = '%28 ti:%22{}%22 OR abs:%22{}%22 %29 AND submittedDate: [{} TO {}]'

# æ¤œç´¢ã‚’è¡Œã„ã€çµæœã‚’å–å¾—ã™ã‚‹é–¢æ•°
def search_arxiv(keyword):
    # Construct the default API client.
    client = arxiv.Client()
    # 2æ—¥å‰ã‹ã‚‰N_DAYSå‰ã¾ã§ã®è«–æ–‡ã‚’æ¤œç´¢
    today = dt.datetime.today() - dt.timedelta(days=2)
    # today = dt.datetime.today()
    
    base_date = today - dt.timedelta(days=N_DAYS)
    query = QUERY_TEMPLATE.format(keyword, keyword, base_date.strftime("%Y%m%d%H%M%S"), today.strftime("%Y%m%d%H%M%S"))

    search = arxiv.Search(
        query=query,
        max_results=MAX_RESULT,
        sort_by=arxiv.SortCriterion.SubmittedDate,
        sort_order=arxiv.SortOrder.Descending,
    )

    results = client.results(search)
    return results

# è«–æ–‡ã®è¦ç´„ã‚’å–å¾—ã™ã‚‹é–¢æ•°
def get_summary(result):
    text = f"title: {result.title}\nbody: {result.summary}"

    messages = [
        {"role" : "system", "content" : SYSTEM},
        {"role": "user", "content": text}
    ]
    
    response = client.chat.completions.create(
        model=MODEL_NAME,
        messages=messages,
        temperature=TEMPERATURE,
    )
    return response.choices[0].message.content

```


```python
import re
def simplify_search_queries(complex_queries):
    simplified_queries = []

    for query in complex_queries:
        # æ•°å­—ã¨ãƒ”ãƒªã‚ªãƒ‰ã‚’é™¤å»ã—ã¦ã€ã‚¯ã‚¨ãƒªã®æœ¬ä½“ã ã‘ã‚’æŠ½å‡º
        clean_query = re.sub(r'^\d+\.\s*', '', query)
        
        # æ‹¬å¼§ã‚’é™¤å»
        clean_query = re.sub(r'[()"]', '', clean_query)
        
        # 'AND' ã¨ 'OR' ã§åˆ†å‰²
        split_queries = re.split(r'\sAND\s|\sOR\s', clean_query)
        
        # åˆ†å‰²ã—ãŸã‚¯ã‚¨ãƒªã‚’ãƒªã‚¹ãƒˆã«è¿½åŠ 
        for sub_query in split_queries:
            sub_query = sub_query.strip()
            if sub_query and sub_query not in simplified_queries:
                simplified_queries.append(sub_query)
                
    return simplified_queries
```


```python
simplified_queries = simplify_search_queries(generate_search_string)
# è¤‡æ•°ã®å˜èªã®é–“ã®ã‚¹ãƒšãƒ¼ã‚¹ã‚’ãƒã‚¤ãƒ•ãƒ³ã«ç½®æ›
# modified_queries = [query.replace(" ", "") for query in simplified_queries]
modified_queries = [query.replace(" ", "_") for query in simplified_queries]
# modified_queries = [query.split(" ") for query in simplified_queries]

for query in modified_queries:
    print(query)
```

    Search_String_1:_evaluating_RAG_status
    RAG_evaluation_methods
    project_management
    project_monitoring
    Search_String_2:_RAG_evaluation_methods
    Red_Amber_Green_assessment_techniques
    industry_applications
    sector-specific_adaptations



```python
simplified_queries
```




    ['Search String 1: evaluating RAG status',
     'RAG evaluation methods',
     'project management',
     'project monitoring',
     'Search String 2: RAG evaluation methods',
     'Red Amber Green assessment techniques',
     'industry applications',
     'sector-specific adaptations']




```python
import arxiv
# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’æ§‹ç¯‰ã™ã‚‹ã€‚
arxivclient = arxiv.Client()

# æ¤œç´¢æ¡ä»¶ã‚’æŒ‡å®šã™ã‚‹ã€‚
# query: æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŒ‡å®šã™ã‚‹ã€‚ã“ã“ã§ã¯ "GPT-4" ã‚’æŒ‡å®šã€‚
# max_results: å–å¾—ã™ã‚‹è«–æ–‡ã®æœ€å¤§ä»¶æ•°ã‚’æŒ‡å®šã™ã‚‹ã€‚ã“ã“ã§ã¯ 10 ä»¶ã€‚
# sort_by: è«–æ–‡ã®ä¸¦ã³æ›¿ãˆæ¡ä»¶ã‚’æŒ‡å®šã™ã‚‹ã€‚ã“ã“ã§ã¯æŠ•ç¨¿æ—¥æ™‚ã®é™é †ï¼ˆæœ€æ–°é †ï¼‰ã€‚

# for query in modified_queries:
for query in simplified_queries:
    print(query)
    search = arxiv.Search(
        query = query,
        max_results = 10,
        sort_by = arxiv.SortCriterion.SubmittedDate
    )

    # æ¤œç´¢ã‚’å®Ÿè¡Œã—ã€çµæœã‚’å–å¾—ã™ã‚‹ã€‚
    results = arxivclient.results(search)
    # å–å¾—ã—ãŸè«–æ–‡ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’1ä»¶ãšã¤è¡¨ç¤ºã™ã‚‹ã€‚
    for r in results:
        print(f"\n{str(r.title)}\n{get_summary(r)}\n{r}")
    print("-" * 50)
```

    Search String 1: evaluating RAG status
    
    Holo-Relighting: Controllable Volumetric Portrait Relighting from a Single Image
    ãƒ›ãƒ­ãƒ»ãƒªãƒ©ã‚¤ãƒ†ã‚£ãƒ³ã‚°: å˜ä¸€ç”»åƒã‹ã‚‰åˆ¶å¾¡å¯èƒ½ãªãƒœãƒªãƒ¥ãƒ¼ãƒ¡ãƒˆãƒªãƒƒã‚¯ãƒãƒ¼ãƒˆãƒ¬ãƒ¼ãƒˆã®ãƒªãƒ©ã‚¤ãƒ†ã‚£ãƒ³ã‚°
    
    - å˜ä¸€ç”»åƒã‹ã‚‰æ–°ã—ã„è¦–ç‚¹ã¨ç…§æ˜ã‚’åˆæˆå¯èƒ½
    - ãƒ˜ãƒƒãƒ‰ãƒãƒ¼ã‚ºã«ä¾å­˜ã—ãŸç…§æ˜åŠ¹æœã®ç”Ÿæˆ
    - ç‰©ç†çš„ãªç…§æ˜ã®äº‹å‰çŸ¥è­˜ãªã—ã§éãƒ©ãƒ³ãƒãƒ¼ãƒˆç…§æ˜åŠ¹æœã‚’ç”Ÿæˆ
    http://arxiv.org/abs/2403.09632v1
    
    Generating functional of correlators of twist-$2$ operators in $\mathcal{N} = 1$ SUSY Yang-Mills theory, I
    $\mathcal{N} = 1$ SUSY Yang-Millsç†è«–ã«ãŠã‘ã‚‹twist-$2$æ¼”ç®—å­ã®ç›¸é–¢é–¢æ•°ã®ç”Ÿæˆæ±é–¢æ•°
    
    - twist-$2$æ¼”ç®—å­ã®ç›¸é–¢é–¢æ•°ã®ç”Ÿæˆæ±é–¢æ•°ã‚’è¨ˆç®—
    - å¤§$N$å±•é–‹ã®leadingã¨next-to-leading orderã§è¨ˆç®—
    - éæ‘‚å‹•è§£ã¸ã®å¼·ã„UVæ¼¸è¿‘åˆ¶ç´„ã‚’è¨­å®š
    http://arxiv.org/abs/2403.09617v1
    
    pARam: Leveraging Parametric Design in Extended Reality to Support the Personalization of Artifacts for Personal Fabrication
    pARam: ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯ãƒ‡ã‚¶ã‚¤ãƒ³ã‚’æ‹¡å¼µç¾å®Ÿã«æ´»ç”¨ã—ã¦ã€å€‹äººè£½ä½œç”¨ã®ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã®ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹
    
    - æ‹¡å¼µç¾å®Ÿã¨ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯ãƒ‡ã‚¶ã‚¤ãƒ³ã‚’çµ„ã¿åˆã‚ã›ãŸpARamã¯ã€è¤‡é›‘ãª3Dãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã®å¿…è¦æ€§ã‚’æ’é™¤ã—ã€ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼ã‚„ç…§æ˜æ¨å®šãªã©ã®å®Ÿè·µçš„ãªå…¥åŠ›ã‚’é€šã˜ã¦ã€å€‹äººè£½ä½œã®ãŸã‚ã®ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªæ§‹æˆã‚’å¯èƒ½ã«ã™ã‚‹ã€‚
    - pARamã‚’ä½¿ç”¨ã—ãŸãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«é–¢é€£ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’é¸æŠã—ã€ç’°å¢ƒã‚’è€ƒæ…®ã—ã¦è¨­å®šã‚’è¡Œã†ã“ã¨ã«æˆåŠŸã—ã€ãã®åŠ¹æœã‚’ç¤ºã—ãŸã€‚
    - ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯ãƒ‡ã‚¶ã‚¤ãƒ³ã®æ‹¡å¼µç¾å®Ÿã«ãŠã‘ã‚‹æ´»ç”¨ã¯ã€å€‹äººè£½ä½œã®ãŸã‚ã®è¤‡é›‘ãªãƒ‡ã‚¶ã‚¤ãƒ³æ‰‹æ³•ã‚’åˆç†åŒ–ã™ã‚‹ä¸€æ–¹ã€é©åˆ‡ãªè¡¨ç¾æ€§ã‚’ä¿æŒã™ã‚‹ä¸Šã§ã®è¦‹é€šã—ã¨èª²é¡Œã«ã¤ã„ã¦ç¤ºå”†ã—ã¦ã„ã‚‹ã€‚
    http://arxiv.org/abs/2403.09607v1
    
    Multi-Fidelity Bayesian Optimization With Across-Task Transferable Max-Value Entropy Search
    å¤šé‡ä¿¡é ¼æ€§ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã«ãŠã„ã¦ã€å°†æ¥ã®ã‚¿ã‚¹ã‚¯ã«ã‚‚é©ç”¨å¯èƒ½ãªæ–°ã—ã„æƒ…å ±ç†è«–çš„å–å¾—é–¢æ•°ãŒå°å…¥ã•ã‚ŒãŸã€‚
    
    - å¤šé‡ä¿¡é ¼æ€§ãƒ–ãƒ©ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹æœ€é©åŒ–æˆ¦ç•¥ã¯ã€æœ€é©ãªå€¤ã‚„è§£ã«é–¢ã™ã‚‹æƒ…å ±ã‚’æœ€å¤§åŒ–ã™ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã‚‹ã€‚
    - æœªæ¥ã®ã‚¿ã‚¹ã‚¯ã«é©ç”¨å¯èƒ½ãªæƒ…å ±ã‚’åé›†ã™ã‚‹å¿…è¦æ€§ã¨ç¾åœ¨ã®ã‚¿ã‚¹ã‚¯ã«é–¢ã™ã‚‹æƒ…å ±ã‚’å–å¾—ã™ã‚‹å¿…è¦æ€§ã‚’ãƒãƒ©ãƒ³ã‚¹ã•ã›ã‚‹ã€‚
    - ææ¡ˆæ‰‹æ³•ã¯ã€æœªæ¥ã®ã‚¿ã‚¹ã‚¯ã«å¯¾å¿œã™ã‚‹ãŸã‚ã®å–å¾—æˆ¦ç•¥ã‚’å«ã¿ã€æœ€é©åŒ–åŠ¹ç‡ã‚’å¤§å¹…ã«æ”¹å–„ã§ãã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚
    http://arxiv.org/abs/2403.09570v1
    
    A perturbative approach to the non-relativistic string spectrum
    Aéç›¸å¯¾è«–çš„ãªæ–‡å­—åˆ—ã®ã‚¹ãƒšã‚¯ãƒˆãƒ«ã«å¯¾ã™ã‚‹æ‘‚å‹•è«–çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
    
    - éç›¸å¯¾è«–çš„æ–‡å­—åˆ—ã®ã‚¹ãƒšã‚¯ãƒˆãƒ«ã‚’è¦‹ã¤ã‘ã‚‹ãŸã‚ã«æ‘‚å‹•è«–çš„æ‰‹æ³•ã‚’ä½¿ç”¨
    - ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒœã‚½ãƒ³ã‚»ã‚¯ã‚¿ãƒ¼ã‚’æ‘‚å‹•ã—ã€BMNæ§˜ã®æŠ˜ã‚Šç•³ã¾ã‚ŒãŸæ–‡å­—åˆ—è§£ã‚’è€ƒãˆã‚‹
    - ç›¸äº’ä½œç”¨é …ãŒãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å†å®šç¾©ã«ã‚ˆã‚Šæ¶ˆå¤±ã—ã€AdSãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ã®è³ªé‡ã¨è³ªé‡ãªã—ã®è‡ªç”±å ´ã®çµ„ã¿åˆã‚ã›ã§è¨˜è¿°ã•ã‚Œã‚‹ã“ã¨ã‚’ç¤ºã™
    http://arxiv.org/abs/2403.09563v1
    
    A targeted radio pulsar survey of redback candidates with MeerKAT
    ã‚¿ã‚¤ãƒˆãƒ«ï¼šMeerKATã‚’ç”¨ã„ãŸãƒ¬ãƒƒãƒ‰ãƒãƒƒã‚¯å€™è£œã®ã‚¿ãƒ¼ã‚²ãƒ†ãƒƒãƒ‰ãªé›»æ³¢ãƒ‘ãƒ«ã‚µãƒ¼èª¿æŸ»
    
    - ãƒ¬ãƒƒãƒ‰ãƒãƒƒã‚¯å€™è£œã®ã†ã¡3ã¤ã®æ–°ãŸãªé›»æ³¢ãƒŸãƒªç§’ãƒ‘ãƒ«ã‚µãƒ¼ã‚’ç™ºè¦‹
    - ãƒ¬ãƒƒãƒ‰ãƒãƒƒã‚¯å€™è£œã®1ã¤ãŒé•·æœŸé–“ã«ã‚ãŸã‚Šé›»æ³¢æ”¾å°„ã‚’å¸åã™ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚Œã€ãã®å¯¾è±¡ã®ç§»ã‚Šå¤‰ã‚ã‚Šã‚’æ˜ã‚‰ã‹ã«
    - é›»æ³¢ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã«ã‚ˆã£ã¦ã€3ã¤ã®ãƒ‘ãƒ«ã‚µãƒ¼ã‹ã‚‰ã‚¬ãƒ³ãƒç·šãƒ‘ãƒ«ã‚¹ãŒæ¤œå‡ºã•ã‚Œã€15å¹´é–“ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°è§£ãŒå¾—ã‚‰ã‚Œã‚‹
    http://arxiv.org/abs/2403.09553v1
    
    How do Machine Learning Projects use Continuous Integration Practices? An Empirical Study on GitHub Actions
    æ©Ÿæ¢°å­¦ç¿’ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ãŠã‘ã‚‹ç¶™ç¶šçš„ã‚¤ãƒ³ãƒ†ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®å®Ÿè·µã«ã¤ã„ã¦ï¼šGitHub Actionsã«é–¢ã™ã‚‹å®Ÿè¨¼çš„ç ”ç©¶
    
    - MLãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯é€šå¸¸ã‚ˆã‚Šã‚‚é•·ã„ãƒ“ãƒ«ãƒ‰æ™‚é–“ã‚’å¿…è¦ã¨ã—ã€ä¸­è¦æ¨¡ã®MLãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯éMLãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚ˆã‚Šã‚‚ä½ã„ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ã‚’ç¤ºã™ã€‚
    - å°è¦æ¨¡ãŠã‚ˆã³ä¸­è¦æ¨¡ã®MLãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ã€éMLãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¨æ¯”è¼ƒã—ã¦ãƒ“ãƒ«ãƒ‰æ™‚é–“ãŒå¢—åŠ ã™ã‚‹å‚¾å‘ãŒé«˜ã„ã€‚
    - MLãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ãŠã‘ã‚‹CIã®å®Ÿè·µã«é–¢ã™ã‚‹å®šæ€§çš„åˆ†æã§ã¯ã€CIãƒ“ãƒ«ãƒ‰å®Ÿè¡Œã¨çŠ¶æ…‹ã€CIãƒ†ã‚¹ãƒˆã€CIã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ãªã©ã®ãƒ†ãƒ¼ãƒãŒå«ã¾ã‚Œã‚‹ã€‚
    http://arxiv.org/abs/2403.09547v1
    
    Artificial Bugs for Crowdsearch
    äººå·¥ãƒã‚°ã«ã‚ˆã‚‹ã‚¯ãƒ©ã‚¦ãƒ‰ã‚µãƒ¼ãƒ(å’Œå)
    
    - ãƒã‚°å ±å¥¨é‡‘ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã«äººå·¥ãƒã‚°ã‚’æŒ¿å…¥ã™ã‚‹ã“ã¨ã§ã€æœ¬ç‰©ã®ãƒã‚°ã‚’æ¢ã™ã‚¤ãƒ³ã‚»ãƒ³ãƒ†ã‚£ãƒ–ã‚’é«˜ã‚ã‚‹
    - äººå·¥ãƒã‚°ã¯1ã¤æŒ¿å…¥ã™ã‚‹ã ã‘ã§åŠ¹ç‡çš„ãªåˆ©ç›Šã‚’ã‚‚ãŸã‚‰ã™
    - ãƒ‡ã‚¶ã‚¤ãƒŠãƒ¼ãŒæœ¬ç‰©ã®ãƒã‚°ã‚’è¦‹ã¤ã‘ã‚‹ã“ã¨ã«é«˜ã„è©•ä¾¡ã‚’ç½®ãå ´åˆã‚„ã€äºˆç®—ãŒä¸ååˆ†ãªå ´åˆã«ç‰¹ã«æœ‰ç›Š
    http://arxiv.org/abs/2403.09484v1
    
    Edge-apexing in hereditary classes of graphs
    ã‚¨ãƒƒã‚¸-ã‚¨ãƒ¼ãƒšã‚­ã‚·ãƒ³ã‚°ã«ãŠã‘ã‚‹ã‚°ãƒ©ãƒ•ã®ä¸–ä»£çš„ã‚¯ãƒ©ã‚¹
    
    - ã‚¨ãƒƒã‚¸-ã‚¨ãƒ¼ãƒšã‚­ã‚·ãƒ³ã‚°ã¯ã€ã‚¯ãƒ©ã‚¹$\mathcal{G}$ãŒç¦æ­¢ã•ã‚ŒãŸèª˜å°éƒ¨åˆ†ã‚°ãƒ©ãƒ•ã‚’æœ‰é™å€‹æŒã¤å ´åˆã€ã‚¨ãƒ¼ãƒšãƒƒã‚¯ã‚¹ã‹ã‚‰ã®è·é›¢ãŒ1ä»¥ä¸‹ã®ã‚°ãƒ©ãƒ•ã®ã‚¯ãƒ©ã‚¹$G^{epex}$ã‚‚æœ‰é™å€‹ã®ç¦æ­¢èª˜å°éƒ¨åˆ†ã‚°ãƒ©ãƒ•ã‚’æŒã¤ã“ã¨ã‚’ç¤ºã™ã€‚
    - ã‚³ãƒ¼ã‚°ãƒ©ãƒ•ã®ä¸–ä»£çš„ã‚¯ãƒ©ã‚¹ã¯ã€è£œé›†åˆã¨ç›´å’Œã‹ã‚‰ç”Ÿæˆã•ã‚Œã‚‹ã™ã¹ã¦ã®ã‚°ãƒ©ãƒ•ã‹ã‚‰ãªã‚‹ã€‚ã‚¨ãƒƒã‚¸-ã‚¨ãƒ¼ãƒšã‚­ã‚·ãƒ³ã‚°ã‚³ãƒ¼ã‚°ãƒ©ãƒ•ã®ç¦æ­¢èª˜å°éƒ¨åˆ†ã‚°ãƒ©ãƒ•ã®å€‹æ•°ã¯8ã«åˆ¶é™ã•ã‚Œã€ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿æ¤œç´¢ã«ã‚ˆã£ã¦ãã‚Œã‚‰ã®ã™ã¹ã¦ãŒè¦‹ã¤ã‹ã‚‹ã€‚
    http://arxiv.org/abs/2403.09456v1
    
    Search for Higgs boson pair production in the bbWW decay mode in proton-proton collisions at $\sqrt{s}$ = 13 TeV
    ãƒ’ãƒƒã‚°ã‚¹ç²’å­å¯¾ç”Ÿæˆã®æ¤œç´¢: $bbWW$å´©å£Šãƒ¢ãƒ¼ãƒ‰ã«ãŠã‘ã‚‹13 TeVãƒ—ãƒ­ãƒˆãƒ³-ãƒ—ãƒ­ãƒˆãƒ³è¡çª
    
    - HHç”Ÿæˆæ–­é¢ç©ã®ä¸Šé™å€¤ãŒæ¨™æº–æ¨¡å‹ã®äºˆæ¸¬å€¤ã®14(18)å€ã¨ãªã‚Šã€éå…±é³´HHç”Ÿæˆã®æ–­é¢ç©ã«åˆ¶é™ã‚’è¨­å®šã€‚
    - ãƒ’ãƒƒã‚°ã‚¹ç²’å­çµåˆå¤‰èª¿å­ã‚„ç•°å¸¸ãƒ’ãƒƒã‚°ã‚¹ç²’å­çµåˆã‚·ãƒŠãƒªã‚ªã«é–¢ã™ã‚‹æ–­é¢ç©ã®åˆ¶é™å€¤ã‚’æç¤ºã€‚
    - è³ªé‡ç¯„å›²250-900 GeVã®ã‚¹ãƒ”ãƒ³0ãŠã‚ˆã³ã‚¹ãƒ”ãƒ³2å…±é³´ã‚’ä»‹ã—ãŸHHç”Ÿæˆã«å¯¾ã™ã‚‹åˆ¶é™ã‚’è¨­å®šã€‚
    http://arxiv.org/abs/2403.09430v1
    --------------------------------------------------
    RAG evaluation methods
    
    SCP-Diff: Photo-Realistic Semantic Image Synthesis with Spatial-Categorical Joint Prior
    SCP-Diff: ç©ºé–“ã‚«ãƒ†ã‚´ãƒªãƒ¼å…±åŒäº‹å‰åˆ†å¸ƒã‚’ç”¨ã„ãŸå†™çœŸå®Ÿåœ¨çš„ãªæ„å‘³ç”»åƒåˆæˆ
    
    - ç¾åœ¨ã®æœ€è‰¯æ‰‹æ³•ã§ã‚ã‚‹GANã«åŸºã¥ãSemantic image synthesis (SIS) ã¯ã€æœ›ã¾ã—ã„å“è³ªãƒ¬ãƒ™ãƒ«ã«ã¾ã é”ã—ã¦ã„ãªã„ã€‚
    - ControlNetã®çµæœã«ã¯ã€å¤§ããªæ„å‘³é ˜åŸŸå†…ã®å¥‡å¦™ãªã‚µãƒ–æ§‹é€ ã®å­˜åœ¨ã¨ã€å†…å®¹ãŒæ„å‘³ãƒã‚¹ã‚¯ã¨ã®æ•´åˆæ€§ãŒæ¬ ã‘ã‚‹ã¨ã„ã†2ã¤ã®ä¸»è¦ãªå•é¡ŒãŒã‚ã‚‹ã€‚
    - SCP-Diffã¯ã€ç©ºé–“ã€ã‚«ãƒ†ã‚´ãƒªãƒ¼ã€ãã—ã¦æ–°ã—ã„ç©ºé–“ã‚«ãƒ†ã‚´ãƒªãƒ¼å…±åŒäº‹å‰åˆ†å¸ƒã‚’å«ã‚€SISå‘ã‘ã®ç‰¹å®šã®ãƒã‚¤ã‚ºäº‹å‰åˆ†å¸ƒã‚’é–‹ç™ºã—ã€ãã®çµæœã€Cityscapesã§FID 10.53ã€ADE20Kã§12.66ã‚’é”æˆã—ãŸã€‚
    http://arxiv.org/abs/2403.09638v1
    
    GaussianGrasper: 3D Language Gaussian Splatting for Open-vocabulary Robotic Grasping
    GaussianGrasper: 3Dè¨€èªã‚¬ã‚¦ã‚¹æ•£ä¹±ã‚’ç”¨ã„ãŸãƒ­ãƒœãƒƒãƒˆã®æ´ã‚€ãŸã‚ã®ã‚ªãƒ¼ãƒ—ãƒ³ãƒœã‚­ãƒ£ãƒ–ãƒ©ãƒªãƒ¼
    
    - 3Dã‚·ãƒ¼ãƒ³ã‚’ã‚¬ã‚¦ã‚¹ãƒ—ãƒªãƒŸãƒ†ã‚£ãƒ–ã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã¨ã—ã¦æ˜ç¤ºçš„ã«è¡¨ç¾ã™ã‚‹
    - Efficient Feature Distillation (EFD)ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã«ã‚ˆã‚‹è¨€èªåŸ‹ã‚è¾¼ã¿ã®åŠ¹ç‡çš„ãªæŠ½å‡º
    - ãƒãƒ¼ãƒãƒ«ã«èª˜å°ã•ã‚ŒãŸæ´ã‚€ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦æœ€é©ãªæ´ã‚€å§¿å‹¢ã‚’é¸æŠ
    http://arxiv.org/abs/2403.09637v1
    
    Dynamic Memory Compression: Retrofitting LLMs for Accelerated Inference
    å‹•çš„ãƒ¡ãƒ¢ãƒªåœ§ç¸®ï¼šé«˜é€Ÿæ¨è«–ã®ãŸã‚ã®LLMã®å¾Œä»˜ã‘
    
    - Dynamic Memory Compression (DMC)ã¯ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã®ã‚­ãƒ¼ãƒ»ãƒãƒªãƒ¥ãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ¥åœ§ç¸®ã‚’ææ¡ˆ
    - DMCã¯ç•°ãªã‚‹ãƒ˜ãƒƒãƒ‰ã‚„ãƒ¬ã‚¤ãƒ¤ãƒ¼ã§ç•°ãªã‚‹åœ§ç¸®ç‡ã‚’é©ç”¨ã™ã‚‹ã“ã¨ã‚’å­¦ç¿’
    - DMCã¯å…ƒã®ãƒ€ã‚¦ãƒ³ã‚¹ãƒˆãƒªãƒ¼ãƒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ä¿æŒã—ã¤ã¤ã€æœ€å¤§4å€ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥åœ§ç¸®ã‚’å®Ÿç¾
    http://arxiv.org/abs/2403.09636v1
    
    OneTracker: Unifying Visual Object Tracking with Foundation Models and Efficient Tuning
    OneTracker: Foundationãƒ¢ãƒ‡ãƒ«ã¨åŠ¹ç‡çš„ãªãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã§è¦–è¦šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã‚’çµ±åˆ
    
    - è¦–è¦šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã¯ã€åˆæœŸãƒ•ãƒ¬ãƒ¼ãƒ ã§ã®å¤–è¦³ã«åŸºã¥ã„ã¦å„ãƒ•ãƒ¬ãƒ¼ãƒ ã®å¯¾è±¡ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ãƒ­ãƒ¼ã‚«ãƒ©ã‚¤ã‚ºã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚
    - OneTrackerã¯ã€Foundation Trackerã¨Prompt Trackerã‹ã‚‰æ§‹æˆã•ã‚Œã€ä»–ã®ãƒ¢ãƒ‡ãƒ«ã‚’å‡Œé§•ã—ã€æœ€å…ˆç«¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã€‚
    - OneTrackerã¯ã€å¤§è¦æ¨¡ãªãƒ—ãƒªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è¡Œã„ã€å®‰å®šã—ãŸèƒ½åŠ›ã‚’æŒã¤Foundation Trackerã‚’æ§‹ç¯‰ã—ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼åŠ¹ç‡ã®è‰¯ã„ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿç¾ã€‚
    http://arxiv.org/abs/2403.09634v1
    
    Holo-Relighting: Controllable Volumetric Portrait Relighting from a Single Image
    Holo-Relighting: å˜ä¸€ç”»åƒã‹ã‚‰ã®åˆ¶å¾¡å¯èƒ½ãªä½“ç©çš„ãƒãƒ¼ãƒˆãƒ¬ãƒ¼ãƒˆãƒ»ãƒªãƒ©ã‚¤ãƒ†ã‚£ãƒ³ã‚°
    
    - Holo-Relightingã¯å˜ä¸€ç”»åƒã‹ã‚‰æ–°ã—ã„è¦–ç‚¹ã¨ç…§æ˜ã‚’åˆæˆã§ãã‚‹ã€‚
    - EG3Dã‚’æ´»ç”¨ã—ã¦ã€ï¼“æ¬¡å…ƒã®ã‚¸ã‚ªãƒ¡ãƒˆãƒªã¨å¤–è¦³ã‚’å¾©å…ƒã™ã‚‹ã€‚
    - ãƒ›ãƒ­ãƒ»ãƒªãƒ©ã‚¤ãƒ†ã‚£ãƒ³ã‚°ã¯ã€ç…§æ˜ã€è¦–ç‚¹ã€ãƒ˜ãƒƒãƒ‰ãƒãƒ¼ã‚ºã‚’åˆ¶å¾¡å¯èƒ½ã«ã™ã‚‹ã€‚
    http://arxiv.org/abs/2403.09632v1
    
    Quiet-STaR: Language Models Can Teach Themselves to Think Before Speaking
    Quiet-STaR: è¨€èªãƒ¢ãƒ‡ãƒ«ã¯è©±ã™å‰ã«è€ƒãˆã‚‹ã“ã¨ã‚’è‡ªå·±å­¦ç¿’ã§ãã‚‹
    
    - STaRã§ã¯å°‘æ•°ã®ä¾‹ã‹ã‚‰åˆç†çš„æ€è€ƒã‚’å­¦ã¶ãŒã€Quiet-STaRã¯ä»»æ„ã®ãƒ†ã‚­ã‚¹ãƒˆã§åˆç†çš„æ€è€ƒã‚’æ¨è«–ã™ã‚‹
    - LMãŒå†…éƒ¨æ€è€ƒã‚’ç”Ÿæˆãƒ»ä½¿ç”¨ã™ã‚‹æ–¹æ³•ã‚’å­¦ã¶èª²é¡Œã‚’è§£æ±ºã—ã€é›£ã—ã„ãƒˆãƒ¼ã‚¯ãƒ³ã®äºˆæ¸¬ç²¾åº¦å‘ä¸Šã«è²¢çŒ®
    - Internetãƒ†ã‚­ã‚¹ãƒˆã§ã®äº‹å‰å­¦ç¿’å¾Œã€GSM8Kã‚„CommonsenseQAã§ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã§æ”¹å–„ã—ã€é›£ã—ã„ãƒˆãƒ¼ã‚¯ãƒ³ã®perplexityã‚‚å‘ä¸Š
    http://arxiv.org/abs/2403.09629v1
    
    Video Mamba Suite: State Space Model as a Versatile Alternative for Video Understanding
    å‹•ç”»ç†è§£ã«ãŠã‘ã‚‹State Space Modelã®é‡è¦æ€§
    
    - State Space Model(Mamba)ã¯é•·ã„ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã®ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã«æˆåŠŸã—ã¦ãŠã‚Šã€å‹•ç”»ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã«ã‚‚æœ‰æœ›ãªç‰¹æ€§ã‚’ç¤ºã™ã€‚
    - Mambaã¯Transformersã«ä»£ã‚ã‚‹å‹•ç”»ç†è§£ã®é¸æŠè‚¢ã¨ã—ã¦å„ªã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚
    - Mambaã¯å‹•ç”»å°‚ç”¨ãŠã‚ˆã³å‹•ç”»-è¨€èªã‚¿ã‚¹ã‚¯ã®ä¸¡æ–¹ã§å¼·åŠ›ãªæ½œåœ¨èƒ½åŠ›ã‚’ç¤ºã—ã€åŠ¹ç‡æ€§ã¨æ€§èƒ½ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚‚æœŸå¾…ã•ã‚Œã‚‹ã€‚
    http://arxiv.org/abs/2403.09626v1
    
    Make-Your-3D: Fast and Consistent Subject-Driven 3D Content Generation
    Make-Your-3D: 3Dã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è¿…é€Ÿã§ä¸€è²«æ€§ã®ã‚ã‚‹ä¸»é¡Œé§†å‹•ç”Ÿæˆ
    
    - æ—¢å­˜ã®3Dç”Ÿæˆæ‰‹æ³•ã§ã¯ã€ç•°ãªã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé–“ã§ä¸»é¡Œé§†å‹•ã®3Dã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒé›£ã—ã„ã€‚
    - Make-Your-3Dã¯ã€å˜ä¸€ã®ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆè¨˜è¿°ã‹ã‚‰ã‚ãšã‹5åˆ†ã§é«˜å“è³ªã‹ã¤ä¸€è²«ã—ãŸ3Dã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å€‹äººåŒ–ã§ãã‚‹ã€‚
    - è‘—è€…ã‚‰ã®æ‰‹æ³•ã¯ã€ä¸»é¡Œã«åˆã£ãŸåˆ†å¸ƒã¸ã®èª¿æ•´ã‚’è¡Œã„ã€æœªçŸ¥ã®ä¸»é¡Œç”»åƒã‹ã‚‰ã®ãƒ†ã‚­ã‚¹ãƒˆé§†å‹•å¤‰æ›´ãŒå¯èƒ½ã€‚
    http://arxiv.org/abs/2403.09625v1
    
    Score-Guided Diffusion for 3D Human Recovery
    Score-Guided Diffusion for 3D Human Recovery
    
    - 3Däººä½“ãƒãƒ¼ã‚ºã¨å½¢çŠ¶å†æ§‹ç¯‰ã®ãŸã‚ã®é€†å•é¡Œè§£æ±ºæ‰‹æ³•
    - ç”»åƒè¦³æ¸¬ã«äººä½“ãƒ¢ãƒ‡ãƒ«ã‚’é©åˆã•ã›ã‚‹ãŒã€ã‚¹ã‚³ã‚¢ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã«ã‚ˆã£ã¦é€†å•é¡Œã‚’è§£æ±º
    - ScoreHMRã¯æœ€é©åŒ–æ‰‹æ³•ã«æ¯”ã¹ã¦ã€3ã¤ã®è¨­å®š/ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã™
    http://arxiv.org/abs/2403.09623v1
    
    Glyph-ByT5: A Customized Text Encoder for Accurate Visual Text Rendering
    ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã«ã‚ˆã‚‹æ­£ç¢ºãªè¦–è¦šãƒ†ã‚­ã‚¹ãƒˆãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°
    
    - ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã®ä¸è¶³ã«ã‚ˆã‚‹è¦–è¦šãƒ†ã‚­ã‚¹ãƒˆãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã®èª²é¡Œ
    - Glyph-ByT5ã®é–‹ç™ºã«ã‚ˆã‚Šã€ãƒ‡ã‚¶ã‚¤ãƒ³ç”»åƒç”Ÿæˆã«ãŠã‘ã‚‹ãƒ†ã‚­ã‚¹ãƒˆãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã®æ­£ç¢ºæ€§ãŒå¤§å¹…ã«å‘ä¸Š
    - Glyph-SDXLãƒ¢ãƒ‡ãƒ«ã®ç™»å ´ã«ã‚ˆã‚Šã€è‡ªå‹•å¤šè¡Œãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã§ã®é«˜ã„ã‚¹ãƒšãƒ«ç²¾åº¦ã‚’å®Ÿç¾
    http://arxiv.org/abs/2403.09622v1
    --------------------------------------------------
    project management
    
    SCP-Diff: Photo-Realistic Semantic Image Synthesis with Spatial-Categorical Joint Prior
    SCP-Diff: ç©ºé–“ã‚«ãƒ†ã‚´ãƒªãƒ¼å…±åŒäº‹å‰åˆ†å¸ƒã‚’ç”¨ã„ãŸå†™çœŸãƒªã‚¢ãƒ«ãªæ„å‘³ç”»åƒåˆæˆ
    
    - ç¾åœ¨ã®æœ€é«˜æ°´æº–ã§ã‚ã‚‹GANã«åŸºã¥ãSISã¯ã€æœ›ã¾ã—ã„å“è³ªã«ã¯è‡³ã£ã¦ã„ãªã„ã€‚
    - ControlNetã®çµæœã«ã¯ã€å¤§ããªæ„å‘³é ˜åŸŸå†…ã®å¥‡å¦™ãªã‚µãƒ–æ§‹é€ ã¨æ„å‘³ãƒã‚¹ã‚¯ã¨ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ä¸ä¸€è‡´ãŒã‚ã‚‹ã€‚
    - SCP-Diffã¯ã€ç‰¹å®šã®ãƒã‚¤ã‚ºäº‹å‰åˆ†å¸ƒã‚’é–‹ç™ºã—ã€å„ªã‚ŒãŸæˆæœã‚’ä¸Šã’ã¦ã„ã‚‹ã€‚
    http://arxiv.org/abs/2403.09638v1
    
    3D-VLA: A 3D Vision-Language-Action Generative World Model
    3D-VLA: 3D Vision-Language-Action Generative World Model
    
    - 2Då…¥åŠ›ã«é ¼ã‚‰ãšã€3Dä¸–ç•Œã¨ã®çµ±åˆã‚’å®Ÿç¾ã™ã‚‹
    - 3DçŸ¥è¦šã€æ¨è«–ã€ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’çµã³ã¤ã‘ã‚‹
    - å®Ÿä¸–ç•Œã®è¨ˆç”»ã«ãŠã‘ã‚‹ç†ç”±ä»˜ã‘ã€å¤šæ§˜ãªç”Ÿæˆã€è¨ˆç”»èƒ½åŠ›ã‚’å‘ä¸Š
    http://arxiv.org/abs/2403.09631v1
    
    Make-Your-3D: Fast and Consistent Subject-Driven 3D Content Generation
    Make-Your-3D: é«˜é€Ÿã§ä¸€è²«ã—ãŸä¸»é¡Œé§†å‹•ã®3Dã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆ
    
    - æ—¢å­˜ã®3Dç”Ÿæˆæ‰‹æ³•ã§ã¯ã€ç•°ãªã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ã£ã¦ä¸»é¡Œé§†å‹•ã®3Dã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”Ÿæˆã™ã‚‹ã®ãŒé›£ã—ã„
    - Make-Your-3Dã¯ã€ä¸€æšã®ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆã®èª¬æ˜ã‹ã‚‰5åˆ†ä»¥å†…ã§é«˜å“è³ªã§ä¸€è²«æ€§ã®ã‚ã‚‹3Dã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ä½œæˆã™ã‚‹
    - ãƒãƒ«ãƒãƒ“ãƒ¥ãƒ¼ãƒ‡ã‚£ãƒ•ãƒ¥ãƒ¼ã‚¸ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ«ã¨ç‰¹å®šã®2Dç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®åˆ†å¸ƒã‚’èª¿å’Œã•ã›ã€æœ›ã¾ã—ã„3Dä¸»é¡Œã®åˆ†å¸ƒã«åˆã‚ã›ã‚‹
    http://arxiv.org/abs/2403.09625v1
    
    Score-Guided Diffusion for 3D Human Recovery
    Score-Guided Diffusionã«ã‚ˆã‚‹3Däººä½“å¾©å…ƒ
    
    - ç”»åƒè¦³æ¸¬ã«å¯¾ã™ã‚‹ã‚¹ã‚³ã‚¢èª˜å°ã«ã‚ˆã‚Šã€æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®æ½œåœ¨ç©ºé–“ã§ãƒ¢ãƒ‡ãƒ«ã¨ç”»åƒã®æ•´åˆã‚’é”æˆã€‚
    - ç”»åƒã‹ã‚‰ã®äººä½“ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ¡ä»¶ä»˜ãåˆ†å¸ƒã‚’æ‰ãˆãŸæ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã€‚
    - ScoreHMRã¯å†ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸è¦ã§é€†å•é¡Œã‚’è§£æ±ºã—ã€3ã¤ã®å¿œç”¨è¨­å®šã§æœ€é©åŒ–æ‰‹æ³•ã‚’å‡Œé§•ã™ã‚‹ã€‚
    http://arxiv.org/abs/2403.09623v1
    
    PosSAM: Panoptic Open-vocabulary Segment Anything
    PosSAM: Panoptic Open-vocabulary Segment Anything
    
    - SAMã®åˆ¶é™ã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€PosSAMã¯LDPãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¨MASEã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ææ¡ˆ
    - PosSAMã¯SAMã¨CLIPã®ç‰¹å¾´ã‚’çµ„ã¿åˆã‚ã›ã€é«˜ã„æ±åŒ–æ€§èƒ½ã‚’å®Ÿç¾
    - COCO to ADE20Kã¨ADE20K to COCOã®ä¸¡æ–¹ã§ã€æ—¢å­˜æ‰‹æ³•ã‚’å¤§å¹…ã«ä¸Šå›ã‚‹æ€§èƒ½
    http://arxiv.org/abs/2403.09620v1
    
    PrompTHis: Visualizing the Process and Influence of Prompt Editing during Text-to-Image Creation
    PrompTHis: ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç”»åƒã¸ã®ç”Ÿæˆéç¨‹ã¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç·¨é›†ã®å½±éŸ¿ã‚’å¯è¦–åŒ–
    
    - ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç·¨é›†ã®éç¨‹ã‚’å¯è¦–åŒ–ã™ã‚‹ãŸã‚ã®Image Variant Graphã®ææ¡ˆ
    - ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå±¥æ­´ã‚’é€šã˜ã¦æ¢ç´¢ã—ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¤‰æ›´ãŒå‡ºåŠ›ç”»åƒã«ä¸ãˆã‚‹å½±éŸ¿ã‚’ç†è§£
    - PrompTHisã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå±¥æ­´ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã¨åˆ†æã‚’é€šã˜ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå‡ºåŠ›ç”»åƒã®ç”Ÿæˆã‚’åŠ¹æœçš„ã«åˆ¶å¾¡
    http://arxiv.org/abs/2403.09615v1
    
    Network-Controlled Repeater -- An Introduction
    ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ¶å¾¡ä¸­ç¶™å™¨--å°å…¥
    
    - 5Gãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§ã¯ã€ãƒŸãƒªæ³¢ã‚¹ãƒšã‚¯ãƒˆãƒ«ãŒã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã€ä¿¡é ¼æ€§ã€é…å»¶ãªã©ã®å‘ä¸Šã‚’ã‚‚ãŸã‚‰ã™ãŒã€ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ã®å½±éŸ¿ã‚‚é«˜ã¾ã‚Šã€ã‚«ãƒãƒ¬ãƒƒã‚¸ã‚’åˆ¶é™ã™ã‚‹èª²é¡Œã‚‚ã€‚
    - ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ¶å¾¡ä¸­ç¶™å™¨(NCR)ã¯ã€ã‚«ãƒãƒ¬ãƒƒã‚¸å•é¡Œã‚’å…‹æœã™ã‚‹æ‰‹æ³•ã¨ã—ã¦ä½è¤‡é›‘æ€§ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒãƒ¼ãƒ‰ã§ã‚ã‚Šã€é©åˆ‡ãªãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¨ˆç”»ã¨ãƒ“ãƒ¼ãƒ ãƒ•ã‚©ãƒ¼ãƒŸãƒ³ã‚°è¨­è¨ˆã«ã‚ˆã‚Šã€BSã®æ­»è§’ã‚’ã‚«ãƒãƒ¼ã™ã‚‹é­…åŠ›çš„ãªè§£æ±ºç­–ã¨ãªã‚‹ã€‚
    - 3GPP Rel-18ã§åˆæ„ã•ã‚ŒãŸNCRã®ä¸»è¦ä»•æ§˜ã‚’æç¤ºã—ã€éƒ½å¸‚ã‚·ãƒŠãƒªã‚ªã§ã®ç•°ãªã‚‹NCRå±•é–‹ã‚’åˆ†æã—ã€ãã®æ€§èƒ½ã‚’ä»–ã®å±•é–‹ã¨æ¯”è¼ƒã€‚
    http://arxiv.org/abs/2403.09601v1
    
    DungeonMaker: Embedding Tangible Creation and Destruction in Hybrid Board Games through Personal Fabrication Technology
    DungeonMaker: ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒœãƒ¼ãƒ‰ã‚²ãƒ¼ãƒ ã«ãŠã‘ã‚‹ç‰©è³ªçš„ãªå‰µé€ ã¨ç ´å£Šã‚’å€‹äººè£½ä½œæŠ€è¡“ã‚’é€šã˜ã¦çµ„ã¿è¾¼ã‚€
    
    - DungeonMakerã¯ç‰©èªã‚’èªã‚Šã€ãƒ‡ã‚¸ã‚¿ãƒ«ã‚²ãƒ¼ãƒ ãƒœãƒ¼ãƒ‰ã‚’ãƒ¬ãƒ¼ã‚¶ãƒ¼ã‚«ãƒƒã‚¿ãƒ¼ã«æŠ•å½±ã™ã‚‹ã€‚
    - ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ãŒä½œæˆã—ãŸã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã‚’è©•ä¾¡ã™ã‚‹ã€‚
    - ãƒ¬ãƒ¼ã‚¶ãƒ¼ãŒãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚„éãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ãƒ•ã‚£ã‚®ãƒ¥ã‚¢ã‚’ç§»å‹•ã•ã›ã€ç‰©ç†çš„ã«æå‚·ã•ã›ã‚‹ã€‚
    http://arxiv.org/abs/2403.09592v1
    
    Are you a robot? Detecting Autonomous Vehicles from Behavior Analysis
    ãƒ­ãƒœãƒƒãƒˆã‹ã©ã†ã‹ã‚’æ¤œå‡ºã™ã‚‹ãŸã‚ã®è¡Œå‹•åˆ†æã‹ã‚‰è‡ªå¾‹è»Šä¸¡ã‚’ç‰¹å®š
    
    - è‡ªå¾‹è»Šä¸¡ã¨äººé–“é‹è»¢è»Šä¸¡ã‚’è‡ªå‹•çš„ã«è­˜åˆ¥ã™ã‚‹å¿…è¦æ€§
    - ã‚«ãƒ¡ãƒ©ç”»åƒã¨çŠ¶æ…‹æƒ…å ±ã‚’æ´»ç”¨ã—ã¦è‡ªå¾‹è»Šä¸¡ã‚’ç‰¹å®šã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®ææ¡ˆ
    - å‹•ç”»ã‚¯ãƒªãƒƒãƒ—ã®åˆ†æã«ã‚ˆã‚Šè‡ªå¾‹è»Šä¸¡ã‚’80%ã®ç²¾åº¦ã§è­˜åˆ¥å¯èƒ½ã§ã‚ã‚Šã€çŠ¶æ…‹æƒ…å ±ãŒã‚ã‚‹å ´åˆã«ã¯93%ã¾ã§å‘ä¸Š
    http://arxiv.org/abs/2403.09571v1
    
    PaperBot: Learning to Design Real-World Tools Using Paper
    PaperBot: ç´™ã‚’ä½¿ç”¨ã—ã¦å®Ÿä¸–ç•Œã®ãƒ„ãƒ¼ãƒ«ã‚’è¨­è¨ˆã™ã‚‹æ–¹æ³•ã‚’å­¦ç¿’ã™ã‚‹
    
    - ç´™ã‚’ä½¿ç”¨ã—ã€ãƒ„ãƒ¼ãƒ«ã‚’è¨­è¨ˆãƒ»ä½¿ç”¨ã™ã‚‹æ–¹æ³•ã‚’ç›´æ¥å­¦ç¿’ã™ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
    - ç´™é£›è¡Œæ©Ÿã®æœ€å¤§é£›è¡Œè·é›¢ã‚„æœ€å¤§æŠŠæŒåŠ›ã‚’æŒã¤ãƒšãƒ¼ãƒ‘ãƒ¼ã‚°ãƒªãƒƒãƒ‘ãƒ¼ã‚’å­¦ç¿’ã™ã‚‹
    - æŠ˜ã‚ŠãŸãŸã¿ã€åˆ‡æ–­ã€ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ãªæ“ä½œã‚’çµ„ã¿åˆã‚ã›ã¦ãƒ„ãƒ¼ãƒ«ã®è¨­è¨ˆãƒ»ä½¿ç”¨ã‚’æœ€é©åŒ–
    http://arxiv.org/abs/2403.09566v1
    --------------------------------------------------
    project monitoring
    
    SCP-Diff: Photo-Realistic Semantic Image Synthesis with Spatial-Categorical Joint Prior
    SCP-Diff: ç©ºé–“-ã‚«ãƒ†ã‚´ãƒªãƒ¼å…±åŒäº‹å‰çŸ¥è­˜ã‚’ç”¨ã„ãŸå†™çœŸãƒªã‚¢ãƒ«ãªæ„å‘³ç”»åƒåˆæˆ
    
    - GANã«åŸºã¥ãSISã®å“è³ªå‘ä¸Šèª²é¡Œ
    - æ—¢å­˜æ‰‹æ³•ã®å•é¡Œç‚¹ã®ç‰¹å®šã¨å¯¾å¿œ
    - SCP-Diffã®é«˜ã„æ€§èƒ½(FID: 10.53 on Cityscapes, 12.66 on ADE20K)
    http://arxiv.org/abs/2403.09638v1
    
    3D-VLA: A 3D Vision-Language-Action Generative World Model
    3D-VLA: 3Dãƒ“ã‚¸ãƒ§ãƒ³ãƒ»è¨€èªãƒ»è¡Œå‹•ç”Ÿæˆãƒ¯ãƒ¼ãƒ«ãƒ‰ãƒ¢ãƒ‡ãƒ«
    
    - 3D-VLAã¯3DçŸ¥è¦šã€æ¨è«–ã€è¡Œå‹•ã‚’ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«çµã³ã¤ã‘ã‚‹ãŸã‚ã®æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã‚’ææ¡ˆã™ã‚‹ã€‚
    - 3D-VLAã¯å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ãƒ™ãƒ¼ã‚¹ã«æ§‹ç¯‰ã•ã‚Œã€ç”Ÿæˆèƒ½åŠ›ã‚’æŒã¤æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã‚’å°å…¥ã—ã¦ã„ã‚‹ã€‚
    - 3D-VLAã¯å®Ÿä¸–ç•Œå¿œç”¨ã«ãŠã„ã¦ã€ç†è«–ã€å¤šæ§˜ãªç”Ÿæˆã€è¨ˆç”»èƒ½åŠ›ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã‚‹å®Ÿé¨“çµæœã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚
    http://arxiv.org/abs/2403.09631v1
    
    Make-Your-3D: Fast and Consistent Subject-Driven 3D Content Generation
    Make-Your-3D: ä¸»ä½“ã«åŸºã¥ã3Dã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆã®é«˜é€Ÿã‹ã¤ä¸€è²«æ€§ã®ã‚ã‚‹æ‰‹æ³•
    
    - æ—¢å­˜ã®3Dç”Ÿæˆæ–¹æ³•ã§ã¯ã€ç•°ãªã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé–“ã§ä¸»ä½“ã«åŸºã¥ã3Dã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ä½œæˆã™ã‚‹ã“ã¨ãŒå›°é›£ã§ã‚ã‚‹
    - Make-Your-3Dã¯ã€å˜ä¸€ã®ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆèª¬æ˜ã‹ã‚‰5åˆ†ä»¥å†…ã§é«˜å“è³ªã‹ã¤ä¸€è²«æ€§ã®ã‚ã‚‹3Dã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å€‹äººåŒ–ã§ãã‚‹
    - å¤šè¦–ç‚¹æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã¨ç‰¹å®šã®ã‚¢ã‚¤ãƒ‡ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã«åŸºã¥ã2Dç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®åˆ†å¸ƒã‚’èª¿å’Œã•ã›ã€æ‰€æœ›ã®3Dä¸»ä½“ã®åˆ†å¸ƒã¨æ•´åˆã•ã›ã‚‹
    http://arxiv.org/abs/2403.09625v1
    
    Score-Guided Diffusion for 3D Human Recovery
    Score-Guided Diffusionã«ã‚ˆã‚‹3Däººç‰©å¾©å…ƒ
    
    - 3Däººç‰©ãƒãƒ¼ã‚ºã¨å½¢çŠ¶å†æ§‹ç¯‰ã®é€†å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã®ScoreHMRã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
    - ç”»åƒè¦³æ¸¬ã«äººä½“ãƒ¢ãƒ‡ãƒ«ã‚’é©åˆã•ã›ã‚‹é€†å•é¡Œã‚’ã€æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®æ½œåœ¨ç©ºé–“ã§ã‚¹ã‚³ã‚¢ã‚¬ã‚¤ãƒ‰ã‚’ç”¨ã„ã¦è§£æ±º
    - ScoreHMRã¯ç”»åƒè¦³æ¸¬ã¨ã®æ•´åˆæ€§ã‚’æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®æ½œåœ¨ç©ºé–“ã§ã‚¹ã‚³ã‚¢ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã«ã‚ˆã£ã¦å®Ÿç¾
    http://arxiv.org/abs/2403.09623v1
    
    PosSAM: Panoptic Open-vocabulary Segment Anything
    PosSAM: Panoptic Open-vocabulary Segment Anything
    
    - SAMã¨CLIPã‚’çµ±åˆã—ãŸPosSAMã¯ã€ç©ºé–“çš„ãƒã‚¹ã‚¯ç”Ÿæˆã¨ç‰©ä½“ã‚¯ãƒ©ã‚¹èªè­˜ã®ä¸¡æ–¹ã«å„ªã‚Œã€ã‚ªãƒ¼ãƒãƒ¼ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è»½æ¸›ã™ã‚‹ã€‚
    - LDPãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯ã€SAMã¨CLIPã®ç‰¹å¾´ã‚’æ´»ç”¨ã—ã€åè¦‹ã®ãªã„ã‚ªãƒ¼ãƒ—ãƒ³ãƒœã‚­ãƒ£ãƒ–ãƒ©ãƒªãƒ¼åˆ†é¡ã‚’å®Ÿç¾ã™ã‚‹ã€‚
    - MASEã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯ã€ãƒã‚¹ã‚¯ã®å“è³ªã‚’å‘ä¸Šã•ã›ã€æ¨è«–æ™‚ã®åˆ†é¡æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚
    http://arxiv.org/abs/2403.09620v1
    
    PrompTHis: Visualizing the Process and Influence of Prompt Editing during Text-to-Image Creation
    PrompTHis: ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç”»åƒã‚’ç”Ÿæˆã™ã‚‹éš›ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç·¨é›†ã®ãƒ—ãƒ­ã‚»ã‚¹ã¨å½±éŸ¿ã‚’å¯è¦–åŒ–
    
    - ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå±¥æ­´ã‚’å¯è¦–åŒ–ã™ã‚‹Image Variant Graphã¯ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ç”»åƒã®æ¯”è¼ƒã‚„ç·¨é›†å±¥æ­´ã®æ¢ç´¢ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹ã€‚
    - PrompTHisã‚·ã‚¹ãƒ†ãƒ ã¯ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå±¥æ­´ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚„åˆ†æã‚’é€šã˜ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¤‰æ›´ã®å½±éŸ¿ã‚’ç†è§£ã—ã€ç”»åƒç”Ÿæˆã‚’åŠ¹æœçš„ã«åˆ¶å¾¡ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚
    - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¹ã‚¿ãƒ‡ã‚£ã«ã‚ˆã‚‹ã¨ã€PrompTHisã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå±¥æ­´ã‚’ç¢ºèªã—ã€ãƒ¢ãƒ‡ãƒ«ã‚’ç†è§£ã—ã€å‰µé€ ãƒ—ãƒ­ã‚»ã‚¹ã‚’è¨ˆç”»ã™ã‚‹ã®ã«å½¹ç«‹ã¤ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚
    http://arxiv.org/abs/2403.09615v1
    
    Network-Controlled Repeater -- An Introduction
    ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ¶å¾¡ãƒªãƒ”ãƒ¼ã‚¿ãƒ¼ã®ç´¹ä»‹
    
    - 5Gãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§ã¯ãƒŸãƒªæ³¢ã‚¹ãƒšã‚¯ãƒˆãƒ«ã‚’æ´»ç”¨ã—ã€NCRãŒã‚«ãƒãƒ¬ãƒƒã‚¸å•é¡Œã‚’è§£æ±º
    - 3GPP Rel-18ã§ã®NCRä»•æ§˜ã‚’æç¤ºã—ã€éƒ½å¸‚ã‚·ãƒŠãƒªã‚ªã§ã®æ€§èƒ½ã‚’æ¤œè¨¼
    - é©åˆ‡ãªãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¨ˆç”»ã¨ãƒ“ãƒ¼ãƒ ãƒ•ã‚©ãƒ¼ãƒŸãƒ³ã‚°è¨­è¨ˆã«ã‚ˆã‚Šã€NCRã¯BSã®æ­»è§’ã‚’ã‚«ãƒãƒ¼
    http://arxiv.org/abs/2403.09601v1
    
    A comprehensive study of orbital evolution of LMC X-4: Existence of a second derivative of the orbital period
    è«–æ–‡ã®ã‚¿ã‚¤ãƒˆãƒ«: LMC X-4ã®è»Œé“é€²åŒ–ã®åŒ…æ‹¬çš„ç ”ç©¶: è»Œé“å‘¨æœŸã®2æ¬¡å°é–¢æ•°ã®å­˜åœ¨
    
    - LMC X-4ã®è»Œé“å‘¨æœŸãŒ0.8 Myrã®æ™‚é–“ã‚¹ã‚±ãƒ¼ãƒ«ã§é€²åŒ–ã—ã¦ã„ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚
    - ä»Šå›åˆã‚ã¦ã€LMC X-4ã«ãŠã„ã¦è»Œé“å‘¨æœŸã®2æ¬¡å°é–¢æ•°ã®å­˜åœ¨ãŒç¢ºèªã•ã‚ŒãŸã€‚
    - ä¸­é–“é£Ÿæ™‚åˆ»ãƒ‡ãƒ¼ã‚¿ã¨ãƒ‘ãƒ«ã‚¹ã‚¿ã‚¤ãƒŸãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦å¾—ã‚‰ã‚ŒãŸè»Œé“é€²åŒ–ã®ç‹¬ç«‹ã—ãŸè§£æã¯ä¸€è‡´ã—ã€é€£æ˜Ÿç³»ã®é›¢å¿ƒç‡ã«0.009ã®ä¸Šé™ã‚’è¨­å®šã—ãŸã€‚
    http://arxiv.org/abs/2403.09595v1
    
    DungeonMaker: Embedding Tangible Creation and Destruction in Hybrid Board Games through Personal Fabrication Technology
    DungeonMaker: ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒœãƒ¼ãƒ‰ã‚²ãƒ¼ãƒ ã«ãŠã‘ã‚‹ç‰©ç†çš„å‰µé€ ã¨ç ´å£Šã®çµ„ã¿è¾¼ã¿ã‚’é€šã˜ãŸå€‹äººè£½ä½œæŠ€è¡“
    
    - DungeonMakerã¯ç‰©ç†çš„è¦ç´ ã¨ãƒ‡ã‚¸ã‚¿ãƒ«ã‚²ãƒ¼ãƒ è¦ç´ ã‚’çµã³ã¤ã‘ã€ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ä½œæˆç‰©ã‚’è©•ä¾¡ã™ã‚‹
    - ãƒ¬ãƒ¼ã‚¶ãƒ¼ã‚«ãƒƒã‚¿ãƒ¼ã«ãƒ‡ã‚¸ã‚¿ãƒ«ã‚²ãƒ¼ãƒ ç›¤ã‚’æŠ•å½±ã—ã€ãƒ•ã‚£ã‚®ãƒ¥ã‚¢ã‚’ç‰©ç†çš„ã«ãƒ€ãƒ¡ãƒ¼ã‚¸ã‚’ä¸ãˆã‚‹
    - è©•ä¾¡çµæœã¯DungeonMakerãŒæ¥½ã—ã„ä½“é¨“ã‚’æä¾›ã—ã€ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ãƒ•ã‚£ã‚®ãƒ¥ã‚¢ã¸ã®ã¤ãªãŒã‚Šã‚’ã‚µãƒãƒ¼ãƒˆã—ã€è£½ä½œã«èˆˆå‘³ã‚’æŒã¤å¯èƒ½æ€§ã‚’ç¤ºå”†
    http://arxiv.org/abs/2403.09592v1
    
    Are you a robot? Detecting Autonomous Vehicles from Behavior Analysis
    ãƒ­ãƒœãƒƒãƒˆã‹ã©ã†ã‹ã‚’è‡ªå‹•çš„ã«æ¤œå‡ºã™ã‚‹ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
    
    - è‡ªå‹•è»ŠãŒè‡ªå¾‹è»Šä¸¡ã‹ã©ã†ã‹ã‚’ã‚«ãƒ¡ãƒ©ç”»åƒã¨çŠ¶æ…‹æƒ…å ±ã‚’æ´»ç”¨ã—ã¦è‡ªå‹•çš„ã«ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã™ã‚‹å¿…è¦æ€§
    - è»Šä¸¡åŒå£«ã®å”åŠ›ã«åŸºã¥ã„ã¦ãƒ‡ãƒ¼ã‚¿å…±æœ‰ã—ã€æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦è‡ªå¾‹è»Šä¸¡ã‚’è­˜åˆ¥ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆ
    - ãƒ“ãƒ‡ã‚ªã‚¯ãƒªãƒƒãƒ—ã®åˆ†æã«ã‚ˆã‚Šã€è‡ªå‹•çš„ã«80%ã®ç²¾åº¦ã§è‡ªå¾‹è»Šä¸¡ã¨äººé–“é‹è»¢è»Šä¸¡ã‚’è­˜åˆ¥å¯èƒ½ã§ã‚ã‚Šã€çŠ¶æ…‹æƒ…å ±ãŒã‚ã‚Œã°93%ã«å‘ä¸Šã™ã‚‹ã€‚
    http://arxiv.org/abs/2403.09571v1
    --------------------------------------------------
    Search String 2: RAG evaluation methods
    
    SCP-Diff: Photo-Realistic Semantic Image Synthesis with Spatial-Categorical Joint Prior
    SCP-Diff: ç©ºé–“ã‚«ãƒ†ã‚´ãƒªãƒ¼å…±åŒäº‹å‰åˆ†å¸ƒã‚’ç”¨ã„ãŸå†™çœŸå®Ÿæ„Ÿçš„ãªæ„å‘³ç”»åƒåˆæˆ
    
    - ç¾è¡Œã®æœ€è‰¯æ‰‹æ³•ã¯GANã«åŸºã¥ããŒã€æœ›ã¾ã—ã„å“è³ªã«ã¯è‡³ã£ã¦ã„ãªã„ã€‚
    - ControlNetã®çµæœã«ãŠã„ã¦ä¸»ã«å•é¡Œã¨ãªã‚‹ã®ã¯ã€å¥‡å¦™ãªã‚µãƒ–æ§‹é€ ã¨æ„å‘³çš„ãƒã‚¹ã‚¯ã¨ã®ä¸æ•´åˆã€‚
    - SCP-Diffã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ã€ç©ºé–“ã€ã‚«ãƒ†ã‚´ãƒªãƒ¼ã€ãã—ã¦æ–°è¦ãªç©ºé–“-ã‚«ãƒ†ã‚´ãƒªãƒ¼å…±åŒäº‹å‰åˆ†å¸ƒã‚’åŒ…æ‹¬ã—ã€å„ªã‚ŒãŸçµæœã‚’é”æˆã€‚
    http://arxiv.org/abs/2403.09638v1
    
    GaussianGrasper: 3D Language Gaussian Splatting for Open-vocabulary Robotic Grasping
    GaussianGrasper: 3Dè¨€èªã‚¬ã‚¦ã‚¹ã‚¹ãƒ—ãƒ©ãƒƒãƒ†ã‚£ãƒ³ã‚°ã«ã‚ˆã‚‹ã‚ªãƒ¼ãƒ—ãƒ³ãƒœã‚­ãƒ£ãƒ–ãƒ©ãƒªãƒ¼ãƒ»ãƒ­ãƒœãƒ†ã‚£ãƒƒã‚¯ã‚°ãƒ©ã‚¹ãƒ”ãƒ³ã‚°
    
    - 3Dã‚·ãƒ¼ãƒ³ã‚’ã‚¬ã‚¦ã‚¹ãƒ—ãƒªãƒŸãƒ†ã‚£ãƒ–ã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã¨ã—ã¦è¡¨ç¾
    - Efficient Feature Distillation (EFD)ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ææ¡ˆ
    - ãƒãƒ¼ãƒãƒ«ã‚¬ã‚¤ãƒ‰ã‚°ãƒ©ã‚¹ãƒ—ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã«ã‚ˆã‚‹æœ€é©ãªã‚°ãƒ©ã‚¹ãƒ—ä½ç½®ã®é¸æŠ
    http://arxiv.org/abs/2403.09637v1
    
    Dynamic Memory Compression: Retrofitting LLMs for Accelerated Inference
    å‹•çš„ãƒ¡ãƒ¢ãƒªåœ§ç¸®ï¼šé«˜é€Ÿæ¨è«–ã®ãŸã‚ã®LLMã®æ”¹é€ 
    
    - æ¨è«–æ™‚ã«ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã§ã‚­ãƒ¼ãƒ»ãƒãƒªãƒ¥ãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’åœ§ç¸®ã™ã‚‹æ–¹æ³•
    - ç•°ãªã‚‹ãƒ˜ãƒƒãƒ‰ã‚„ãƒ¬ã‚¤ãƒ¤ãƒ¼ã§ç•°ãªã‚‹åœ§ç¸®ç‡ã‚’é©ç”¨ã™ã‚‹ã“ã¨ã‚’å­¦ç¿’
    - ã‚­ãƒ£ãƒƒã‚·ãƒ¥åœ§ç¸®ç‡ã‚’æœ€å¤§4å€ã«ã—ã¦ã‚‚å…ƒã®æ€§èƒ½ã‚’ç¶­æŒ
    http://arxiv.org/abs/2403.09636v1
    
    OneTracker: Unifying Visual Object Tracking with Foundation Models and Efficient Tuning
    OneTracker: Foundationãƒ¢ãƒ‡ãƒ«ã¨åŠ¹ç‡çš„ãªãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã§ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã‚’çµ±ä¸€
    
    - åˆã‚ã«Foundation Trackerã§å¤§è¦æ¨¡ãªäº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è¡Œã„ã€å®‰å®šã—ãŸèƒ½åŠ›ã‚’ç²å¾—
    - Prompt Trackerã¯Foundation Trackerã‚’å‡çµã—ã€è¿½åŠ ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª¿æ•´ã—ã¦RGB+Xãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã‚¿ã‚¹ã‚¯ã«é©ã—ãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŠ¹ç‡çš„ãªfine-tuningã‚’å®Ÿç¾
    - OneTrackerã¯ä»–ã®ãƒ¢ãƒ‡ãƒ«ã‚’å‡Œé§•ã—ã€11ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’é€šã˜ã¦6ã¤ã®äººæ°—ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã‚¿ã‚¹ã‚¯ã§æœ€å…ˆç«¯ã®æ€§èƒ½ã‚’é”æˆ
    http://arxiv.org/abs/2403.09634v1
    
    Holo-Relighting: Controllable Volumetric Portrait Relighting from a Single Image
    Holo-Relighting: å˜ä¸€ç”»åƒã‹ã‚‰ã®åˆ¶å¾¡å¯èƒ½ãªãƒœãƒªãƒ¥ãƒ¼ãƒ¡ãƒˆãƒªãƒƒã‚¯è‚–åƒå†™çœŸã®ãƒªãƒ©ã‚¤ãƒ†ã‚£ãƒ³ã‚°
    
    - 1æšã®ç”»åƒã‹ã‚‰æ–°ã—ã„è¦–ç‚¹ã¨ç…§æ˜ã‚’åˆæˆã™ã‚‹ãƒœãƒªãƒ¥ãƒ¼ãƒ¡ãƒˆãƒªãƒƒã‚¯ãƒªãƒ©ã‚¤ãƒ†ã‚£ãƒ³ã‚°æ‰‹æ³•
    - ãƒ˜ãƒƒãƒ‰ãƒãƒ¼ã‚ºã«åŸºã¥ã„ãŸç…§æ˜åŠ¹æœã‚’å¯èƒ½ã«ã™ã‚‹æ¡ä»¶ä»˜ãã®ãƒªãƒ©ã‚¤ãƒ†ã‚£ãƒ³ã‚°ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
    - ç‰©ç†çš„ãªç…§æ˜ã®äº‹å‰çŸ¥è­˜ãªã—ã§è¤‡é›‘ãªéãƒ©ãƒ³ãƒãƒ¼ãƒ†ã‚£ã‚¢ãƒ³ç…§æ˜åŠ¹æœã‚’ç”Ÿæˆ
    http://arxiv.org/abs/2403.09632v1
    
    Quiet-STaR: Language Models Can Teach Themselves to Think Before Speaking
    Quiet-STaR: è¨€èªãƒ¢ãƒ‡ãƒ«ã¯è©±ã™å‰ã«è€ƒãˆã‚‹ã“ã¨ã‚’è‡ªå·±å­¦ç¿’ã§ãã‚‹
    
    - STaRã§ã¯ã€è³ªå•å¿œç­”ã®å°‘ãªã„ä¾‹ã‹ã‚‰åˆç†çš„ãªè€ƒãˆæ–¹ã‚’å­¦ã¶ãŒã€Quiet-STaRã§ã¯æ–‡è„ˆã«å¿œã˜ã¦ç†ç”±ã‚’ç”Ÿæˆã™ã‚‹ã‚ˆã†ã«å­¦ç¿’ã€‚
    - è¨ˆç®—ã‚³ã‚¹ãƒˆã€å†…éƒ¨æ€è€ƒã®ç”Ÿæˆæ–¹æ³•ã€å€‹ã€…ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¶…ãˆãŸäºˆæ¸¬ã®å¿…è¦æ€§ãªã©ã€ä¸»è¦ãªèª²é¡Œã«å¯¾å‡¦ã™ã‚‹ã€‚
    - ç„¡Fine-tuningã§GSM8Kã¨CommonsenseQAã§ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆæ”¹å–„ã‚’é”æˆã—ã€è‡ªç„¶æ–‡ã®é›£ã—ã„ãƒˆãƒ¼ã‚¯ãƒ³ã®Perplexityã‚‚æ”¹å–„ã€‚
    http://arxiv.org/abs/2403.09629v1
    
    Video Mamba Suite: State Space Model as a Versatile Alternative for Video Understanding
    ãƒ“ãƒ‡ã‚ªç†è§£ã«ãŠã‘ã‚‹çŠ¶æ…‹ç©ºé–“ãƒ¢ãƒ‡ãƒ«ã®æ±ç”¨çš„ä»£æ›¿æ‰‹æ®µ
    
    - ãƒ“ãƒ‡ã‚ªãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã«ãŠã„ã¦ã€çŠ¶æ…‹ç©ºé–“ãƒ¢ãƒ‡ãƒ«ï¼ˆMambaï¼‰ã¯é•·ã„ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã®ãƒ¢ãƒ‡ãƒªãƒ³ã‚°æˆåŠŸã‚’æ‹¡å¼µã™ã‚‹æœ‰æœ›ãªç‰¹æ€§ã‚’ç¤ºã™ã€‚
    - 14ã®ãƒ¢ãƒ‡ãƒ«/ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ã‚‰ãªã‚‹Video Mamba Suiteã‚’å°å‡ºã—ã€12ã®ãƒ“ãƒ‡ã‚ªç†è§£ã‚¿ã‚¹ã‚¯ã§è©•ä¾¡ã€‚
    - Mambaã¯ãƒ“ãƒ‡ã‚ªã®ã¿ãªã‚‰ãšãƒ“ãƒ‡ã‚ª-è¨€èªã‚¿ã‚¹ã‚¯ã§ã‚‚å¼·åŠ›ãªæ½œåœ¨èƒ½åŠ›ã‚’ç¤ºã—ã€æœ‰æœ›ãªåŠ¹ç‡-æ€§èƒ½ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’ç¤ºã™ã€‚
    http://arxiv.org/abs/2403.09626v1
    
    Make-Your-3D: Fast and Consistent Subject-Driven 3D Content Generation
    Make-Your-3D: é«˜å“è³ªã‹ã¤ä¸€è²«ã—ãŸä¸»é¡Œé§†å‹•å‹3Dã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆ
    
    - æ—¢å­˜ã®3Dç”Ÿæˆæ‰‹æ³•ã§ã¯å¤šæ§˜ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”¨ã„ãŸä¸»é¡Œé§†å‹•å‹3Dã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ä½œæˆãŒå›°é›£ã§ã‚ã‚‹
    - Make-Your-3Dã¯ãŸã£ãŸ1æšã®ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆèª¬æ˜ã‹ã‚‰5åˆ†ä»¥å†…ã§é«˜å“è³ªã‹ã¤ä¸€è²«ã—ãŸ3Dã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”Ÿæˆã™ã‚‹
    - è‘—è€…ã‚‰ã®æ‰‹æ³•ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®åˆ†å¸ƒã‚’èª¿å’Œã•ã›ã‚‹ã“ã¨ã§ã€é«˜å“è³ªã§ä¸»é¡Œã«ç‰¹åŒ–ã—ãŸ3Dã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”Ÿæˆå¯èƒ½
    http://arxiv.org/abs/2403.09625v1
    
    Score-Guided Diffusion for 3D Human Recovery
    Score-Guided Diffusionã‚’ç”¨ã„ãŸ3Dãƒ’ãƒ¥ãƒ¼ãƒãƒ³ãƒªã‚«ãƒãƒªãƒ¼
    
    - ScoreHMRã¯ã€ç”»åƒè¦³æ¸¬ã«å¯¾ã—ã¦å¾—ã‚‰ã‚Œã‚‹ã‚¹ã‚³ã‚¢ã®ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã‚’ä»‹ã—ã¦ã€æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®æ½œåœ¨ç©ºé–“ã§ã®ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã«ã‚ˆã‚Šã€3Dãƒ’ãƒ¥ãƒ¼ãƒãƒ³ãƒãƒ¼ã‚ºã¨å½¢çŠ¶ã®å†æ§‹ç¯‰ã®é€†å•é¡Œã‚’è§£æ±ºã™ã‚‹æ‰‹æ³•ã€‚
    - ScoreHMRã¯ã€å†ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒä¸è¦ãªã‚¿ã‚¹ã‚¯éç‰¹åŒ–ã®æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚Šã€æ§˜ã€…ãªã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«ãŠã‘ã‚‹é€†å•é¡Œã‚’åŠ¹æœçš„ã«è§£æ±ºã™ã‚‹ã€‚
    - ScoreHMRã¯ã€ã‚·ãƒ³ã‚°ãƒ«ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¢ãƒ‡ãƒ«é©åˆã€è¤‡æ•°ã®éã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ“ãƒ¥ãƒ¼ã‹ã‚‰ã®å†æ§‹ç¯‰ã€ãƒ“ãƒ‡ã‚ªã‚·ãƒ¼ã‚±ãƒ³ã‚¹å†…ã®äººç‰©å†æ§‹ç¯‰ã¨ã„ã£ãŸ3ã¤ã®è¨­å®š/ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«ãŠã„ã¦ã€äººæ°—ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€é©åŒ–ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’å¸¸ã«ä¸Šå›ã‚‹ã€‚
    http://arxiv.org/abs/2403.09623v1
    
    Glyph-ByT5: A Customized Text Encoder for Accurate Visual Text Rendering
    Glyph-ByT5: æ­£ç¢ºãªè¦–è¦šãƒ†ã‚­ã‚¹ãƒˆãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã®ãŸã‚ã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€
    
    - ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã«å¿…è¦ãªè¦ä»¶: æ–‡å­—èªè­˜ã¨ã‚°ãƒªãƒ•ã¨ã®æ•´åˆæ€§
    - Glyph-ByT5ã¯ByT5ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã‚’å¾®èª¿æ•´ã—ã€ã‚°ãƒªãƒ•-ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã—ã¦ä½œæˆ
    - Glyph-SDXLãƒ¢ãƒ‡ãƒ«ã®å°å…¥ã«ã‚ˆã‚Šã€ãƒ‡ã‚¶ã‚¤ãƒ³ç”»åƒç”Ÿæˆã«ãŠã‘ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã®æ­£ç¢ºæ€§ãŒé£›èºçš„ã«å‘ä¸Š
    http://arxiv.org/abs/2403.09622v1
    --------------------------------------------------
    Red Amber Green assessment techniques
    
    GaussianGrasper: 3D Language Gaussian Splatting for Open-vocabulary Robotic Grasping
    GaussianGrasper: 3Dè¨€èªã‚¬ã‚¦ã‚¹ã‚¹ãƒ—ãƒ©ãƒƒãƒ†ã‚£ãƒ³ã‚°ã«ã‚ˆã‚‹ã‚ªãƒ¼ãƒ—ãƒ³ãƒœã‚­ãƒ£ãƒ–ãƒ©ãƒªãƒ¼ãƒ­ãƒœãƒƒãƒˆã‚°ãƒ©ã‚¹ãƒ”ãƒ³ã‚°
    
    - ã‚¬ã‚¦ã‚¹ã‚¹ãƒ—ãƒ©ãƒƒãƒ†ã‚£ãƒ³ã‚°ã‚’ä½¿ç”¨ã—ã¦ã€ã‚·ãƒ¼ãƒ³ã‚’ã‚¬ã‚¦ã‚¹åŸç†ã®é›†åˆã¨ã—ã¦æ˜ç¤ºçš„ã«è¡¨ç¾
    - Efficient Feature Distillation (EFD) ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å°å…¥ã—ã€åŠ¹ç‡çš„ã‹ã¤æ­£ç¢ºã«è¨€èªåŸ‹ã‚è¾¼ã¿ã‚’æŠ½å‡º
    - ãƒªã‚¢ãƒ«ãƒ¯ãƒ¼ãƒ«ãƒ‰ã®å®Ÿé¨“ã«ã‚ˆã‚Šã€GaussianGrasperãŒè¨€èªæŒ‡ç¤ºã«ã‚ˆã‚‹ç‰©ä½“æ´ã¿ã‚’å¯èƒ½ã«ã—ã€æ–°ã—ã„è§£æ±ºç­–ã‚’æä¾›
    http://arxiv.org/abs/2403.09637v1
    
    Holo-Relighting: Controllable Volumetric Portrait Relighting from a Single Image
    Holo-Relighting: å˜ä¸€ç”»åƒã‹ã‚‰ã®åˆ¶å¾¡å¯èƒ½ãªä½“ç©ãƒãƒ¼ãƒˆãƒ¬ãƒ¼ãƒˆç…§æ˜
    
    - 3D GANï¼ˆEG3Dï¼‰ã‚’åˆ©ç”¨ã—ã¦å…¥åŠ›ãƒãƒ¼ãƒˆãƒ¬ãƒ¼ãƒˆã‹ã‚‰ã‚¸ã‚ªãƒ¡ãƒˆãƒªã¨å¤–è¦³ã‚’å†æ§‹ç¯‰ã—ã€3Dæ„ŸçŸ¥ç‰¹å¾´ã®å½¢ã§ç…§æ˜ã‚’ç”Ÿæˆã™ã‚‹ã€‚
    - ä¸‰é¢ä½“å½¢å¼ã®ãƒªãƒ©ã‚¤ãƒˆ3Dè¡¨ç¾ã‚’äºˆæ¸¬ã—ã€ä»»æ„ã®è¦–ç‚¹ã«ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã§ãã‚‹ã€‚
    - ãƒ˜ãƒƒãƒ‰ãƒãƒ¼ã‚ºã«å¿œã˜ãŸãƒ©ã‚¤ãƒ†ã‚£ãƒ³ã‚°åŠ¹æœã‚’å¯èƒ½ã«ã—ã€ç‰©ç†çš„ãªãƒ©ã‚¤ãƒ†ã‚£ãƒ³ã‚°å…ˆè¡ŒçŸ¥è­˜ã‚’ä½¿ç”¨ã›ãšã«è¤‡é›‘ãªéãƒ©ãƒ³ãƒãƒ¼ãƒˆç…§æ˜åŠ¹æœã‚’ç”Ÿæˆã§ãã‚‹ã€‚
    http://arxiv.org/abs/2403.09632v1
    
    Quiet-STaR: Language Models Can Teach Themselves to Think Before Speaking
    Quiet-STaR: è¨€èªãƒ¢ãƒ‡ãƒ«ã¯è©±ã™å‰ã«è€ƒãˆã‚‹ã“ã¨ã‚’è‡ªå·±å­¦ç¿’ã§ãã‚‹
    
    - STaRã§ã¯ã€å°‘æ•°ã®ä¾‹ã‹ã‚‰åˆç†çš„ãªè€ƒãˆæ–¹ã‚’å­¦ã³ã€æ­£ã—ã„ç­”ãˆã«è‡³ã‚‹éç¨‹ã‚’å­¦ç¿’
    - Quiet-STaRã§ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ãŒæœªæ¥ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’èª¬æ˜ã™ã‚‹ãŸã‚ã«rationalesã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã‚’å­¦ç¿’
    - ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬èƒ½åŠ›ã‚’æ”¹å–„ã—ã€é›£ã—ã„è³ªå•ã«ç›´æ¥ç­”ãˆã‚‹èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ zero-shot æ”¹å–„ã‚’é”æˆ
    http://arxiv.org/abs/2403.09629v1
    
    Video Mamba Suite: State Space Model as a Versatile Alternative for Video Understanding
    ãƒ“ãƒ‡ã‚ªç†è§£ã®ãŸã‚ã®çŠ¶æ…‹ç©ºé–“ãƒ¢ãƒ‡ãƒ«ã®æ±ç”¨çš„ä»£æ›¿æ‰‹æ®µ
    
    - Mambaã¯é•·ã„ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã®æˆåŠŸã‚’ãƒ“ãƒ‡ã‚ªãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã«æ‹¡å¼µã™ã‚‹æœ‰æœ›ãªç‰¹æ€§ã‚’ç¤ºã™ã€‚
    - 14ã®ãƒ¢ãƒ‡ãƒ«/ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã§æ§‹æˆã•ã‚ŒãŸãƒ“ãƒ‡ã‚ªMamba Suiteã®ææ¡ˆã€‚
    - ãƒ“ãƒ‡ã‚ªã®ã¿ãŠã‚ˆã³ãƒ“ãƒ‡ã‚ª-è¨€èªã‚¿ã‚¹ã‚¯ã®ä¸¡æ–¹ã§Mambaã®å¼·åŠ›ãªãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«ã¨æœ‰æœ›ãªåŠ¹ç‡æ€§èƒ½ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ãŒæ˜ã‚‰ã‹ã«ã•ã‚ŒãŸã€‚
    http://arxiv.org/abs/2403.09626v1
    
    Physically motivated improvements of Variational Quantum Eigensolvers
    ç‰©ç†çš„å‹•æ©Ÿã«åŸºã¥ãå¤‰åˆ†é‡å­å›ºæœ‰å€¤ã‚½ãƒ«ãƒãƒ¼ã®æ”¹å–„
    
    - ADAPT-VQEã®åŠ¹ç‡å‘ä¸Šã‚’å›³ã‚‹ãŸã‚ã«ã€çŠ¶æ…‹ã®æº–å‚™ã‚’æœ€é©åŒ–ã—ã€å›è·¯ã‚’æµ…ãã™ã‚‹ã€‚
    - é›»å­æ§‹é€ ç†è«–ã‹ã‚‰å¾—ãŸçŸ¥è¦‹ã‚’æ´»ç”¨ã—ã¦ã€æ­£ç¢ºãªè§£ã«åæŸã‚’æ—©ã‚ã‚‹ã€‚
    - H4ãƒ¢ãƒ‡ãƒ«ã‚„æ°´åˆ†å­ã«ãŠã„ã¦ã€ç‰©ç†çš„å‹•æ©Ÿã«åŸºã¥ãæˆ¦ç•¥ãŒADAPT-VQEã®åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’å®Ÿè¨¼ã€‚
    http://arxiv.org/abs/2403.09624v1
    
    Score-Guided Diffusion for 3D Human Recovery
    Score-Guided Diffusion for 3D Human Recovery
    
    - 3Däººç‰©ã®å§¿å‹¢ã¨å½¢çŠ¶å†æ§‹ç¯‰ã®é€†å•é¡Œã‚’è§£æ±ºã™ã‚‹Score-Guided Human Mesh Recoveryï¼ˆScoreHMRï¼‰ã‚’ææ¡ˆ
    - ç”»åƒè¦³æ¸¬ã«äººä½“ãƒ¢ãƒ‡ãƒ«ã‚’é©åˆã•ã›ã‚‹é€†å•é¡Œã‚’æœ€é©åŒ–æŠ€è¡“ã§è§£æ±ºã™ã‚‹ä»£ã‚ã‚Šã«ã€å¾—ç‚¹ã«ã‚ˆã‚‹èª˜å°ã‚’ç”¨ã„ãŸæ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®æ½œåœ¨ç©ºé–“ã§ç”»åƒè¦³æ¸¬ã¨ã®æ•´åˆæ€§ã‚’å®Ÿç¾
    - ScoreHMRã¯æœ€é©åŒ–ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’å¸¸ã«ä¸Šå›ã‚Šã€ç•°ãªã‚‹ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§é€†å•é¡Œã‚’åŠ¹æœçš„ã«è§£æ±ºå¯èƒ½ã€‚
    http://arxiv.org/abs/2403.09623v1
    
    Minimax Optimal and Computationally Efficient Algorithms for Distributionally Robust Offline Reinforcement Learning
    åˆ†å¸ƒçš„ã«å …ç‰¢ãªã‚ªãƒ•ãƒ©ã‚¤ãƒ³å¼·åŒ–å­¦ç¿’ã®ãŸã‚ã®ãƒŸãƒ‹ãƒãƒƒã‚¯ã‚¹æœ€é©ã‹ã¤è¨ˆç®—åŠ¹ç‡çš„ãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
    
    - ç’°å¢ƒã®æ‘‚å‹•ã«å¯¾ã—ã¦å …ç‰¢ãªãƒãƒªã‚·ãƒ¼è¨“ç·´ã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã€é–¢æ•°è¿‘ä¼¼ãŒå¿…è¦ã€‚
    - ãƒ¢ãƒ‡ãƒ«ã®ä¸ç¢ºå®Ÿæ€§ã«ã‚ˆã‚Šã€é–¢æ•°è¿‘ä¼¼ã«æœ¬è³ªçš„ãªéç·šå½¢æ€§ã¨è¨ˆç®—è² è·ãŒå°å…¥ã•ã‚Œã€ç‹¬è‡ªã®èª²é¡Œã‚’ã‚‚ãŸã‚‰ã™ã€‚
    - å …ç‰¢ãªã‚ªãƒ•ãƒ©ã‚¤ãƒ³å¼·åŒ–å­¦ç¿’ã«ãŠã‘ã‚‹é–¢æ•°è¿‘ä¼¼ã¯ã€é€šå¸¸ã®ã‚ªãƒ•ãƒ©ã‚¤ãƒ³å¼·åŒ–å­¦ç¿’ã‚ˆã‚Šã‚‚æœ¬è³ªçš„ã«ç•°ãªã‚Šã€ãŠãã‚‰ãé›£ã—ã„ã€‚
    http://arxiv.org/abs/2403.09621v1
    
    PosSAM: Panoptic Open-vocabulary Segment Anything
    PosSAM: Panoptic Open-vocabulary Segment Anything
    
    - SAMã®é™ç•Œã‚’è§£æ¶ˆã—ã€ã‚¯ãƒ©ã‚¹æƒ…å ±ã®èªè­˜ã¨éå‰°ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ”¹å–„
    - LDPãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å°å…¥ã—ã€ã‚ªãƒ¼ãƒ—ãƒ³ãƒœã‚­ãƒ£ãƒ–ãƒ©ãƒªãƒ¼åˆ†é¡ã‚’ææ¡ˆ
    - MASEã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ä½¿ç”¨ã—ã¦ãƒã‚¹ã‚¯ã®å“è³ªã‚’å‘ä¸Šã€æ€§èƒ½ã‚’å‘ä¸Š
    http://arxiv.org/abs/2403.09620v1
    
    Optimistic Verifiable Training by Controlling Hardware Nondeterminism
    æœ€é©åŒ–ã•ã‚ŒãŸæ¤œè¨¼å¯èƒ½ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ–¹æ³•
    
    - ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã®éæ±ºå®šæ€§ã‚’åˆ¶å¾¡ã™ã‚‹ã“ã¨ã§ä¿¡é ¼æ€§ã®é«˜ã„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿç¾
    - NVIDIA GPUã‚’ä½¿ç”¨ã—ã¦FP32ç²¾åº¦ã§ResNet-50ã¨GPT-2ãƒ¢ãƒ‡ãƒ«ã®æ­£ç¢ºãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°è¤‡è£½ã‚’é”æˆ
    - è¨¼æ˜ãƒ™ãƒ¼ã‚¹ã®ã‚·ã‚¹ãƒ†ãƒ ã«æ¯”ã¹ã¦ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã¨æ™‚é–“ã‚³ã‚¹ãƒˆã‚’å¤§å¹…ã«å‰Šæ¸›
    http://arxiv.org/abs/2403.09603v1
    
    Network-Controlled Repeater -- An Introduction
    ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ¶å¾¡ä¸­ç¶™å™¨--å°å…¥
    
    - 5Gç„¡ç·šã‚»ãƒ«ãƒ©ãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§ã¯ã€ãƒŸãƒªæ³¢ã‚¹ãƒšã‚¯ãƒˆãƒ«ãŒã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã€ä¿¡é ¼æ€§ã€é…å»¶ãªã©ã®å‘ä¸Šã‚’ã‚‚ãŸã‚‰ã™å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚
    - ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ¶å¾¡ä¸­ç¶™å™¨(NCR)ã¯ã€ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ã®å½±éŸ¿ã‚’ä½æ¸›ã—ã€ã‚«ãƒãƒ¬ãƒƒã‚¸å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã®æ‰‹æ³•ã¨ã—ã¦æ³¨ç›®ã•ã‚Œã¦ã„ã‚‹ã€‚
    - 3GPP Rel-18ã§åˆæ„ã•ã‚ŒãŸNCRã®ä¸»ãªä»•æ§˜ã‚’æç¤ºã—ã€éƒ½å¸‚ã‚·ãƒŠãƒªã‚ªã§ã®NCRå±•é–‹ã‚’åˆ†æã—ã€ãã®æ€§èƒ½ã‚’æ¯”è¼ƒã—ã¦ã„ã‚‹ã€‚
    http://arxiv.org/abs/2403.09601v1
    --------------------------------------------------
    industry applications
    
    3D-VLA: A 3D Vision-Language-Action Generative World Model
    3D-VLA: 3Dãƒ“ã‚¸ãƒ§ãƒ³ãƒ»è¨€èªãƒ»ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç”Ÿæˆãƒ¯ãƒ¼ãƒ«ãƒ‰ãƒ¢ãƒ‡ãƒ«
    
    - ç¾åœ¨ã®VLAãƒ¢ãƒ‡ãƒ«ã¯2Då…¥åŠ›ã«ä¾å­˜ã—ã¦ãŠã‚Šã€3Dç‰©ç†ä¸–ç•Œã¨ã®çµ±åˆãŒä¸è¶³ã—ã¦ã„ã‚‹ã€‚
    - 3D-VLAã¯3DçŸ¥è¦šã€æ¨è«–ã€ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ãƒªãƒ³ã‚¯ã™ã‚‹æ–°ã—ã„çµ„ã¿è¾¼ã¿åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã‚’å°å…¥ã™ã‚‹ã€‚
    - 3D-VLAã¯å¤šå¤§ãª3Dé–¢é€£æƒ…å ±ã‹ã‚‰ãªã‚‹å¤§è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã¦å®Ÿé¨“ã‚’è¡Œã„ã€å®Ÿä¸–ç•Œã®å¿œç”¨ã«ãŠã‘ã‚‹æ½œåœ¨èƒ½åŠ›ã‚’ç¤ºã™ã€‚
    http://arxiv.org/abs/2403.09631v1
    
    Generalized Predictive Model for Autonomous Driving
    è‡ªå‹•é‹è»¢å‘ã‘æ±ç”¨äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«
    
    - å¤§è¦æ¨¡ãƒ“ãƒ‡ã‚ªäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚’å°å…¥
    - Webã‹ã‚‰å¤§é‡ãƒ‡ãƒ¼ã‚¿å–å¾—ã—ã€é«˜å“è³ªãªãƒ†ã‚­ã‚¹ãƒˆã¨ãƒšã‚¢ã«
    - GenADã¯æ™‚ç©ºé–“æ¨è«–ãƒ–ãƒ­ãƒƒã‚¯ã‚’æŒã¡ã€ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã§æ±ç”¨æ€§ã‚’ç¤ºã™
    http://arxiv.org/abs/2403.09630v1
    
    Score-Guided Diffusion for 3D Human Recovery
    Score-Guided Diffusion for 3D Human Recovery
    
    - 3Däººä½“å§¿å‹¢ã¨å½¢çŠ¶ã®é€†å•é¡Œã‚’è§£æ±ºã™ã‚‹ScoreHMRã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
    - æ½œåœ¨ç©ºé–“ã§ã‚¹ã‚³ã‚¢ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã‚’ä½¿ç”¨ã—ã¦ç”»åƒè¦³æ¸¬ã¨ã®æ•´åˆæ€§ã‚’é”æˆ
    - ç”»åƒã‹ã‚‰ã®æ¡ä»¶ä»˜ãåˆ†å¸ƒã‚’æ‰ãˆãŸæ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚Šã€é€†å•é¡Œã‚’è§£æ±º
    http://arxiv.org/abs/2403.09623v1
    
    Compute-first optical detection for noise-resilient visual perception
    å…‰å­¦ä¿¡å·å‡¦ç†ã«ã‚ˆã‚‹ãƒã‚¤ã‚ºè€æ€§è¦–è¦šçŸ¥è¦š
    
    - ãƒã‚¤ã‚ºã®å½±éŸ¿ã‚’å—ã‘ã‚„ã™ã„çŠ¶æ³ã«ãŠã„ã¦ã€å…‰å­¦ä¿¡å·å‡¦ç†ã‚’æ¤œå‡ºå‰ã«è¡Œã†ã“ã¨ã§ã€è¦–è¦šçŸ¥è¦šã‚¿ã‚¹ã‚¯ã®æ€§èƒ½å‘ä¸ŠãŒå¯èƒ½ã€‚
    - ç©ºé–“çš„ã«å…‰å­¦ä¿¡å·ã‚’å†é…åˆ†ã™ã‚‹ã“ã¨ã§ã€MNISTåˆ†é¡ãªã©ã®è¦–è¦šèªè­˜ã‚¿ã‚¹ã‚¯ã®æ¤œå‡ºãƒã‚¤ã‚ºè€æ€§ãŒå‘ä¸Šã™ã‚‹ã€‚
    - å®Ÿè£…å¯èƒ½ãªéã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ãƒˆã‚¤ãƒ¡ãƒ¼ã‚¸ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã«ãŠã„ã¦ã€ä¿¡å·æ¿ƒåº¦ã¨ãƒã‚¤ã‚ºè€æ€§ã®é–¢ä¿‚ã‚’å®šé‡çš„ã«åˆ†æã—ã€ææ¡ˆæ‰‹æ³•ã®æœ‰åŠ¹æ€§ã‚’ç¤ºã—ãŸã€‚
    http://arxiv.org/abs/2403.09612v1
    
    Signal Recovery with Proximal Comixtures
    ä¿¡å·å›å¾©ã«ãŠã‘ã‚‹Proximal Comixtures
    
    - æå¤±é–¢æ•°ã¨ç·šå½¢æ¼”ç®—å­ã‚’æ··åˆã—ãŸproximal comixturesã®ä»£æ›¿ãƒ•ã‚©ãƒ¼ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ææ¡ˆ
    - çµæœé–¢æ•°ã®è¿‘æ¥ä½œç”¨ç´ ãŒæ˜ç¤ºçš„ã«è¨ˆç®—å¯èƒ½ãªæ“ä½œ
    - ç”»åƒå›å¾©ã¨æ©Ÿæ¢°å­¦ç¿’ã¸ã®comixtureãƒ•ã‚©ãƒ¼ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®æ©æµ
    http://arxiv.org/abs/2403.09610v1
    
    Parafermions with symmetry-protected non-Abelian statistics
    å¯¾ç§°æ€§ä¿è­·ã•ã‚ŒãŸéã‚¢ãƒ¼ãƒ™ãƒ«çµ±è¨ˆã‚’æŒã¤ãƒ‘ãƒ©ãƒ•ã‚§ãƒ«ãƒŸã‚ªãƒ³
    
    - å¯¾ç§°æ€§ä¿è­·ã•ã‚ŒãŸéã‚¢ãƒ¼ãƒ™ãƒ«çµ±è¨ˆ(SPNAS)ã®æ¦‚å¿µã‚’æ‹¡å¼µ
    - ãƒ‘ãƒ©ãƒ•ã‚§ãƒ«ãƒŸã‚ªãƒ³é›¶ãƒ¢ãƒ¼ãƒ‰(PZM)ã‚’ä¿è­·ã™ã‚‹ä¸€èˆ¬çš„ãªãƒ¦ãƒ‹ã‚¿ãƒªãƒ¼å¯¾ç§°æ€§
    - PZMãŒSPNASã‚’å›ºæœ‰ã«å¾“ã†ã“ã¨ã‚’å³å¯†ã«è¨¼æ˜
    http://arxiv.org/abs/2403.09602v1
    
    ExploRLLM: Guiding Exploration in Reinforcement Learning with Large Language Models
    ExploRLLM: Guiding Exploration in Reinforcement Learning with Large Language Models
    
    - å¤§è¦³æ¸¬ãƒ»è¡Œå‹•ç©ºé–“ã‚’æŒã¤ç”»åƒãƒ™ãƒ¼ã‚¹ã®ãƒ­ãƒœãƒƒãƒˆæ“ä½œã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã€ExploRLLMã¯å¤§è¦æ¨¡ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã®å¸°ç´ãƒã‚¤ã‚¢ã‚¹ã‚’æ´»ç”¨ã—ã€æ¢ç´¢ã‚’èª˜å°ã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã€‚
    - åŸºç¤ãƒ¢ãƒ‡ãƒ«ã‚’æ´»ç”¨ã—ã¦è¡Œå‹•ã¨è¦³æ¸¬ç©ºé–“ã‚’å†æ§‹æˆã—ã€å¼·åŒ–å­¦ç¿’ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚
    - å®Ÿé¨“çµæœã§ã¯ã€èª˜å°æ¢ç´¢ãŒãªã„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚ˆã‚Šã‚‚ã¯ã‚‹ã‹ã«è¿…é€ŸãªåæŸã‚’å¯èƒ½ã«ã—ã€ExploRLLMã¯ãƒãƒ‹ãƒ©åŸºç¤ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚å„ªã‚Œã¦ã„ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚
    http://arxiv.org/abs/2403.09583v1
    
    Universal Definitions of the Roman Factorial: Introduction to Foundational Functions and the Generalization Process
    Universal Definitions of the Roman Factorial: Foundational Functions and Generalization
    
    - ãƒ­ãƒ¼ãƒæ•°å­—éšä¹—ã‚’å†å®šç¾©ã™ã‚‹ãŸã‚ã®æ™®éçš„ãªé©ç”¨å¯èƒ½ãªé–¢æ•°ã®å°å…¥
    - Booleanæ¼”ç®—ã«é¡ä¼¼ã—ãŸåŸºç¤é–¢æ•°ã®ä½¿ç”¨ã«ã‚ˆã‚‹éšä¹—è¡¨ç¾ã®ç°¡ç´ åŒ–
    - æ±åŒ–ãƒ—ãƒ­ã‚»ã‚¹ã‚’é€šã˜ã¦ã€å†å¸°çš„ãŠã‚ˆã³éå†å¸°çš„ãªãƒ­ãƒ¼ãƒæ•°å­—éšä¹—ã®æ™®éçš„ãªå®šç¾©ã‚’ç›®æŒ‡ã™
    http://arxiv.org/abs/2403.09581v1
    
    Algorithmic syntactic causal identification
    ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒŸãƒƒã‚¯æ§‹æ–‡çš„å› æœåŒå®š
    
    - ç¾åœ¨ã®å› æœåŒå®šæ‰‹æ³•ãŒé©ç”¨ã§ããªã„çŠ¶æ³ã‚’è§£æ±ºã™ã‚‹ãŸã‚ã€å¤å…¸çš„ç¢ºç‡è«–ã®ä»£ã‚ã‚Šã«å¯¾ç§°çš„å˜ä½çš„åœã®å…¬ç†çš„åŸºç›¤ã‚’ä½¿ç”¨ã™ã‚‹æ–¹æ³•ã‚’ææ¡ˆã€‚
    - ä¸€èˆ¬çš„ãªå› æœåŒå®šæ‰‹æ³•ã‚’ç´”ç²‹ã«æ§‹æ–‡çš„ã«è¨˜è¿°ã™ã‚‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’æä¾›ã€‚
    - å¤å…¸çš„ãªãƒãƒƒã‚¯ãƒ‰ã‚¢ãŠã‚ˆã³ãƒ•ãƒ­ãƒ³ãƒˆãƒ‰ã‚¢ã®å› æœèª¿æ•´ã®æ§‹æ–‡çš„é¡ä¼¼ç‰©ã‚’å°å‡ºã—ã€ã‚ˆã‚Šè¤‡é›‘ãªå› æœãƒ¢ãƒ‡ãƒ«ã¸ã®é©ç”¨ã‚’ç¤ºã™ã€‚
    http://arxiv.org/abs/2403.09580v1
    
    Commutation principles for nonsmooth variational problems on Euclidean Jordan algebras
    Euclidean Jordanä»£æ•°ä¸Šã®æ»‘ã‚‰ã‹ã§ãªã„å¤‰åˆ†å•é¡Œã®ãŸã‚ã®äº¤æ›åŸç†
    
    - Ram\'irez, Seeger, and Sossaã«ã‚ˆã£ã¦è¨¼æ˜ã•ã‚ŒãŸEuclidean Jordanä»£æ•°ã®è¨­å®šã«ãŠã‘ã‚‹äº¤æ›åŸç†
    - $\Theta$ãŒæ»‘ã‚‰ã‹ã§ãªãã¦ã‚‚ã€å±€æ‰€æœ€å°åŒ–å­$a$ã¯$\Theta$ã®å‹¾é…ã¨äº¤æ›ã™ã‚‹
    - å±€æ‰€æœ€å¤§åŒ–å­$a$ã¯$\Theta$ã®(Fenchel)éƒ¨åˆ†å¾®åˆ†ã®å„è¦ç´ ã¨äº¤æ›ã™ã‚‹
    http://arxiv.org/abs/2403.09578v1
    --------------------------------------------------
    sector-specific adaptations
    
    Generalized Predictive Model for Autonomous Driving
    è‡ªå‹•é‹è»¢ã®ãŸã‚ã®æ±ç”¨äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«
    
    - è‡ªå‹•é‹è»¢å‘ã‘ã®å¤§è¦æ¨¡ãƒ“ãƒ‡ã‚ªäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚’ç´¹ä»‹
    - é«˜ã‚³ã‚¹ãƒˆãªãƒ‡ãƒ¼ã‚¿åé›†ã®åˆ¶ç´„ã‚’å–ã‚Šé™¤ãã€æ±ç”¨æ€§ã‚’é«˜ã‚ã‚‹ãŸã‚ã«å¤§è¦æ¨¡ãªWebãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
    - GenADã¯ä»–ã®ãƒ“ãƒ‡ã‚ªäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆå­¦ç¿’ã§æœªçŸ¥ã®ãƒ‡ãƒ¼ã‚¿ã«é©ç”¨å¯èƒ½
    http://arxiv.org/abs/2403.09630v1
    
    Physically motivated improvements of Variational Quantum Eigensolvers
    ç‰©ç†çš„ãªãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã«åŸºã¥ãVariational Quantum Eigensolversã®æ”¹å–„
    
    - ADAPT-VQEã®åŠ¹æœã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ã€çŠ¶æ…‹æº–å‚™ã®æœ€é©åŒ–ã¨ã‚¢ãƒ³ã‚µãƒƒãƒ„ã®å±•é–‹ã‚’è¡Œã†ã€‚
    - æ–°ã—ã„æ‰‹æ³•ã«ã‚ˆã‚Šã€æµ…ã„å›è·¯ã¨æ¸›å°‘ã—ãŸæ¸¬å®šè¦ä»¶ã‚’å®Ÿç¾ã™ã‚‹ã€‚
    - H4ãƒ¢ãƒ‡ãƒ«ã¨æ°´åˆ†å­ã«ãŠã‘ã‚‹æ€§èƒ½è©•ä¾¡ã‚’é€šã˜ã¦ã€ç‰©ç†çš„ãªæˆ¦ç•¥ã®æœ‰åŠ¹æ€§ãŒç¤ºã•ã‚Œã‚‹ã€‚
    http://arxiv.org/abs/2403.09624v1
    
    PosSAM: Panoptic Open-vocabulary Segment Anything
    PosSAM: Panoptic Open-vocabulary Segment Anything
    
    - SAMã®ç©ºé–“çš„ãªãƒã‚¹ã‚¯ç”Ÿæˆã«å„ªã‚Œã¤ã¤ã‚‚ã€ç‰©ä½“ã‚¯ãƒ©ã‚¹æƒ…å ±ã®èªè­˜ã¨éåˆ†å‰²ã®èª²é¡Œã‚’è§£æ±º
    - PosSAMã¯SAMã®ç‰¹å¾´ã‚’æ´»ç”¨ã—ã€ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹èªè­˜ãƒã‚¹ã‚¯ã‚’ç”Ÿæˆã—ã€CLIPã®ç‰¹å¾´ã‚’åˆ©ç”¨ã—ã¦åŠ¹æœçš„ãªã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åˆ†é¡ã‚’å®Ÿç¾
    - MASEã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«ã‚ˆã‚Šç”Ÿæˆã•ã‚ŒãŸãƒã‚¹ã‚¯ã®å“è³ªã‚’å‘ä¸Šã•ã›ã€ã‚ªãƒ¼ãƒ—ãƒ³ãƒœã‚­ãƒ£ãƒ–ãƒ©ãƒªãƒ¼åˆ†é¡ã®æ€§èƒ½ã‚’é«˜ã‚ã‚‹
    http://arxiv.org/abs/2403.09620v1
    
    pARam: Leveraging Parametric Design in Extended Reality to Support the Personalization of Artifacts for Personal Fabrication
    pARam: Leveraging Parametric Design in Extended Reality to Support the Personalization of Artifacts for Personal Fabrication
    
    - XRã‚’ä½¿ç”¨ã—ãŸPDã¨ã®çµ„ã¿åˆã‚ã›ã«ã‚ˆã‚‹PFå‘ã‘ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã®in-situè¨­å®šã‚’å¯èƒ½ã«ã™ã‚‹pARam
    - pARamã¯è¤‡é›‘ãª3Dãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã‚¹ã‚­ãƒ«ã‚’è¦æ±‚ã›ãšã€ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼ã‚„ç…§æ˜æ¨å®šãªã©ã®å®Ÿç”¨çš„ãªå…¥åŠ›ã§ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã‚’ã‚µãƒãƒ¼ãƒˆ
    - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ç’°å¢ƒã‚’è€ƒæ…®ã—ã¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’é¸æŠã—ã€è¤‡é›‘ãªè¨­è¨ˆæ–¹æ³•ã‚’ç°¡ç´ åŒ–ã—ãªãŒã‚‰é©åˆ‡ãªè¡¨ç¾åŠ›ã‚’ä¿æŒå¯èƒ½
    http://arxiv.org/abs/2403.09607v1
    
    Optimistic Verifiable Training by Controlling Hardware Nondeterminism
    æœ€é©ãªãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã®éæ±ºå®šæ€§ã‚’åˆ¶å¾¡ã™ã‚‹ã“ã¨ã«ã‚ˆã‚‹æ¥½è¦³çš„æ¤œè¨¼å¯èƒ½ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
    
    - è¨“ç·´ãƒ—ãƒ­ã‚»ã‚¹ã®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã®éæ±ºå®šæ€§ã‚’åˆ¶å¾¡ã™ã‚‹ãŸã‚ã«ã€é«˜ã„ç²¾åº¦ã§è¨“ç·´ã‚’è¡Œã„ã€ä¸­é–“è¨ˆç®—ã‚¹ãƒ†ãƒƒãƒ—å¾Œã«ä¸¸ã‚ã‚’è¡Œã†æ‰‹æ³•ã‚’ææ¡ˆã€‚
    - NVIDIAã®ç•°ãªã‚‹GPUã§ã®æ¤œè¨¼ã‚’é€šã˜ã¦ã€FP32ç²¾åº¦ã§ã®æ­£ç¢ºãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å†ç¾ã‚’é”æˆã€‚
    - è¨¼æ˜ãƒ™ãƒ¼ã‚¹ã®ã‚·ã‚¹ãƒ†ãƒ ã¨æ¯”è¼ƒã—ã¦ã€ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ãŠã‚ˆã³æ™‚é–“ã‚³ã‚¹ãƒˆã‚’å¤§å¹…ã«å‰Šæ¸›ã™ã‚‹æ¤œè¨¼å¯èƒ½ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã‚’ç¤ºã—ãŸã€‚
    http://arxiv.org/abs/2403.09603v1
    
    Iterative Forgetting: Online Data Stream Regression Using Database-Inspired Adaptive Granulation
    ã‚¤ãƒ†ãƒ¬ãƒ¼ãƒ†ã‚£ãƒ–ãƒ»ãƒ•ã‚©ãƒ¼ã‚²ãƒƒãƒ†ã‚£ãƒ³ã‚°: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ç€æƒ³ã‚’å¾—ãŸé©å¿œçš„ãªç²—ç²’åº¦ã‚’ç”¨ã„ãŸã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆãƒªãƒ¼ãƒ å›å¸°
    
    - æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ãŸç²—ç²’åº¦ã®ä½œæˆ
    - æƒ…å ±ãŒå¤ããªã£ãŸç²’ã‚’ç¶™ç¶šçš„ã«å¿˜ã‚Œã‚‹
    - ãƒ‡ãƒ¼ã‚¿ã¨ç²’ã‚’åˆ©ç”¨ã—ã¦ä½é…å»¶äºˆæ¸¬ã‚’æä¾›
    http://arxiv.org/abs/2403.09588v1
    
    uaMix-MAE: Efficient Tuning of Pretrained Audio Transformers with Unsupervised Audio Mixtures
    uaMix-MAE: æ•™å¸«ãªã—ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªæ··åˆç‰©ã§äº‹å‰å­¦ç¿’æ¸ˆã¿ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã‚’åŠ¹ç‡çš„ã«èª¿æ•´ã™ã‚‹æ–¹æ³•
    
    - æ•™å¸«ãªã—ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªæ··åˆç‰©ã‚’åˆ©ç”¨ã—ãŸã€åŠ¹ç‡çš„ãªInstance Discrimination(ID)èª¿æ•´æˆ¦ç•¥ã®å°å…¥
    - å¯¾è±¡ã‚»ãƒãƒ³ãƒ†ã‚£ã‚¯ã‚¹ã¸ã®é©å¿œã‚’åŠ©ã‘ã‚‹ãŸã‚ã«ã€äº‹å‰å­¦ç¿’æ¸ˆã¿MAEã®è¡¨ç¾ã‚’æ•´åˆ—ã•ã›ã‚‹ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒ†ã‚£ãƒ–èª¿æ•´ã®æ´»ç”¨
    - å°‘é‡ã®æ•™å¸«ãªã—ãƒ‡ãƒ¼ã‚¿ã§ãƒ¢ãƒ‡ãƒ«ã‚’æœ€é©åŒ–ã™ã‚‹ãŸã‚ã®ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªæ··åˆæŠ€è¡“ã®ææ¡ˆ
    http://arxiv.org/abs/2403.09579v1
    
    Eyes Closed, Safety On: Protecting Multimodal LLMs via Image-to-Text Transformation
    ç›®ã‚’é–‰ã˜ã¦å®‰å…¨ã‚’ç¢ºä¿ï¼šç”»åƒã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã¸ã®å¤‰æ›ã‚’é€šã˜ãŸãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«LLMã®ä¿è­·
    
    - MLLMã¯å°è±¡çš„ãªæ¨è«–èƒ½åŠ›ã‚’ç¤ºã™ãŒã€ç”»åƒç‰¹å¾´ã®å°å…¥ã«ã‚ˆã‚Šã€å®‰å…¨ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ãŒè¿‚å›ã•ã‚Œã‚„ã™ããªã£ã¦ã„ã‚‹ã€‚
    - ECSOã¯MLLMã®å†…åœ¨çš„ãªå®‰å…¨æ„è­˜ã‚’æ´»ç”¨ã—ã€ä¸å®‰å…¨ãªç”»åƒã‚’é©å¿œçš„ã«ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ã—ã¦ã€å®‰å…¨ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’æ´»æ€§åŒ–ã•ã›ã‚‹ã€‚
    - ECSOã¯5ã¤ã®SoTA MLLMã§å®Ÿé¨“ã‚’è¡Œã„ã€ãƒ¢ãƒ‡ãƒ«ã®å®‰å…¨æ€§ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚
    http://arxiv.org/abs/2403.09572v1
    
    AdaShield: Safeguarding Multimodal Large Language Models from Structure-based Attack via Adaptive Shield Prompting
    AdaShield: æ§‹é€ ãƒ™ãƒ¼ã‚¹æ”»æ’ƒã‹ã‚‰ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’é©å¿œçš„ã«å®ˆã‚‹
    
    - MLLMã«å¯¾ã™ã‚‹æ§‹é€ ãƒ™ãƒ¼ã‚¹ã‚¸ã‚§ã‚¤ãƒ«ãƒ–ãƒ¬ã‚¤ã‚¯æ”»æ’ƒã«å¯¾æŠ—ã™ã‚‹AdaShieldã¯ã€MLLMã‚’Fine-tuningã‚„è¿½åŠ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãªã—ã§é˜²å¾¡ã™ã‚‹ã€‚
    - æ‰‹å‹•è¨­è¨ˆã•ã‚ŒãŸé™çš„ãªé˜²å¾¡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ã€é©å¿œçš„ãªè‡ªå‹•ä¿®æ­£ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã«ã‚ˆã‚Šã€æ‚ªæ„ã®ã‚ã‚‹ã‚¯ã‚¨ãƒªã«å¯¾ã™ã‚‹é˜²å¾¡ãŒå¯èƒ½ã€‚
    - å®Ÿé¨“çµæœã¯ã€AdaShieldãŒMLLMã®å …ç‰¢æ€§ã‚’å‘ä¸Šã•ã›ã€ä¸€èˆ¬çš„ãªèƒ½åŠ›ã‚’æãªã†ã“ã¨ãªãã€æ§‹é€ ãƒ™ãƒ¼ã‚¹ã®æ”»æ’ƒã‹ã‚‰ä¿è­·ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚
    http://arxiv.org/abs/2403.09513v1
    
    SkateFormer: Skeletal-Temporal Transformer for Human Action Recognition
    SkateFormer: äººé–“ã®å‹•ä½œèªè­˜ã®ãŸã‚ã®ã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ»ãƒ†ãƒ³ãƒãƒ©ãƒ«ãƒ»ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼
    
    - ã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ‡ãƒ¼ã‚¿ã«ãŠã‘ã‚‹GCNã®å—å®¹é‡åˆ¶ç´„ã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«Transformerã‚’å°å…¥
    - SkateFormerã¯ã‚¹ã‚±ãƒ«ãƒˆãƒ³-æ™‚é–“çš„é–¢ä¿‚ã«åŸºã¥ããƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ã¨self-attentionã‚’ç”¨ã„ãŸæ–°æ‰‹æ³•
    - 4ã¤ã®ç•°ãªã‚‹ã‚¹ã‚±ãƒ«ãƒˆãƒ³-æ™‚é–“çš„é–¢ä¿‚ã‚¿ã‚¤ãƒ—ã‚’çµ„ã¿åˆã‚ã›ãŸã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§é«˜ã„æ€§èƒ½ã‚’é”æˆ
    http://arxiv.org/abs/2403.09508v1
    --------------------------------------------------



```python
generate_search_string


# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’æ§‹ç¯‰ã™ã‚‹ã€‚
arxivclient = arxiv.Client()

# æ¤œç´¢æ¡ä»¶ã‚’æŒ‡å®šã™ã‚‹ã€‚
# query: æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŒ‡å®šã™ã‚‹ã€‚ã“ã“ã§ã¯ "GPT-4" ã‚’æŒ‡å®šã€‚
# max_results: å–å¾—ã™ã‚‹è«–æ–‡ã®æœ€å¤§ä»¶æ•°ã‚’æŒ‡å®šã™ã‚‹ã€‚ã“ã“ã§ã¯ 10 ä»¶ã€‚
# sort_by: è«–æ–‡ã®ä¸¦ã³æ›¿ãˆæ¡ä»¶ã‚’æŒ‡å®šã™ã‚‹ã€‚ã“ã“ã§ã¯æŠ•ç¨¿æ—¥æ™‚ã®é™é †ï¼ˆæœ€æ–°é †ï¼‰ã€‚
for query in generate_search_string:
    print(query)
    search = arxiv.Search(
        query = query,
        max_results = 10,
        sort_by = arxiv.SortCriterion.SubmittedDate
    )

    # æ¤œç´¢ã‚’å®Ÿè¡Œã—ã€çµæœã‚’å–å¾—ã™ã‚‹ã€‚
    results = arxivclient.results(search)
    # å–å¾—ã—ãŸè«–æ–‡ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’1ä»¶ãšã¤è¡¨ç¤ºã™ã‚‹ã€‚
    for r in results:
        print(f"\n{str(r.title)}\n{get_summary(r)}\n{r}")
    print("-" * 50)
```

    Search String 1: ("evaluating RAG status" OR "RAG evaluation methods") AND ("project management" OR "project monitoring")
    --------------------------------------------------
    Search String 2: ("RAG evaluation methods" OR "Red Amber Green assessment techniques") AND ("industry applications" OR "sector-specific adaptations")
    --------------------------------------------------



```python
# client = arxiv.Client()
# for query in modified_queries:
#     search = arxiv.Search(
#         query = query,
#         max_results = 10,
#         sort_by = arxiv.SortCriterion.SubmittedDate
#     )

#     # æ¤œç´¢ã‚’å®Ÿè¡Œã—ã€çµæœã‚’å–å¾—ã™ã‚‹ã€‚
#     results = client.results(search)
#     # å–å¾—ã—ãŸè«–æ–‡ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’1ä»¶ãšã¤è¡¨ç¤ºã™ã‚‹ã€‚
#     for r in results:
#         print(r.title)
#         print(r)
        
#         print(r.summary)
#     print("-" * 50)
```


```python
# results = arxiv.Search(
#         query = "AI",
#         max_results = 10,
#         sort_by = arxiv.SortCriterion.SubmittedDate
#     )
# print(results)
```


```python
# for k in modified_queries:
#     for keyword in k:
#         print(f"Searching for: {keyword}\n")
#         try:
#             results = search_arxiv(str(keyword))
#         except Exception as e:
#             print(f"Error searching for keyword '{keyword}': {e}")
#             continue  # æ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã€æ¬¡ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®æ¤œç´¢ã«é€²ã‚€

#         for result in results:
#             try:
#                 # summary = get_summary(result)
#                 print()
#             except KeyboardInterrupt:
#                 print("KeyboardInterrupt detected, skipping to the next result.")
#                 continue  # KeyboardInterruptãŒç™ºç”Ÿã—ãŸå ´åˆã€æ¬¡ã®è«–æ–‡ã®å‡¦ç†ã«é€²ã‚€
#             except Exception as e:
#                 print(f"Error getting summary for result '{result.title}': {e}")
#                 continue  # ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã€æ¬¡ã®è«–æ–‡ã®å‡¦ç†ã«é€²ã‚€

#             # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãªã‹ã£ãŸå ´åˆã®å‡¦ç†ã‚’ã“ã“ã«è¨˜è¿°
#             print(f"title: {result.title}")
#             print(f"published: {result.published}")
#             # print(f"abstract: {result.summary}")
#             print(f"PDF link: {result.pdf_url}")
#             # print(f"summary: {summary}")
#         print("-" * 50)

```


```python

```


```python

```

```
from bs4 import BeautifulSoup
import requests
import re

def get_search_results(keyword, number=5):
    # Google Scholarã®æ¤œç´¢URLã‚’æ§‹ç¯‰
    html_doc = requests.get(f"https://scholar.google.co.jp/scholar?hl=ja&num={number}&q=" + keyword).text
    soup = BeautifulSoup(html_doc, "html.parser")  # BeautifulSoupã®åˆæœŸåŒ–
    
    # å¿…è¦ãªæƒ…å ±ã‚’æŠ½å‡º
    tags_title_url = soup.find_all("h3", {"class": "gs_rt"})  # ã‚¿ã‚¤ãƒˆãƒ«&URL
    tags_author_year = soup.find_all("div", {"class": "gs_a"})  # è‘—è€…&å¹´
    tags_citations = soup.find_all("div", {"class": "gs_fl"})  # å¼•ç”¨å…ƒãƒªãƒ³ã‚¯ãŒå«ã¾ã‚Œã‚‹ã‚»ã‚¯ã‚·ãƒ§ãƒ³

    for tag_title, tag_author_year, tag_citation in zip(tags_title_url, tags_author_year, tags_citations):
        title = tag_title.text.replace("[HTML]", "").replace("[PDF]", "")
        url = tag_title.find('a')['href']
        
        citation_link = None
        for a in tag_citation.find_all('a'):
            if "å¼•ç”¨" in a.text:
                citation_link = a['href']
                break
                
        citations = re.search(r'\d+', a.text) if citation_link else '0'
        citations = citations.group(0) if citations else '0'

        print(f"Title: {title}\nURL: {url}\nCitations: {citations}")
        
        # å¼•ç”¨å…ƒãƒªãƒ³ã‚¯ãŒã‚ã‚Œã°ã€ãã®URLã‚’è¡¨ç¤ºï¼ˆå¼•ç”¨å…ƒãƒšãƒ¼ã‚¸ã‹ã‚‰ã•ã‚‰ã«æƒ…å ±ã‚’å–å¾—ã™ã‚‹å ´åˆã«ä½¿ç”¨ï¼‰
        if citation_link:
            print(f"Citation URL: https://scholar.google.co.jp{citation_link}")

        # æ¦‚è¦ã®å–å¾—ã¯Google Scholarã®HTMLæ§‹é€ ã«ä¾å­˜ã™ã‚‹ãŸã‚ã€æ¦‚è¦ã‚’ç›´æ¥å–å¾—ã™ã‚‹ã“ã¨ã¯æ¨å¥¨ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚
        # ä»£ã‚ã‚Šã«ã€è«–æ–‡ã®URLã‚’è¨ªã‚Œã¦å†…å®¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚
        
        print("--------------------------------------------------\n")

search_strings = [
    '"Risk Assessment and Governance evaluation methods"',
    '"Organizations measure success outcomes Risk Assessment Governance initiatives"'
]

for keyword in search_strings:
    print(f"Searching for: {keyword}\n")
    get_search_results(keyword, number=2)

# search_strings = [
#     '1. "Risk Assessment and Governance evaluation methods"',
#     '2. "Organizations measure success outcomes Risk Assessment Governance initiatives"'
# ]


for keyword in generate_search_string:
    print(f"Searching for: {keyword}\n")
    get_search_results(keyword, number=2)



def get_title_and_url(soup):
    """obtain title and url from soup
    :param soup: parsed html by BeautifulSoup
    :return: title_list, url_list
    """
    tags1 = soup.find_all("h3", {"class": "gs_rt"})
    title_list = []
    url_list = []
    for tag1 in tags1:
        # ã‚¿ã‚¤ãƒˆãƒ«å–å¾—
        # PDF, æ›¸ç±, B, HTML, å¼•ç”¨, Cã®ã‚¿ã‚°ã‚’é™¤å»
        title = re.sub(r"\[(PDF|æ›¸ç±|B|HTML|å¼•ç”¨|C)\]", "", tag1.text)
        # ç©ºç™½åŒºåˆ‡ã‚Šã‚’å»ƒæ­¢
        title = "_".join(title.split(" "))
        if title[0] == "_":
            title = title[1:]
        title_list.append(title)

        # urlå–å¾—
        try:
            url = tag1.select("a")[0].get("href")
            url_list.append(url)
        except IndexError:
            url_list.append(None)
    return title_list, url_list


def get_writer_and_year(soup):
    """obtain writer(author) and year from soup
    :param soup: parsed html by BeautifulSoup
    :return: writer_list, year_list
    """
    tags2 = soup.find_all("div", {"class": "gs_a"})
    writer_list = []
    year_list = []
    for tag2 in tags2:
        # è‘—è€…å–å¾—
        """
        writer = tag2.text
        writer = re.sub(r"\d", "", writer)
        for char in range(0, len(writer)):
            if writer[char] == "-":
                writer = writer[2 : char - 1]
                break
        """
        writer = tag2.text.split("\xa0- ")[0]
        writer_list.append(writer)

        # è«–æ–‡ç™ºè¡Œå¹´å–å¾—
        year = tag2.text
        year = re.sub(r"\D", "", year)
        # yearãŒ5æ¡ä»¥ä¸Šã ã£ãŸå ´åˆã®ä¾‹å¤–å‡¦ç†
        if len(year) > 4:
            year_list.append(year[len(year) - 4 : len(year)])
        else:
            year_list.append(year)
    return writer_list, year_list


def get_citations(soup):
    """obtain number of citations from soup
    :param soup: parsed html by BeautifulSoup
    :return: ci_num_list
    """
    tags3 = soup.find_all(text=re.compile("å¼•ç”¨å…ƒ"))
    ci_num_list = []
    for tag3 in tags3:
        # è¢«å¼•ç”¨æ•°å–å¾—
        citation = tag3.replace("å¼•ç”¨å…ƒ", "")
        ci_num_list.append(int(citation))
    return ci_num_list


def get_id(soup):
    """obtain paper id from soup
    :param soup: parsed html by BeautifulSoup
    :return: ci_num_list
    """
    tags4 = soup.find_all("div", {"class": "gs_fl"})
    p_id_list = []
    for tag4 in tags4:
        # è«–æ–‡IDå–å¾—
        try:
            elem = tag4.find_all("a")[2]["href"]
            a = 15
            while True:
                if elem[a] == "&":
                    break
                a += 1
            p_id_list.append(elem[15:a])
        except:
            print("")
    return p_id_list

def year_list_to_cite_years(year_list,p_year):
    """convert year_list into cite_years
    :param year_list,p_year:
    :return: cite_years
    """
    year_list_int = []
    for s in year_list:
        try:
            year_list_int.append(int(s))
        except:
            pass
    y = [p_year+i for i in range(2021 - p_year + 1)]
    cite_years = [0 for _ in range(2021 - p_year + 1)]
    for year in year_list_int:
        if year >= p_year and year <= 2021:
            cite_years[year - p_year] += 1
    list_return = [y, cite_years]
#    cite_years = pd.DataFrame(cite_years,
#                       index=y,
#                       columns=['total'])
#    cite_years  = cite_years.T
    return list_return



def make_url(keyword, conf, author, year, paper_id=None):
    """make url for search papers
    normal search (keyword, conf, author, year) or target search (paper_id)
    :param keyword: str or None
    :param conf: str or None, conference information
    :param author: str or None, author information
    :param year: int or None, published year
    :param paper_id: None or int, paper information
    :return: url
    """
    assert (
        keyword is not None
        or conf is not None
        or author is not None
        or year is not None
        or paper_id is not None
    ), "KeywordNotFoundError"
    url = "https://scholar.google.co.jp/scholar?"
    if paper_id is not None:
        url += f"&cites={paper_id}"
    else:
        url += "&as_sdt=0%2C5"
        if keyword is not None:
            url += f"&as_q={'%20'.join(keyword.split())}"
        else:
            url += "&as_q="
        if conf is not None:
            url += f"&as_publication={'%20'.join(conf.split())}"
        if author is not None:
            author = "+".join(author.split())
            url += f"&as_sauthors={'%20'.join(author.split())}"
        if year is not None:
            url += f"&as_ylo={year}"
    return url



def get_snippet(soup):
    """obtain snippet from soup
    :param soup: parsed html by BeautifulSoup
    :return: snippet_list
    """
    tags = soup.find_all("div", {"class": "gs_rs"})
    snippet_list = [tags[i].text for i in range(len(tags))]
    return snippet_list


def grep_candidate_papers(url):
    html_doc = requests.get(url).text
    soup = BeautifulSoup(html_doc, "html.parser")

    title_list, url_list = get_title_and_url(soup)
    writer_list, year_list = get_writer_and_year(soup)
    ci_num_list = get_citations(soup)
    p_id_list = get_id(soup)
    snippet_list = get_snippet(soup)

    for i in range(len(title_list)):
        print("-" * 20)
        print(f"paper number: {i}")
        print(f"paper title: {title_list[i]}")
        print(f"published year: {year_list[i]}")
        print(f"citations: {ci_num_list[i]}")

    print(f"\nSelect a paper number between 0 and {len(title_list)-1}")
    while True:
        try:
            target_paper_num = int(input("Select paper number: "))
            if 0 <= target_paper_num < len(title_list):
                break
            else:
                print(f"Please enter a number between 0 and {len(title_list)-1}.")
        except ValueError:
            print("Invalid input. Please enter a valid number.")
    
    target_paper = {
        "title": title_list[target_paper_num],
        "writer": writer_list[target_paper_num],
        "year": year_list[target_paper_num],
        "citations": ci_num_list[target_paper_num],
        "url": url_list[target_paper_num],
        "paper_id": p_id_list[target_paper_num],
        "snippet": snippet_list[target_paper_num],
    }
    return target_paper



def scraping_papers(url):
    """scrape 100 papers
    :param url: target url
    :return: title_list, url_list, writer_list, year_list, ci_num_list, p_id_list, snippet_list
    """
    url_each = url.split("&")
    url_each[0] = url_each[0] + "start={}"
    url_base = "&".join(url_each)

    title_list = []
    url_list = []
    writer_list = []
    year_list = []
    ci_num_list = []
    p_id_list = []
    snippet_list = []

    for page in range(0, 100, 10):
        print("Loading next {} results".format(page + 10))
        url_tmp = url_base.format(page)
        html_doc = requests.get(url_tmp).text
        soup = BeautifulSoup(html_doc, "html.parser")

        title_list_tmp, url_list_tmp = get_title_and_url(soup)
        writer_list_tmp, year_list_tmp = get_writer_and_year(soup)
        ci_num_list_tmp = get_citations(soup)
        p_id_list_tmp = get_id(soup)
        snippet_list_tmp = get_snippet(soup)

        title_list.extend(title_list_tmp)
        url_list.extend(url_list_tmp)
        writer_list.extend(writer_list_tmp)
        year_list.extend(year_list_tmp)
        ci_num_list.extend(ci_num_list_tmp)
        p_id_list.extend(p_id_list_tmp)
        snippet_list.extend(snippet_list_tmp)

        sleep(np.random.randint(5, 10))
    return (
        title_list,
        url_list,
        writer_list,
        year_list,
        ci_num_list,
        p_id_list,
        snippet_list,
    )
```


```python

def check_paper_relevance_and_keywords(title, search_string, client):
    # Adjust the prompt to ask for relevance and keywords
    prompt = (f"Determine if the paper titled '{title}' is relevant to the topic '{search_string}'. "
              "and in return just informed paper is relevant or paper is not relevant, to the point.")

    data = {
        "model": "gpt-3.5-turbo",
        "messages": [
            {"role": "system", "content": "You are a knowledgeable assistant."},
            {"role": "user", "content": prompt}
        ]
    }
    response = client.chat.completions.create(
        # model="gpt-3.5-turbo",
        model="gpt-3.5-turbo-0125",
        messages=[
            {"role": "system", "content": "You are a knowledgeable assistant."},
            {"role": "user", "content": prompt}
        ],
        # response_format={ "type": "json_object" },
        temperature=TEMPERATURE,
    )
    content = response.choices[0].message.content.strip().lower()
    
    return content
```


```python

```

```
# ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®å…¥åŠ›
search_strings = [
    '"Risk Assessment and Governance evaluation methods"',
    '"Organizations measure success outcomes Risk Assessment Governance initiatives"'
]

for keyword in search_strings:
    print(f"Searching for: {keyword}\n")
    
    # æ¤œç´¢ç”¨URLã®ä½œæˆ
    url = make_url(keyword=keyword, conf=None, author=None, year=None)
    
    # å€™è£œã¨ãªã‚‹è«–æ–‡ã®é¸æŠ
    print("Please select a paper")
    selected_paper = grep_candidate_papers(url)
    
    # é¸æŠã•ã‚ŒãŸè«–æ–‡ã®æƒ…å ±ã‚’è¡¨ç¤º
    print(f"Selected Paper: {selected_paper['title']}")
    print(f"URL: {selected_paper['url']}")
    print(f"Citations: {selected_paper['citations']}")
    print(f"Snippet: {selected_paper['snippet']}\n")
    
    # é¸æŠã•ã‚ŒãŸè«–æ–‡ã®å¼•ç”¨è«–æ–‡æƒ…å ±ã®å–å¾—
    url_cite = make_url(paper_id=selected_paper["paper_id"])
    cited_papers_info = scraping_papers(url_cite)
    
    # å¼•ç”¨è«–æ–‡æƒ…å ±ã®è¡¨ç¤º (ä¾‹: ã‚¿ã‚¤ãƒˆãƒ«ã¨URL)
    for title, url in zip(cited_papers_info[0], cited_papers_info[1]):
        print(f"Cited Paper Title: {title}")
        print(f"Cited Paper URL: {url}\n")
```

```
# æ¤œç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨­å®š
# N_DAYS = 365  # éå»30æ—¥é–“ã®è«–æ–‡ã‚’æ¤œç´¢
N_DAYS = 30  # éå»30æ—¥é–“ã®è«–æ–‡ã‚’æ¤œç´¢

MAX_RESULT = 5  # æœ€å¤§çµæœæ•°
QUERY_TEMPLATE = 'all:{} AND submittedDate:[{} TO {}]'  # æ¤œç´¢ã‚¯ã‚¨ãƒªãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

# æ¤œç´¢ã‚’è¡Œã„ã€çµæœã‚’å–å¾—ã™ã‚‹é–¢æ•°
def search_arxiv_with_keywords(keywords):
    client = arxiv.Client()
    results_list = []

    today = dt.datetime.today() - dt.timedelta(days=2)
    base_date = today - dt.timedelta(days=N_DAYS)

    for keyword in keywords:
        query = QUERY_TEMPLATE.format(keyword, base_date.strftime("%Y-%m-%d"), today.strftime("%Y-%m-%d"))
        
        search = arxiv.Search(
            query=query,
            max_results=MAX_RESULT,
            sort_by=arxiv.SortCriterion.SubmittedDate,
            sort_order=arxiv.SortOrder.Descending,
        )

        results = client.results(search)
        
        for result in results:
            # ç‰¹å®šã®æ¡ä»¶ã«åŸºã¥ã„ã¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’è¡Œã†å ´åˆã¯ã“ã“ã«è¿½åŠ 
            results_list.append({
                'title': result.title,
                'summary': result.summary,
                'url': result.entry_id  # arXivã¸ã®ãƒªãƒ³ã‚¯
            })

    return results_list

search_results = search_arxiv_with_keywords(generate_search_string)
for result in search_results:
    print(f"Title: {result['title']}\nSummary: {result['summary']}\nURL: {result['url']}\n")

# ã†ã¾ãã„ã‹ãªã„ã®ã§ã‚¯ã‚¨ãƒªã‚’å°ã•ãã™ã‚‹(æœ¬ã¡ã‚ƒã‚“ã§ã¯ã“ã‚Œä½¿ã„ãŸãã­ãƒ¼ãª)

import re

def simplify_search_queries(complex_queries):
    simplified_queries = []

    for query in complex_queries:
        # æ•°å­—ã¨ãƒ”ãƒªã‚ªãƒ‰ã‚’é™¤å»ã—ã¦ã€ã‚¯ã‚¨ãƒªã®æœ¬ä½“ã ã‘ã‚’æŠ½å‡º
        clean_query = re.sub(r'^\d+\.\s*', '', query)
        
        # æ‹¬å¼§ã‚’é™¤å»
        clean_query = re.sub(r'[()"]', '', clean_query)
        
        # 'AND' ã¨ 'OR' ã§åˆ†å‰²
        split_queries = re.split(r'\sAND\s|\sOR\s', clean_query)
        
        # åˆ†å‰²ã—ãŸã‚¯ã‚¨ãƒªã‚’ãƒªã‚¹ãƒˆã«è¿½åŠ 
        for sub_query in split_queries:
            sub_query = sub_query.strip()
            if sub_query and sub_query not in simplified_queries:
                simplified_queries.append(sub_query)
                
    return simplified_queries


simplified_queries = simplify_search_queries(generate_search_string)
for query in simplified_queries:
    print(query)

from tqdm import tqdm
import time

# for query in tqdm(simplified_queries, desc="Searching"):
#     print(f"Query: {query}")
#     search_results = search_arxiv_with_keywords(query)
#     for result in search_results:
#         print(f"Title: {result['title']}\nSummary: {result['summary']}\nURL: {result['url']}\n")
#     time.sleep(2)  # æ¤œç´¢ã”ã¨ã«2ç§’é–“å¾…æ©Ÿã—ã¾ã™ã€‚



from duckduckgo_search import DDGS
import requests
from bs4 import BeautifulSoup


# ãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢ç”¨ã®é–¢æ•°
def search_text(keywords, region='wt-wt', safesearch='moderate', timelimit=None, max_results=3):
    with DDGS() as ddgs:
        results = [r for r in ddgs.text(keywords, region=region, safesearch=safesearch, timelimit=timelimit, max_results=max_results)]
        time.sleep(2)
    return results

# BeautifulSoupã‚’ä½¿ã£ã¦ã‚¦ã‚§ãƒ–ãƒšãƒ¼ã‚¸ã‹ã‚‰æƒ…å ±ã‚’æŠ½å‡ºã™ã‚‹é–¢æ•°
def extract_info_from_url(url):
    try:
        response = requests.get(url)
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # å¿…è¦ãªæƒ…å ±ã‚’æŠ½å‡ºã™ã‚‹ãŸã‚ã®ã‚³ãƒ¼ãƒ‰ã‚’ã“ã“ã«è¿½åŠ ã—ã¾ã™ã€‚
        # ä¾‹ãˆã°ã€ãƒšãƒ¼ã‚¸ã®å…¨ã¦ã®æ®µè½ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã™ã‚‹å ´åˆ:
        paragraphs = soup.find_all('p')
        text = ' '.join([p.text for p in paragraphs])
        return text
    except Exception as e:
        print(f"Error extracting information from {url}: {e}")
        return None




for query in tqdm(simplified_queries, desc="Searching"):
    print(query)
    text_results = search_text(query)
    print(text_results)
    for result in text_results:
        print(f"Title: {result['title']}\nURL: {result['href']}\n")
        # # URLã‹ã‚‰æƒ…å ±ã‚’æŠ½å‡º
        # extracted_info = extract_info_from_url(result['href'])
        # print(f"Extracted Info: {extracted_info}\n")

import time
from tqdm import tqdm
from duckduckgo_search import DDGS  # ã‚ã‚‹ã„ã¯é©åˆ‡ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å

# ãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢ç”¨ã®é–¢æ•°
def search_text(keywords, max_results=3):
    with DDGS() as ddgs:
        results = [r for r in ddgs.text(keywords, max_results=max_results)]
        time.sleep(2)  # æ¤œç´¢ã”ã¨ã«2ç§’é–“å¾…æ©Ÿ
    return results

# æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ç°¡ç•¥åŒ–ã™ã‚‹é–¢æ•°
def simplify_search_queries(complex_queries):
    simplified_queries = []
    # (ã‚¯ã‚¨ãƒªã‚’ç°¡ç•¥åŒ–ã™ã‚‹ãƒ­ã‚¸ãƒƒã‚¯)
    return simplified_queries

# è¤‡é›‘ãªã‚¯ã‚¨ãƒªã®ãƒªã‚¹ãƒˆ
complex_queries = [
    '1. ("RAG evaluation methods" OR "risk assurance governance evaluation methods") AND ("accuracy" AND "efficiency")',
    '2. ("RAG evaluation methods" OR "risk assurance governance evaluation methods") AND ("factors influencing" AND "development" AND "implementation")'
]

# ç°¡ç•¥åŒ–ã•ã‚ŒãŸã‚¯ã‚¨ãƒªã®ãƒªã‚¹ãƒˆã‚’å–å¾—
simplified_queries = simplify_search_queries(complex_queries)

# tqdmã‚’ä½¿ç”¨ã—ã¦é€²æ—çŠ¶æ³ã‚’è¡¨ç¤ºã—ãªãŒã‚‰æ¤œç´¢ã‚’å®Ÿè¡Œ
for query in tqdm(simplified_queries, desc="Searching"):
    print(f"Query: {query}")
    search_results = search_text(query)
    for result in search_results:
        print(f"Title: {result['title']}\nSummary: {result['summary']}\nURL: {result['url']}\n")
```


```python

```
