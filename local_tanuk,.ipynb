{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21463c8-f653-4a5c-8d03-8bd7da4b6edc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b59134db-50e1-4da7-9dad-3682ef75df4c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.45.2 in /usr/local/lib/python3.10/dist-packages (4.45.2)\n",
      "Collecting accelerate==1.0.0\n",
      "  Downloading accelerate-1.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting bitsandbytes==0.44.1\n",
      "  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.2) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.2) (0.25.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.2) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.2) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.2) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.2) (2024.9.11)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.2) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.2) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.2) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.2) (4.66.4)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==1.0.0) (6.0.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==1.0.0) (2.3.1+cu118)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.2) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.2) (4.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==1.0.0) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==1.0.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==1.0.0) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==1.0.0) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==1.0.0) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==1.0.0) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.7.0.84 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==1.0.0) (8.7.0.84)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==1.0.0) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==1.0.0) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==1.0.0) (10.3.0.86)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==1.0.0) (11.4.1.48)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==1.0.0) (11.7.5.86)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==1.0.0) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==1.0.0) (11.8.86)\n",
      "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==1.0.0) (2.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.2) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.2) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.2) (2024.7.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate==1.0.0) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==1.0.0) (1.3.0)\n",
      "Downloading accelerate-1.0.0-py3-none-any.whl (330 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.9/330.9 kB\u001b[0m \u001b[31m439.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bitsandbytes, accelerate\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 1.0.1\n",
      "    Uninstalling accelerate-1.0.1:\n",
      "      Successfully uninstalled accelerate-1.0.1\n",
      "Successfully installed accelerate-1.0.0 bitsandbytes-0.44.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Collecting flash_attn==2.6.3\n",
      "  Downloading flash_attn-2.6.3.tar.gz (2.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[22 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m fatal: not a git repository (or any of the parent directories): .git\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-ar5rih81/flash-attn_cd88aba202b546dd8bd98890666d2525/setup.py\", line 158, in <module>\n",
      "  \u001b[31m   \u001b[0m     _, bare_metal_version = get_cuda_bare_metal_version(CUDA_HOME)\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-ar5rih81/flash-attn_cd88aba202b546dd8bd98890666d2525/setup.py\", line 82, in get_cuda_bare_metal_version\n",
      "  \u001b[31m   \u001b[0m     raw_output = subprocess.check_output([cuda_dir + \"/bin/nvcc\", \"-V\"], universal_newlines=True)\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/lib/python3.10/subprocess.py\", line 421, in check_output\n",
      "  \u001b[31m   \u001b[0m     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/lib/python3.10/subprocess.py\", line 503, in run\n",
      "  \u001b[31m   \u001b[0m     with Popen(*popenargs, **kwargs) as process:\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/lib/python3.10/subprocess.py\", line 971, in __init__\n",
      "  \u001b[31m   \u001b[0m     self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/lib/python3.10/subprocess.py\", line 1863, in _execute_child\n",
      "  \u001b[31m   \u001b[0m     raise child_exception_type(errno_num, err_msg, err_filename)\n",
      "  \u001b[31m   \u001b[0m FileNotFoundError: [Errno 2] No such file or directory: '/usr/local/cuda/bin/nvcc'\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m torch.__version__  = 2.3.1+cu118\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip3 install transformers==4.45.2 accelerate==1.0.0 bitsandbytes==0.44.1\n",
    "!pip3 install --no-build-isolation flash_attn==2.6.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76342971-fc02-48f6-bb9f-dba113d7d24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer\n",
    "import torch\n",
    "\n",
    "# ローカルに保存するディレクトリパス\n",
    "model_dir = \"./local_model/Tanuki-8B-dpo-v1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a870304-d3e2-41e5-b1a0-2866177ddcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 一度だけローカルにモデルとトークナイザーをダウンロードして保存\n",
    "# # これを一度実行すれば、以降のコードでローカルのコピーを使用できます\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"weblab-GENIAC/Tanuki-8B-dpo-v1.0\")\n",
    "# tokenizer.save_pretrained(model_dir)\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"weblab-GENIAC/Tanuki-8B-dpo-v1.0\", device_map=\"auto\", torch_dtype=\"auto\")\n",
    "# model.save_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c54b0b8-93d6-4acd-9fce-a3f581dd8b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a7078aa163e4388be22f6edbb7316c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ローカルに保存したモデルとトークナイザーを読み込むコード\n",
    "# ダウンロードを再度行うことなく、保存済みのモデルを読み込みます\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_dir, device_map=\"auto\", torch_dtype=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88c5aee0-29e5-4ea5-9ae1-d779f488c779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# テキスト生成に必要なストリーマーの設定\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bce9a02-bc1a-416a-a98f-970936e3dce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# メッセージの準備\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"以下は、タスクを説明する指示です。要求を適切に満たす応答を書きなさい。\"},\n",
    "    {\"role\": \"user\", \"content\": \"たぬきに純粋理性批判は理解できますか？\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7aac7155-b48a-4e98-b84f-915fd3bd5741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入力IDを生成\n",
    "input_ids = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\").to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1d8dd0a-4725-4057-a821-9027fdeabb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:601: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "「たぬきに純粋理性批判」を理解できるかどうかという問いには、いくつかの観点から考える必要があります。まず、純粋理性批判はドイツの哲学者イマヌエル・カントによって書かれた哲学書であり、人間の認識能力や知識の限界について深く探求しています。この書物は非常に抽象的で複雑な概念を含んでおり、哲学的な訓練や知識が不可欠です。\n",
      "\n",
      "たぬきは動物であり、人間のように高度な認知能力や抽象的思考を持つことはありません。そのため、純粋理性批判のような高度な哲学的議論を理解することは難しいでしょう。たぬきが理解できるのは、基本的な感覚や経験に基づく情報に限られます。例えば、食べ物の味や匂い、音、触感など、具体的な経験に基づく知識は持っているかもしれませんが、それ以上の抽象的な概念や論理的推論には対応できないでしょう。\n",
      "\n",
      "さらに、純粋理性批判は言語と認識の関係、因果関係、時間と空間の概念など、非常に専門的なテーマを扱っています。これらの概念は、人間特有のものであり、動物には直接適用することが難しいです。したがって、たぬきが純粋理性批判を理解することは現実的には不可能と言えるでしょう。\n",
      "\n",
      "結論として、たぬきに純粋理性批判を理解することは非常に困難であり、その理由はたぬきが人間のような高度な認知能力や抽象的思考を持たないためです。たぬきが理解できるのは、基本的な感覚や経験に基づく情報に限られ、哲学的な議論や複雑な理論には対応できないでしょう。\n"
     ]
    }
   ],
   "source": [
    "# モデルを使用して応答を生成\n",
    "output_ids = model.generate(input_ids, max_new_tokens=1024, temperature=0.5, streamer=streamer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97608012-1273-4702-b3d1-2f7931d902fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 応答生成関数の定義\n",
    "DEFAULT_SYSTEM_PROMPT = \"以下は、タスクを説明する指示です。要求を適切に満たす応答を書きなさい。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77b5760a-67ab-4d88-bfbd-789b778e7768",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": DEFAULT_SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "    input_ids = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\").to(model.device)\n",
    "    output_ids = model.generate(input_ids, max_new_tokens=1024, temperature=0.5, streamer=streamer)\n",
    "    return tokenizer.decode(output_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f083a206-f46e-4099-ac4d-3724b4290f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The question of how many helicopters a human can eat in one sitting is highly speculative and not based on scientific evidence. Eating helicopters is a fictional concept and is not something that can be accurately quantified or measured in real-world terms.\n",
      "\n",
      "In reality, a human can consume a variety of foods, but the number of items they can eat in one sitting is limited by factors such as stomach capacity, the time available for eating, and the nutritional needs of the body. A typical adult can comfortably consume several meals a day, but the exact number can vary greatly depending on individual dietary preferences, health conditions, and the type of food consumed.\n",
      "\n",
      "If we were to entertain the idea of eating helicopters, it would be purely hypothetical and not something that can be quantified in a meaningful way. The concept of a \"helicopter meal\" would likely involve consuming a large quantity of food, but the number would be determined by the size and nutritional content of the helicopters being eaten, rather than the human capacity to consume them.\n",
      "\n",
      "In conclusion, there is no practical or scientific basis for determining how many helicopters a human can eat in one sitting. The question is more of a humorous or imaginative one rather than a factual one.\n",
      "以下は、タスクを説明する指示です。要求を適切に満たす応答を書きなさい。\n",
      "\n",
      "### 指示:\n",
      "How many helicopters can a human eat in one sitting?\n",
      "\n",
      "### 応答:\n",
      "The question of how many helicopters a human can eat in one sitting is highly speculative and not based on scientific evidence. Eating helicopters is a fictional concept and is not something that can be accurately quantified or measured in real-world terms.\n",
      "\n",
      "In reality, a human can consume a variety of foods, but the number of items they can eat in one sitting is limited by factors such as stomach capacity, the time available for eating, and the nutritional needs of the body. A typical adult can comfortably consume several meals a day, but the exact number can vary greatly depending on individual dietary preferences, health conditions, and the type of food consumed.\n",
      "\n",
      "If we were to entertain the idea of eating helicopters, it would be purely hypothetical and not something that can be quantified in a meaningful way. The concept of a \"helicopter meal\" would likely involve consuming a large quantity of food, but the number would be determined by the size and nutritional content of the helicopters being eaten, rather than the human capacity to consume them.\n",
      "\n",
      "In conclusion, there is no practical or scientific basis for determining how many helicopters a human can eat in one sitting. The question is more of a humorous or imaginative one rather than a factual one.\n",
      "CPU times: user 42.6 s, sys: 0 ns, total: 42.6 s\n",
      "Wall time: 42.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# サンプルテキストを使用して応答を生成\n",
    "text = \"How many helicopters can a human eat in one sitting?\"\n",
    "print(generate_response(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38fadb03-0c2e-45d0-af8a-ce641bd51143",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "日本には多くの魅力的な観光地がありますが、特にお薦めの場所を五つご紹介します。まず、東京は現代と伝統が融合した都市で、浅草寺やスカイツリー、渋谷のスクランブル交差点など、見どころがたくさんあります。次に、京都は歴史と文化の宝庫で、金閣寺や清水寺、伏見稲荷大社など、美しい寺院や神社が点在しています。\n",
      "\n",
      "また、北海道も外せません。特に札幌と美瑛・富良野の風景は四季折々の美しさを楽しむことができ、冬には雪まつりも開催されます。さらに、沖縄は南国のリゾート地として有名で、美しいビーチや独自の文化、美味しい料理が魅力です。最後に、広島は平和記念公園や原爆ドームを通じて戦争の歴史を学びつつ、宮島の厳島神社や瀬戸内海の美しい島々を楽しむことができます。\n",
      "\n",
      "これらの場所はそれぞれ異なる魅力を持ち、日本の多様な魅力を存分に味わうことができるでしょう。\n",
      "以下は、タスクを説明する指示です。要求を適切に満たす応答を書きなさい。\n",
      "\n",
      "### 指示:\n",
      "日本でお薦めの観光地を5つあげてください。\n",
      "\n",
      "### 応答:\n",
      "日本には多くの魅力的な観光地がありますが、特にお薦めの場所を五つご紹介します。まず、東京は現代と伝統が融合した都市で、浅草寺やスカイツリー、渋谷のスクランブル交差点など、見どころがたくさんあります。次に、京都は歴史と文化の宝庫で、金閣寺や清水寺、伏見稲荷大社など、美しい寺院や神社が点在しています。\n",
      "\n",
      "また、北海道も外せません。特に札幌と美瑛・富良野の風景は四季折々の美しさを楽しむことができ、冬には雪まつりも開催されます。さらに、沖縄は南国のリゾート地として有名で、美しいビーチや独自の文化、美味しい料理が魅力です。最後に、広島は平和記念公園や原爆ドームを通じて戦争の歴史を学びつつ、宮島の厳島神社や瀬戸内海の美しい島々を楽しむことができます。\n",
      "\n",
      "これらの場所はそれぞれ異なる魅力を持ち、日本の多様な魅力を存分に味わうことができるでしょう。\n",
      "CPU times: user 33.3 s, sys: 0 ns, total: 33.3 s\n",
      "Wall time: 33.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text = \"日本でお薦めの観光地を5つあげてください。\"\n",
    "print(generate_response(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "775bfaa3-b4e7-4d3b-90e3-7d5647ada832",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "日本で二番目に高い山は富士山（ふじさん）です。富士山はその美しい円錐形の姿から国内外で非常に有名で、標高は3,776メートルです。富士山は静岡県と山梨県にまたがっており、特に静岡県側からのアクセスが一般的です。また、富士山は日本最高峰の富士山（標高3,776メートル）とともに、多くの登山者や観光客に親しまれています。\n",
      "以下は、タスクを説明する指示です。要求を適切に満たす応答を書きなさい。\n",
      "\n",
      "### 指示:\n",
      "日本で二番目に高い山を検討して答えてください。\n",
      "\n",
      "### 応答:\n",
      "日本で二番目に高い山は富士山（ふじさん）です。富士山はその美しい円錐形の姿から国内外で非常に有名で、標高は3,776メートルです。富士山は静岡県と山梨県にまたがっており、特に静岡県側からのアクセスが一般的です。また、富士山は日本最高峰の富士山（標高3,776メートル）とともに、多くの登山者や観光客に親しまれています。\n",
      "CPU times: user 16.1 s, sys: 0 ns, total: 16.1 s\n",
      "Wall time: 16.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text = \"日本で二番目に高い山を検討して答えてください。\"\n",
    "print(generate_response(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1458937e-7928-4259-b0c8-1e7efc790445",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "日本で最も高い山は富士山（ふじさん）ではなく、実際には標高3,776メートルの「エベレスト山」が世界で最も高い山です。富士山は日本国内で最も高い山であり、その標高は3,776メートルですが、エベレスト山には及びません。したがって、「日本で1番目に高い山」という質問に対しては、富士山が該当しますが、二番目に高い山として「エベレスト山」を挙げるのは誤りです。エベレスト山が世界最高峰であるため、日本国内で二番目に高い山という概念は存在しません。\n",
      "以下は、タスクを説明する指示です。要求を適切に満たす応答を書きなさい。\n",
      "\n",
      "### 指示:\n",
      "日本で1番目に高い山を検討して答えてください。二番目に高い山は富士山(ふじさん)なのは本当ですか?\n",
      "\n",
      "### 応答:\n",
      "日本で最も高い山は富士山（ふじさん）ではなく、実際には標高3,776メートルの「エベレスト山」が世界で最も高い山です。富士山は日本国内で最も高い山であり、その標高は3,776メートルですが、エベレスト山には及びません。したがって、「日本で1番目に高い山」という質問に対しては、富士山が該当しますが、二番目に高い山として「エベレスト山」を挙げるのは誤りです。エベレスト山が世界最高峰であるため、日本国内で二番目に高い山という概念は存在しません。\n",
      "CPU times: user 20.3 s, sys: 0 ns, total: 20.3 s\n",
      "Wall time: 20.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text = \"日本で1番目に高い山を検討して答えてください。二番目に高い山は富士山（ふじさん）なのは本当ですか？\"\n",
    "print(generate_response(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b49f53-2de0-44ca-a0c7-37800284027b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
