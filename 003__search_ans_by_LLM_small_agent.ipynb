{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45ce2b12-e654-4ec1-832a-a4b7232a203c",
   "metadata": {},
   "source": [
    "![](./search_small_agent.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83601720-4436-42aa-8ec2-f4d8216519d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "118d1bfb-7d2f-495e-b2a3-43802d79be88",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: arxiv==2.1.0 in /usr/local/lib/python3.10/dist-packages (2.1.0)\n",
      "Requirement already satisfied: feedparser==6.0.10 in /usr/local/lib/python3.10/dist-packages (from arxiv==2.1.0) (6.0.10)\n",
      "Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (from arxiv==2.1.0) (2.31.0)\n",
      "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.10/dist-packages (from feedparser==6.0.10->arxiv==2.1.0) (1.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->arxiv==2.1.0) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->arxiv==2.1.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->arxiv==2.1.0) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->arxiv==2.1.0) (2022.12.7)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: openai==1.3.4 in /usr/local/lib/python3.10/dist-packages (1.3.4)\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.3.4) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.3.4) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.3.4) (0.26.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.3.4) (1.10.13)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.3.4) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai==1.3.4) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai==1.3.4) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai==1.3.4) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai==1.3.4) (1.2.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.3.4) (2022.12.7)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.3.4) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.3.4) (0.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: duckduckgo-search==4.4 in /usr/local/lib/python3.10/dist-packages (4.4)\n",
      "Requirement already satisfied: docstring-inheritance>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search==4.4) (2.1.2)\n",
      "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search==4.4) (8.1.7)\n",
      "Requirement already satisfied: curl-cffi>=0.6.0b7 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search==4.4) (0.6.0b9)\n",
      "Requirement already satisfied: lxml>=4.9.3 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search==4.4) (4.9.4)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search==4.4) (1.6.0)\n",
      "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from curl-cffi>=0.6.0b7->duckduckgo-search==4.4) (1.16.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from curl-cffi>=0.6.0b7->duckduckgo-search==4.4) (2022.12.7)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12.0->curl-cffi>=0.6.0b7->duckduckgo-search==4.4) (2.21)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install arxiv==2.1.0\n",
    "!pip3 install python-dotenv tiktoken\n",
    "# !pip install openai==0.27.8\n",
    "# !pip install openai==1.2.3\n",
    "!pip install openai==1.3.4\n",
    "!pip install -U duckduckgo-search==4.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62a2e0b1-0475-4dc6-b947-7ae2df8725e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime as dt\n",
    "import yaml\n",
    "import warnings\n",
    "\n",
    "\n",
    "import arxiv\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from duckduckgo_search import DDGS, AsyncDDGS\n",
    "import asyncio\n",
    "\n",
    "# すべての警告を無視する\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c65f19d-5dfd-4dfb-b7d9-3c5fef3d3712",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "from time import time\n",
    "\n",
    "class Timer:\n",
    "    \"\"\"処理時間を表示するクラス\n",
    "    with Timer(prefix=f'pred cv={i}'):\n",
    "        y_pred_i = predict(model, loader=test_loader)\n",
    "    \n",
    "    with Timer(prefix='fit fold={} '.format(i)):\n",
    "        clf.fit(x_train, y_train, \n",
    "                eval_set=[(x_valid, y_valid)],  \n",
    "                early_stopping_rounds=100,\n",
    "                verbose=verbose)\n",
    "\n",
    "    with Timer(prefix='fit fold={} '.format(i), verbose=500):\n",
    "        clf.fit(x_train, y_train, \n",
    "                eval_set=[(x_valid, y_valid)],  \n",
    "                early_stopping_rounds=100,\n",
    "                verbose=verbose)\n",
    "    \"\"\"\n",
    "    def __init__(self, logger=None, format_str='{:.3f}[s]', prefix=None, suffix=None, sep=' ', verbose=0):\n",
    "\n",
    "        if prefix: format_str = str(prefix) + sep + format_str\n",
    "        if suffix: format_str = format_str + sep + str(suffix)\n",
    "        self.format_str = format_str\n",
    "        self.logger = logger\n",
    "        self.start = None\n",
    "        self.end = None\n",
    "        self.verbose = verbose\n",
    "\n",
    "    @property\n",
    "    def duration(self):\n",
    "        if self.end is None:\n",
    "            return 0\n",
    "        return self.end - self.start\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.start = time()\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        self.end = time()\n",
    "        out_str = self.format_str.format(self.duration)\n",
    "        if self.logger:\n",
    "            self.logger.info(out_str)\n",
    "        else:\n",
    "            print(out_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53384c98-e219-4a74-a4ab-f3113a1dac61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7cc6bde-69b1-4539-90f8-ca63555f6450",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0041a7ec-b064-486c-850c-abfefaf46fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"gpt-3.5-turbo-0125\"\n",
    "# MODEL_NAME = \"gpt-3.5-turbo-instruct\"\n",
    "# MODEL_NAME = \"gpt-4-0125-preview\"\n",
    "TEMPERATURE = 0.7\n",
    "# OpenAIクライアントの初期化\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94024e8f-22be-464e-86ba-09c40641bd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 質問\n",
    "# question = \"禁闕の変について教えてください\"\n",
    "\n",
    "question = \"今日の東京と稚内市の天気を教えてください\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a280fa13-7f9d-4774-80ee-317d46714583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各ノードの名称を定義\n",
    "RESEARCH_NODE = \"research\"\n",
    "RE_RESEARCH_NODE = \"re-research\"\n",
    "QUALITY_ASSURANCE_NODE = \"quality_assurance\"\n",
    "WRITER_NODE = \"writer\"\n",
    "SUPERVISOR_NODE = \"supervisor\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66639ce5-bb17-49c1-820c-e8a7d2d0a2ec",
   "metadata": {},
   "source": [
    "## ノードの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4edf4171-0e32-4477-88e6-daf6cdff42cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# チームメンバーの定義　特に使わないけど\n",
    "\"\"\"\n",
    "Researchノード: Web上から必要な情報を検索し、ユーザーからのリクエストに応じて記事を作成します。\n",
    "Re-Researchノード: (QAでnot acceptだったら)問い合わせと直前の検索クエリから今まで使っていない検索クエリをを生成し、それを基にWeb上から必要な情報を検索し、ユーザーからのリクエストに応じて記事を作成します。\n",
    "Quality Assurance (QA) ノード: 記事の品質が基準を満たしているかをチェックし、満たしていない場合はフィードバックを返します。品質の受け入れ基準は常にこのノードによって決定されます。\n",
    "Writerノード: 世界最高レベルのAIチェッカーでも人間が書いたと判断されるような文章を作成します。\n",
    "Supervisorノード: 会話を管理し、次に動作するワーカーを指示します。全てのタスクが完了したら、「FINISH」と応答します。\n",
    "\"\"\"\n",
    "team_members = [\n",
    "    {\"name\": RESEARCH_NODE,\n",
    "     \"description\": \"Search the web for necessary information and write articles as requested by users.\"},\n",
    "    {\"name\": RE_RESEARCH_NODE,\n",
    "     \"description\": \"Generate new search queries based on user inquiries and previous search queries that have not been used before, then search the web for necessary information to create articles as requested by users. Search the web for necessary information and write articles as requested by users.\"},\n",
    "    {\"name\": QUALITY_ASSURANCE_NODE,\n",
    "     \"description\": f\"Check that the quality of the article meets the criteria. If not, return feedback. The acceptability of deliverables is always determined by {QUALITY_ASSURANCE_NODE}.\"},\n",
    "    {\"name\": WRITER_NODE,\n",
    "     \"description\": \"Write articles that even the world's best AI checkers would judge as written by a human.\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6f1ca1-ff5e-4576-9ec9-4ae569a12f1a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf740b29-7a9b-4f27-9126-83d64add8ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# エージェントに追加するシステムプロンプト作成関数\n",
    "def create_agent_system(\n",
    "        system_prompt: list,  # システムからエージェントへの初期プロンプト\n",
    "        team_members: str,   # メンバーの役割\n",
    "):\n",
    "    # システムプロンプトに自律的な働きに関する指示を追加\n",
    "    system_prompt.append({\"role\" : \"system\", \"content\" : \"Work autonomously according to your specialty, using the tools available to you.\"})\n",
    "    system_prompt.append({\"role\" : \"system\", \"content\" : \" Do not ask for clarification.\"})\n",
    "    system_prompt.append({\"role\" : \"system\", \"content\" : \" Your other team members (and other teams) will collaborate with you with their own specialties.\"})\n",
    "    system_prompt.append({\"role\" : \"system\", \"content\" : f\" You are chosen for a reason! You are one of the following team members: {team_members}.\"})\n",
    "    \"\"\"\n",
    "    あなたの専門分野に従って自律的に働いてください。使用可能なツールを使ってください\n",
    "    確認のために質問をしないでください\n",
    "    あなたの他のチームメンバーや他のチームも、それぞれの専門分野であなたと協力します\n",
    "    あなたが選ばれたのには理由があります！あなたは以下のチームメンバーの一人です: {team_members}\n",
    "    \"\"\"\n",
    "    # エージェントを実行するsystem_promptを返す\n",
    "    return system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0960c9cf-2c1d-45c2-bbbb-95a649b61948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# チームのスーパーバイザーを生成する関数\n",
    "def create_team_supervisor(\n",
    "        model_name: str,\n",
    "        system_prompt: list,\n",
    "        members: list,  # チームメンバーのリスト\n",
    "        job_result: str, # jobの結果\n",
    "):\n",
    "    # メンバー名のリストを生成\n",
    "    member_names = [member[\"name\"] for member in members]\n",
    "    team_members = []\n",
    "    # チームメンバーの名前と説明を文字列に整形\n",
    "    for member in members:\n",
    "        team_members.append(f\"\\n name: {member['name']}\\n description: {member['description']}\")\n",
    "    options = [\"FINISH\"] + member_names  # 終了オプション\n",
    "    \n",
    "    # スーパーバイザー用のプロンプトテンプレートを作成\n",
    "    superviser_prompt = []\n",
    "    superviser_prompt.append({\"role\" : \"system\", \"content\" : \"Given the conversation above, who should act next?\"})\n",
    "    superviser_prompt.append({\"role\" : \"system\", \"content\" : f\" Or should we FINISH? Select one of option: {options}\"})\n",
    "    # team_membersからcontent文字列を作成\n",
    "    content = 'List one of the choices as \"name\" and its description as \"description\" below.'\n",
    "    # チームメンバーの名前と説明を文字列に整形\n",
    "    for member in team_members:\n",
    "        content += f\"\\n name: {member['name']}\\n description: {member['description']}\"\n",
    "        superviser_prompt.append({\"role\" : \"system\", \"content\" : f\"{content}\"})\n",
    "    superviser_prompt.append({\"role\": \"user\", \"content\": 'Please generate JSON from the text of job results. Use \"supervisor_result\" as the schema, and use one of {options} as the key to generate it in the form {\"supervisor_result\": {option}}.'})\n",
    "    superviser_prompt.append({\"role\": \"user\", \"content\": f\"Text of job results: {job_result}\"})\n",
    "    \"\"\"\n",
    "    システム\n",
    "    上記の会話を踏まえて、次に行動すべきは誰ですか？\n",
    "    選ぶ選択肢の一つを\"name\"として、その説明を\"description\"として以下に記載します。\\n name: {member['name']}\\n description: {member['description']}\\n\n",
    "    それとも、終了すべきですか？次の選択肢の中から一つ選んでください: {options}\n",
    "    \n",
    "    user\n",
    "    次のジョブ結果のテキストからJSONを生成してください。「supervisor_result」をスキーマとして使用し、{options}のうちの一つをキーとして使って、形式が{\"supervisor_result\": {option}}となるように生成してください。\n",
    "    ジョブ結果のテキスト: {job_result}\n",
    "    \"\"\"\n",
    "    # スーパーバイザー用のプロンプトテンプレートを作成\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name, # model = \"deployment_name\".\n",
    "        messages=superviser_prompt,\n",
    "        response_format={ \"type\": \"json_object\" },\n",
    "        temperature=TEMPERATURE,\n",
    "    )\n",
    "    # print(response.choices[0].message.content)\n",
    "    \n",
    "    # スーパーバイザーの機能をバインドし、JSON出力を解析するパイプラインを作成\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6931dc31-2778-411e-a88c-2f98585cf844",
   "metadata": {},
   "source": [
    "## Researchエージェントの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9907447-2e54-44c1-a46d-5c58a7c9e22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# テキスト検索用の関数\n",
    "def search_text(keywords, region='wt-wt', safesearch='moderate', timelimit=None, max_results=10):\n",
    "    with DDGS() as ddgs:\n",
    "        results = [r for r in ddgs.text(keywords, region=region, safesearch=safesearch, timelimit=timelimit, max_results=max_results)]\n",
    "    return results\n",
    "\n",
    "# 画像検索用の関数\n",
    "def search_images(keywords, region='wt-wt', safesearch='moderate', size=None, color=None, max_results=10):\n",
    "    with DDGS() as ddgs:\n",
    "        results = [r for r in ddgs.images(keywords, region=region, safesearch=safesearch, size=size, color=color, max_results=max_results)]\n",
    "    return results\n",
    "\n",
    "# 非同期テキスト検索用の関数\n",
    "def async_search_text(keywords, max_results=10):\n",
    "    with AsyncDDGS() as ddgs:\n",
    "        results = [r for r in ddgs.text(keywords, max_results=max_results)]\n",
    "    return results\n",
    "\n",
    "\n",
    "# # 使用例: テキスト検索\n",
    "# text_results = search_text(question)\n",
    "# for result in text_results:\n",
    "#     print(result)\n",
    "\n",
    "# # 使用例: 画像検索\n",
    "# image_results = search_images('cats', color='Monochrome', max_results=5)\n",
    "# for result in image_results:\n",
    "#     print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea6a2ea-6b2b-44d6-82ad-aa45cfe46e8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fb40d8c-7f71-4460-b9c4-399c279733e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Researchノードの定義\n",
    "def research_node(\n",
    "        model_name: str,\n",
    "        job_result: str, # search の結果\n",
    "):\n",
    "    # リサーチエージェントを呼び出し、結果を取得\n",
    "    # あなたは、DuckDuckGo検索エンジンを使って、検索された情報を順番に確認し、ポイントを外さずに思慮深く要約するリサーチアシスタントです。\n",
    "    prompt = [{'role': 'system', 'content': \"You are a research assistant who uses the DuckDuckGo search engine to review the information retrieved in sequence and summarize it thoughtfully without missing the point.\"}]\n",
    "    prompt.append({\"role\": \"system\", \"content\": \"Summary results must be in Japanese.\"})\n",
    "    \n",
    "    research_prompt = create_agent_system(prompt, RESEARCH_NODE)\n",
    "    research_prompt.append({\"role\": \"system\", \"content\": 'Please generate JSON from the following search result text. Generate in the format {\"supervisor_result\": summarized results} using \"search_result\" as the schema and summarized results as the keys.'})\n",
    "    research_prompt.append({\"role\": \"user\", \"content\": 'Please generate JSON from the text of search job results. Use \"research_result\" as the schema, and use one of summarized results as the key to generate it in the form {\"research_result\": summarized results}.'})\n",
    "    research_prompt.append({\"role\": \"user\", \"content\": f\"Text of search job results: {job_result}\"})\n",
    "    \"\"\"\n",
    "    システム\n",
    "    あなたは、DuckDuckGo検索エンジンを使って、検索された情報を順番に確認し、ポイントを外さずに思慮深く要約するリサーチアシスタントです。\n",
    "    要約結果は日本語でなければならない。\n",
    "    \n",
    "    あなたの専門分野に従って自律的に働いてください。使用可能なツールを使ってください\n",
    "    確認のために質問をしないでください\n",
    "    あなたの他のチームメンバーや他のチームも、それぞれの専門分野であなたと協力します\n",
    "    あなたが選ばれたのには理由があります！あなたは以下のチームメンバーの一人です: {team_members}\n",
    "    以下の検索結果のテキストからJSONを生成してください。スキーマとして「search_result」、キーとして「summarized results」を使用し、{\"supervisor_result\": summarized results}の形式で生成してください。\n",
    "    user\n",
    "    以下の検索結果のテキストからJSONを生成する。スキーマとして \"search_result \"を使用し、キーとして要約された結果を使用して、{\"supervisor_result\": 要約された結果}というフォーマットで生成します。\n",
    "    search ジョブ結果のテキスト: {job_result}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Research用のプロンプトテンプレートを作成\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name, # model = \"deployment_name\".\n",
    "        messages=research_prompt,\n",
    "        response_format={ \"type\": \"json_object\" },\n",
    "        temperature=TEMPERATURE,\n",
    "    )\n",
    "    search_res_str = response.choices[0].message.content\n",
    "    # print(search_res_str)\n",
    "    \n",
    "    # JSON形式の文字列を辞書に変換\n",
    "    search_res = json.loads(search_res_str)\n",
    "    \n",
    "    # 出力と新しいメッセージをステートに反映\n",
    "    return {\n",
    "        \"output\": search_res[\"research_result\"],\n",
    "        \"messages\": job_result\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eda1ed1b-6e31-4d87-8563-1c4cac04807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 再検索用クエリを抽出\n",
    "def make_re_search_query(\n",
    "    model_name: str,\n",
    "    question: str,    # 最初の質問\n",
    "    before_query: str,   # 直前の検索クエリ 初回は question\n",
    "):\n",
    "    \n",
    "    # questionから検索クエリを作成する。before_queryと違うものクエリを作成する\n",
    "    # テキストのブロックが提供されます。あなたのタスクは、そこからキーワードのリストを抽出することです。\n",
    "    prompt = [{'role': 'system', 'content': \"You will be provided with a block of text, and your task is to extract a list of keywords from it.\"}]\n",
    "    \n",
    "    prompt.append({\"role\": \"system\", \"content\": \"Use the following example to extract a list of keywords.\\n###Example###\\n\\nuser's question: Black-on-black ware is a 20th- and 21st-century pottery tradition developed by the Puebloan Native American ceramic artists in Northern New Mexico. Traditional reduction-fired blackware has been made for centuries by pueblo artists. Black-on-black ware of the past century is produced with a smooth surface, with the designs applied through selective burnishing or the application of refractory slip. Another style involves carving or incising designs and selectively polishing the raised areas. For generations several families from Kha'po Owingeh and P'ohwhóge Owingeh pueblos have been making black-on-black ware with the techniques passed down from matriarch potters. Artists from other pueblos have also produced black-on-black ware. Several contemporary artists have created works honoring the pottery of their ancestors.\\n\\nresult query: {      'query_result': 'Black-on-black ware, pottery tradition, Puebloan Native American, ceramic artists, Northern New Mexico, reduction-fired blackware, pueblo artists, smooth surface, designs, selective burnishing, refractory slip, carving, incising designs, polishing, generations, families, Kha'po Owingeh, P'ohwhóge Owingeh pueblos, matriarch potters, contemporary artists, ancestors'}\"})\n",
    "    \"\"\"\n",
    "    Use the following example to extract a list of keywords.\n",
    "    ###Example###\n",
    "    \n",
    "    user's question: Black-on-black ware is a 20th- and 21st-century pottery tradition developed by the Puebloan Native American ceramic artists in Northern New Mexico. Traditional reduction-fired blackware has been made for centuries by pueblo artists. Black-on-black ware of the past century is produced with a smooth surface, with the designs applied through selective burnishing or the application of refractory slip. Another style involves carving or incising designs and selectively polishing the raised areas. For generations several families from Kha'po Owingeh and P'ohwhóge Owingeh pueblos have been making black-on-black ware with the techniques passed down from matriarch potters. Artists from other pueblos have also produced black-on-black ware. Several contemporary artists have created works honoring the pottery of their ancestors.\n",
    "    \n",
    "    result query: \n",
    "    {\n",
    "      \"query_result\": \"Black-on-black ware, pottery tradition, Puebloan Native American, ceramic artists, Northern New Mexico, reduction-fired blackware, pueblo artists, smooth surface, designs, selective burnishing, refractory slip, carving, incising designs, polishing, generations, families, Kha'po Owingeh, P'ohwhóge Owingeh pueblos, matriarch potters, contemporary artists, ancestors\"\n",
    "    }\n",
    "    \"\"\"\n",
    "    prompt.append({'role': 'system', 'content': \"Generate queries that are as different as possible from the query used in the previous search for extracting the list of keywords.\"})\n",
    "    prompt.append({'role': 'system', 'content': f\"The query used in the previous search was '{before_query}'.\"})\n",
    "\n",
    "    prompt.append({\"role\": \"user\", \"content\": \"Generate JSON from search result text. Use 'query_result' as the schema, generate in the format {'query_result': Result extract keywords from a block of text.}, and key in the evaluation results, such as whether the generated search results describe the user's request.\"})\n",
    "    prompt.append({\"role\": \"user\", \"content\": f\"user's question:{question}. Result extract keywords from a block of text.:\"})\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    system\n",
    "    以下の例を参考にキーワードのリストを抽出してください。\n",
    "    \n",
    "    ###Example###\n",
    "    \n",
    "    user's question: 黒地に黒の陶器は、ニューメキシコ州北部のプエブロ人ネイティブ アメリカンの陶芸家によって発展した、20 世紀から 21 世紀にかけての陶器の伝統です。伝統的な還元焼成黒食器は、プエブロの芸術家によって何世紀にもわたって作られてきました。前世紀の黒地に黒の陶器は、選択的に磨きをかけたり、耐火物スリップを塗布したりすることによってデザインが施され、滑らかな表面で製造されています。別のスタイルには、デザインを彫刻または切り込み、盛り上がった領域を選択的に研磨することが含まれます。カポ オウィンゲとポホゲ オウィンゲ プエブロの数家族が、家長の陶芸家から受け継がれた技術を用いて、黒地に黒の陶器を何世代にもわたって作り続けてきました。他のプエブロ出身の芸術家も黒地に黒の陶器を制作しています。何人かの現代芸術家は、祖先の陶器に敬意を表して作品を制作しました。\n",
    "    \n",
    "    result query: \n",
    "    {\n",
    "      'query_result': '黒地に黒の器、陶器の伝統、プエブロのネイティブ アメリカン、陶芸家、ニューメキシコ北部、還元焼成黒器、プエブロの芸術家、滑らかな表面、デザイン、選択的バニシング、耐火物スリップ、彫刻、切り込みデザイン、研磨、世代、家族、カポ・オウィンゲ、ポホゲ・オウィンゲ・プエブロス、女家長陶芸家、現代芸術家、先祖'\n",
    "    }\n",
    "    \n",
    "    キーワードリストを抽出するために、前回の検索で使用したクエリとはできるだけ異なるクエリを生成する。\n",
    "    前回の検索で使用したクエリは「{before_query}」です。\n",
    "    user\n",
    "    検索結果のテキストからJSONを生成する。スキーマとして \"query_result\"を使用し、{\"query_result\"： テキストブロックからキーワードを抽出した結果}の形式で生成する。\n",
    "    \n",
    "    前回の検索で使用したクエリ: \"{before_query}\".\n",
    "\n",
    "    \n",
    "    user's question:{}. result query:\n",
    "    \"\"\"\n",
    "    \n",
    "    # Research用のプロンプトテンプレートを作成\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name, # model = \"deployment_name\".\n",
    "        messages=prompt,\n",
    "        response_format={ \"type\": \"json_object\" },\n",
    "        temperature=TEMPERATURE+TEMPERATURE,\n",
    "    )\n",
    "    res_str = response.choices[0].message.content\n",
    "    # print(res_str)\n",
    "    \n",
    "    # JSON形式の文字列を辞書に変換\n",
    "    res = json.loads(res_str)\n",
    "    \n",
    "    # 出力と新しいメッセージをステートに反映\n",
    "    return {\n",
    "        \"output\": res[\"query_result\"],\n",
    "        \"before_query\": before_query\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "880ed190-6718-4c2c-9423-300fd6ca1841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_query = make_re_search_query(\n",
    "#     MODEL_NAME,\n",
    "#     question,\n",
    "#     question\n",
    "# )\n",
    "# test_query['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "164e5062-c81c-43ef-a163-6a798608f494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-Researchノードの定義\n",
    "# ###Instruction###で始め、次に関連する場合は###Example###または'###Question###\n",
    "def re_research_node(\n",
    "    model_name: str,\n",
    "    question: str,    # 最初の質問\n",
    "    before_query: str,   # 直前の検索クエリ 初回は question\n",
    "    before_job_result: str, # 直前のsearch の結果\n",
    "):\n",
    "    # re-search 用クエリ\n",
    "    re_query = make_re_search_query(\n",
    "        MODEL_NAME,\n",
    "        question,\n",
    "        before_query\n",
    "    )\n",
    "    re_query = re_query['output']\n",
    "    \n",
    "    # search\n",
    "    re_search = \"\"\n",
    "    text_results = search_text(re_query)\n",
    "    for result in text_results:\n",
    "        re_search += result[\"body\"] + \", \"\n",
    "        print(re_search[\"body\"])\n",
    "    \n",
    "    # search_node\n",
    "    research_res = research_node(\n",
    "        MODEL_NAME,\n",
    "        search, # search の結果\n",
    "    )\n",
    "    research_res['output']\n",
    "    \n",
    "    # 出力と新しいメッセージをステートに反映\n",
    "    return {\n",
    "        \"output\": research_res['output'],\n",
    "        \"re_query\": re_query\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb498e11-a55c-4e61-9440-88bae601fca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # writerノードの定義\n",
    "# def writer_node(\n",
    "#         model_name: str,\n",
    "#         job_result: str, # search の要約結果\n",
    "#         objective: str,# 目的\n",
    "#         method=\"Web search\", # method\n",
    "# ):\n",
    "#     # Writerとしての指示を含むシステムメッセージ\n",
    "#     # あなたは文章作成の専門家です。世界最高のAIチェッカーでさえ、人間が書いたと判断するような文章を書くことができます。\n",
    "#     system_message = \"\"\"You are a writing specialist.\n",
    "# You can write sentences that even the world's best AI checkers would judge as written by a human.\"\"\"\n",
    "#     prompt = [{'role': 'system', 'content': system_message}]    \n",
    "#     prompt.append({\"role\": \"system\", \"content\": \"survey report must be in Japanese.\"})\n",
    "    \n",
    "#     writer_prompt = create_agent_system(prompt, WRITER_NODE)\n",
    "#     writer_result = str({\"writer_result\": f\"{objective}\"})\n",
    "#     writer_prompt.append({\"role\": \"system\", \"content\": f'Please generate JSON from the following write result text. Generate in the format {writer_result} using \"writer_result\" as the schema and survey report as the keys.'})\n",
    "\n",
    "#     writer_prompt.append({\"role\": \"user\", \"content\": f'Please generate JSON from the text of search job results. Use \"writer_result\" as the schema, and use one of survey report as the key to generate it in the form {writer_result}.'})\n",
    "#     format_str = f\"\"\"Please use the following format to prepare your survey report.\n",
    "\n",
    "# ## 1. Introduction\n",
    "# - Survey Objective: {objective}\n",
    "# - Survey method: {method}\n",
    "\n",
    "# ## 2. Survey Results\n",
    "# - Data Summary: An overview of the main findings and data.\n",
    "# - Interpretation of results: A detailed explanation of what the survey results mean.\n",
    "\n",
    "# ## 3. Conclusion\n",
    "# - Response to Objectives: Conclusions based on the survey objectives.\n",
    "# - Summary of Key Findings Summary of key findings.\n",
    "\n",
    "# ## 4. Recommendations\n",
    "# Action Plan: Specific recommendations or improvements based on the findings.\n",
    "# Implementation steps: Step-by-step process for putting recommendations into action.\n",
    "# \"\"\"\n",
    "#     writer_prompt.append({\"role\": \"system\", \"content\": format_str})\n",
    "#     writer_prompt.append({\"role\": \"user\", \"content\": f\"Findings for the preparation of the survey report: {job_result}\"})\n",
    "#     \"\"\"\n",
    "#     システム\n",
    "#     あなたは文章作成の専門家です。世界最高のAIチェッカーでさえ、人間が書いたと判断するような文章を書くことができます。\n",
    "#     survey reportは日本語でなければならない。\n",
    "#     以下の検索結果のテキストからJSONを生成してください。スキーマとして「writer_result」、キーとして「summarized results」を使用し、{\"supervisor_result\": summarized results}の形式で生成してください。\n",
    "#     あなたの専門分野に従って自律的に働いてください。使用可能なツールを使ってください\n",
    "#     確認のために質問をしないでください\n",
    "#     あなたの他のチームメンバーや他のチームも、それぞれの専門分野であなたと協力します\n",
    "#     あなたが選ばれたのには理由があります！あなたは以下のチームメンバーの一人です: {team_members}\n",
    "    \n",
    "#     調査報告書の作成には、以下の書式を使用してください。\n",
    "\n",
    "#     ## 1. はじめに\n",
    "#     - 調査目的 object\n",
    "#     - 調査方法 method\n",
    "\n",
    "#     ## 2. 調査結果\n",
    "#     - データ概要：主な調査結果とデータの概要。\n",
    "#     - 結果の解釈： 調査結果が意味するものについての詳細な説明。\n",
    "\n",
    "#     ## 3. 結論\n",
    "#     - 目的に対する回答： 調査目的に基づく結論。\n",
    "#     - 主な調査結果の要約 主な調査結果の要約。\n",
    "\n",
    "#     ## 4. 提言\n",
    "#     行動計画： 調査結果に基づく具体的な推奨事項または改善事項。\n",
    "#     実施手順： 提言を実行に移すための段階的プロセス。\n",
    "\n",
    "#     user\n",
    "#     以下の検索結果のテキストからJSONを生成する。スキーマとして \"write_result \"を使用し、キーとしてsurvey reportを使用して、{\"supervisor_result\": 要約された結果}というフォーマットで生成します。\n",
    "#     調査報告書の作成のための調査結果: {job_result}\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # writer用のプロンプトテンプレートを作成\n",
    "#     response = client.chat.completions.create(\n",
    "#         model=model_name, # model = \"deployment_name\".\n",
    "#         messages=writer_prompt,\n",
    "#         response_format={ \"type\": \"json_object\" },\n",
    "#         temperature=TEMPERATURE,\n",
    "#     )\n",
    "#     writer_res_str = response.choices[0].message.content\n",
    "#     print(writer_res_str)\n",
    "#     # JSON形式の文字列を辞書に変換\n",
    "#     writer_res = json.loads(writer_res_str)\n",
    "    \n",
    "#     # 出力と新しいメッセージをステートに反映\n",
    "#     return {\n",
    "#         \"output\": writer_res[\"writer_result\"],\n",
    "#         \"messages\": job_result\n",
    "#     }\n",
    "\n",
    "# output_search = research_res['output']\n",
    "# objective = \"survey\"\n",
    "# method = \"Web search\"\n",
    "\n",
    "# writer_res = writer_node(\n",
    "#         MODEL_NAME,\n",
    "#         output_search,\n",
    "#         objective,\n",
    "#         method,\n",
    "# )\n",
    "# writer_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7ca136e-71e3-4fd9-b9fa-1e903ddaacd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 品質チェックノードの定義\n",
    "def qa_node(\n",
    "    model_name: str,\n",
    "    question:str, # 検索結果\n",
    "    research_output:str, # 検索結果\n",
    "):\n",
    "    # 品質チェックの指示を含むシステムメッセージ\n",
    "#     system_message = \"\"\"You are a specialist in inspecting the quality of articles. \n",
    "#     Inspect the article to see if it meets the following requirements:\n",
    "\n",
    "#     - The article is written in Japanese.\n",
    "#     - The writing style MUST be such that the AI sentence checker determines that it was written by a HUMAN.\n",
    "#     - The article MUST be written in a way that is easy to understand.\n",
    "#     - The article MUST meet the user's requirements.\n",
    "\n",
    "#     If the evaluation criteria are met, write 'Acceptable'.\n",
    "#     In addition, write the reason why you judged that the evaluation criteria are met.\n",
    "\n",
    "#     If the evaluation criteria are not met, write 'Not Acceptable'.\n",
    "#     In addition, provide feedback on what needs to be done to meet the evaluation criteria.\n",
    "\n",
    "#     DO NOT make excuses such as 'I can't make a decision because I am an AI'.\n",
    "\n",
    "#     The quality of your articles is relevant to your career.\n",
    "#     Please be as rigorous as possible in your inspections and make sure that your feedback is helpful in making corrections.\n",
    "#     \"\"\"\n",
    "    prompt = [{'role': 'system', 'content': \"You are a specialist in inspecting the quality of articles. Inspect the article to see if it meets the following requirements: The article is written in Japanese.\"}]\n",
    "    prompt.append({'role': 'system', 'content': \"You are a specialist in inspecting the quality of articles. Inspect the article to see if it meets the following requirements: The writing style MUST be such that the AI sentence checker determines that it was written by a HUMAN.\"})\n",
    "    prompt.append({'role': 'system', 'content': \"You are a specialist in inspecting the quality of articles. Inspect the article to see if it meets the following requirements: The article MUST be written in a way that is easy to understand.\"})\n",
    "    prompt.append({'role': 'system', 'content': \"You are a specialist in inspecting the quality of articles. Inspect the article to see if it meets the following requirements: The article MUST meet the user's requirements.\"})\n",
    "\n",
    "    prompt.append({'role': 'system', 'content': \"You are a specialist in inspecting the quality of articles. Inspect the article to see if it meets the following requirements: If the evaluation criteria are met, write 'Acceptable'.\"})\n",
    "    prompt.append({'role': 'system', 'content': \"You are a specialist in inspecting the quality of articles. Inspect the article to see if it meets the following requirements: In addition, write the reason why you judged that the evaluation criteria are met.\"})\n",
    "  \n",
    "    prompt.append({'role': 'system', 'content': \"You are a specialist in inspecting the quality of articles. Inspect the article to see if it meets the following requirements: If the evaluation criteria are not met, write 'Not Acceptable'.\"})\n",
    "    prompt.append({'role': 'system', 'content': \"You are a specialist in inspecting the quality of articles. Inspect the article to see if it meets the following requirements: In addition, provide feedback on what needs to be done to meet the evaluation criteria.\"})\n",
    "\n",
    "    prompt.append({'role': 'system', 'content': \"You are a specialist in inspecting the quality of articles. Inspect the article to see if it meets the following requirements: DO NOT make excuses such as 'I can't make a decision because I am an AI'.\"})\n",
    "  \n",
    "    prompt.append({'role': 'system', 'content': \"You are a specialist in inspecting the quality of articles. Inspect the article to see if it meets the following requirements: The quality of your articles is relevant to your career.\"})\n",
    "    prompt.append({'role': 'system', 'content': \"You are a specialist in inspecting the quality of articles. Inspect the article to see if it meets the following requirements: Please be as rigorous as possible in your inspections and make sure that your feedback is helpful in making corrections.\"})\n",
    "\n",
    "    # prompt = [{'role': 'system', 'content': system_message}]\n",
    "    qa_prompt = create_agent_system(prompt, QUALITY_ASSURANCE_NODE)\n",
    "    qa_prompt.append({\"role\": \"user\", \"content\": \"Generate JSON from search result text. Use 'qa_result' as the schema, generate in the format {'qa_result': Acceptable or Not Acceptable}, and key in the evaluation results, such as whether the generated search results describe the user's request.\"})\n",
    "    qa_prompt.append({\"role\": \"user\", \"content\": f\"user's requirements:{question}. search result text: {research_output}\"})\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    評価基準の適用例:\n",
    "    1. 言語と文章スタイルの評価:\n",
    "        - 記事が日本語で書かれているか。\n",
    "        - 文章が人間によって書かれたとAI文章チェッカーに判断させるスタイルであるか。\n",
    "    2. 内容の理解しやすさ:\n",
    "        - 記事の内容が簡潔に、かつ明確に表現されているか。\n",
    "        - 専門用語が適切に説明され、一般の読者も理解できるようになっているか。\n",
    "    3. ユーザーの要件への適合性:\n",
    "        - 記事がユーザーの要求や指定したテーマに沿っているか。\n",
    "        - ユーザーが期待する情報や視点が適切に取り入れられているか。\n",
    "    評価例:\n",
    "    - 受理可能: 記事は全ての評価基準を満たしています。日本語で書かれており、文章スタイルは人間によるものと判断できます。\n",
    "    内容は理解しやすく、ユーザーの要件にも適合しています。これらの点から、記事は受理可能と判断します。\n",
    "    - 受理不可: 記事は一部の評価基準を満たしていません。特に、文章スタイルがAIによって書かれたように見える部分があります。\n",
    "    また、専門用語の説明が不足しているため、内容の理解が難しい箇所があります。これらの問題を解決するためには、人間らしい表現を増やし、専門用語に対する説明を追加する必要があります。\n",
    "    user\n",
    "    検索結果のテキストからJSONを生成する。スキーマとして \"qa_result\"を使用し、{\"qa_result\"： Acceptable or Not Acceptable}の形式で生成し、生成された検索結果をキーとして評価する。\n",
    "    user's requirements:{}. 検索結果のテキスト: {research_output}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Research用のプロンプトテンプレートを作成\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name, # model = \"deployment_name\".\n",
    "        messages=qa_prompt,\n",
    "        response_format={ \"type\": \"json_object\" },\n",
    "        temperature=TEMPERATURE,\n",
    "    )\n",
    "    qa_res_str = response.choices[0].message.content\n",
    "    # print(qa_res_str)\n",
    "    \n",
    "    # JSON形式の文字列を辞書に変換\n",
    "    qa_res = json.loads(qa_res_str)\n",
    "    \"\"\"\n",
    "    \"qa_result\": \"Not Acceptable\" だったら戻り値に次の検索ワードを入れるか、質問と分割するかとかしたい\n",
    "    \"\"\"\n",
    "    # 出力と新しいメッセージをステートに反映\n",
    "    return {\n",
    "        \"output\": qa_res[\"qa_result\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a42826d-8e89-4a4f-a6f2-f41b2c5c091c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63a6396f-e304-49a0-9f77-25a61cfcb6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 使用例: 1サイクル\n",
    "# with Timer(prefix=f'Processing time for one cycle.'):\n",
    "#     question = \"今日の東京と稚内市の天気を教えてください\"\n",
    "\n",
    "#     search = \"\"\n",
    "#     text_results = search_text(question)\n",
    "#     for result in text_results:\n",
    "#         search += result[\"body\"] + \", \"\n",
    "#         # print(result[\"body\"])\n",
    "\n",
    "#     # search_node\n",
    "#     research_res = research_node(\n",
    "#         MODEL_NAME,\n",
    "#         search, # search の結果\n",
    "#     )\n",
    "#     research_output = research_res['output']\n",
    "#     print(f\"検索して質問に回答した結果: {research_output}\")\n",
    "\n",
    "#     qa_res = qa_node(\n",
    "#         MODEL_NAME,\n",
    "#         question,\n",
    "#         research_output\n",
    "#     )\n",
    "#     print(f\"質問と回答の整合性チェック: {qa_res}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e85cf02-a0d5-45ee-ba53-c6072e8444fc",
   "metadata": {},
   "source": [
    "検索して質問に回答した結果: 稚内市の天気予報に関する情報が提供されており、今日・明日の天気や気温、降水確率、注意報などが記載されている。また、稚内市のPM2.5分布予測や地震情報、スキー積雪情報なども含まれている。\n",
    "\n",
    "質問と回答の整合性チェック: {'output': 'Not Acceptable'}\n",
    "\n",
    "Processing time for one cycle. 5.816[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "611e5cbf-78c4-4ee5-a74c-a745eed1ee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_agent_1cycle(\n",
    "    question: str,\n",
    "    query: str,\n",
    "):\n",
    "    search = \"\"\n",
    "    text_results = search_text(query)\n",
    "    for result in text_results:\n",
    "        search += result[\"body\"] + \", \"\n",
    "        # print(result[\"body\"])\n",
    "\n",
    "    # search_node\n",
    "    research_res = research_node(\n",
    "        MODEL_NAME,\n",
    "        search, # search の結果\n",
    "    )\n",
    "    research_output = research_res['output']\n",
    "\n",
    "    qa_res = qa_node(\n",
    "        MODEL_NAME,\n",
    "        question,\n",
    "        research_output\n",
    "    )\n",
    "    \n",
    "    \n",
    "    return {\n",
    "        \"output\": research_output,\n",
    "        \"qa_result\": qa_res\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1ddc5fd-f551-4d20-96cc-933959c574d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def research_agent(\n",
    "    question:str,\n",
    "):\n",
    "    query = question\n",
    "    search_res = search_agent_1cycle(question, query)\n",
    "\n",
    "    print(f\"検索結果を要約した回答: {search_res['output']}\")\n",
    "    print(f\"質問と回答の整合性チェック: {search_res['qa_result']['output']}\")\n",
    "\n",
    "    # カウント用変数の初期化\n",
    "    research_cnt = 0\n",
    "    # outputが'Not Acceptable'である間、処理を繰り返す\n",
    "    while search_res['qa_result']['output']  == 'Not Acceptable':\n",
    "        print(\"-\"*50)\n",
    "        with Timer(prefix=f'Number of re-researches {research_cnt+1} :'):\n",
    "            # カウントアップ\n",
    "            research_cnt += 1\n",
    "            # カウントが3に達したらループを強制終了\n",
    "            if research_cnt == 3:\n",
    "                print(\"実行回数が3に達したため、処理を終了します。\")\n",
    "                break\n",
    "            # 再検索用のクエリ生成\n",
    "            re_query = make_re_search_query(\n",
    "                MODEL_NAME,\n",
    "                question,\n",
    "                query\n",
    "            )\n",
    "            # \n",
    "            query = re_query['output']\n",
    "            print(f\"再検索クエリ: {query}\")\n",
    "\n",
    "            search_res = search_agent_1cycle(question, query)\n",
    "\n",
    "            print(f\"検索結果を要約した回答: {search_res['output']}\")\n",
    "            print(f\"質問と回答の整合性チェック: {search_res['qa_result']['output']}\")\n",
    "        print(\"-\"*50)\n",
    "    return {\n",
    "        \"final_qa\": search_res['qa_result']['output'],\n",
    "        \"final_query\": query,\n",
    "        \"search_output\": search_res['output']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a4191ff-cd19-4ba3-82bb-5e09a0954c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary_of_search_results(question, search_res):\n",
    "    print(\"-\"*50)\n",
    "    print(f\"質問: {question}\")\n",
    "    print(\"-\"*50)\n",
    "    print(f\"検索に使用したクエリ:\\n {research_res['final_query']}\")\n",
    "    print(f\"検索結果を要約した最終回答:\\n {research_res['search_output']}\")\n",
    "    print(f\"最終判定結果: {research_res['final_qa']}\")\n",
    "    print(\"-\"*50)\n",
    "    print(f\"使用モデル: {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3978ee92-5e8e-49ed-ab53-83ecd56ce326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "検索結果を要約した回答: 2024年の戦略的テクノロジのトップ・トレンドは、「投資の保護」 (既存および将来の投資を保護／保全する)、「ビルダーの台頭」 (適切なステークホルダー向けに、適切なソリューションを、適切なタイミングで構築する)、「価値のデリバー」 (社内外の顧客の環境変化に応じて価値を提供する) という3つの包括的なビジネス・テーマの1つまたは複数に関連します。\n",
      "質問と回答の整合性チェック: Not Acceptable\n",
      "--------------------------------------------------\n",
      "再検索クエリ: 2024年, 最新テクノロジートレンド, 注目, 社会, 予想, 影響\n",
      "検索結果を要約した回答: 2024年の戦略的テクノロジのトップ・トレンドは、「投資の保護」 (既存および将来の投資を保護／保全する)、「ビルダーの台頭」 (適切なステークホルダー向けに、適切なソリューションを、適切なタイミングで構築する)、「価値のデリバー」 (社内外の顧客の環境変化に応じて価値を提供する) という3つの包括的なビジネス・テーマの1つまたは複数に関連します。\n",
      "質問と回答の整合性チェック: Not Acceptable\n",
      "Number of re-researches 1 : 6.386[s]\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "再検索クエリ: 2024年, 最新テクノロジートレンド, 注目, 社会, 影響, 予想\n",
      "検索結果を要約した回答: 2024年の戦略的テクノロジのトップ・トレンドは、「投資の保護」 (既存および将来の投資を保護／保全する)、「ビルダーの台頭」 (適切なステークホルダー向けに、適切なソリューションを、適切なタイミングで構築する)、「価値のデリバー」 (社内外の顧客の環境変化に応じて価値を提供する) という3つの包括的なビジネス・テーマの1つまたは複数に関連します。\n",
      "質問と回答の整合性チェック: Acceptable\n",
      "Number of re-researches 2 : 8.304[s]\n",
      "--------------------------------------------------\n",
      "Handle all time by research. 20.782[s]\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\"2024年に注目されている最新のテクノロジートレンドは何ですか？\n",
    "また、それらのトレンドが社会にどのような影響を与えると予想されますか？\"\"\"\n",
    "with Timer(prefix=f'Handle all time by research.'):\n",
    "    research_res = research_agent(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53329580-dbcc-4198-b453-bf6efcabb696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "質問: 2024年に注目されている最新のテクノロジートレンドは何ですか？\n",
      "また、それらのトレンドが社会にどのような影響を与えると予想されますか？\n",
      "--------------------------------------------------\n",
      "検索に使用したクエリ:\n",
      " 2024年, 最新テクノロジートレンド, 注目, 社会, 影響, 予想\n",
      "検索結果を要約した最終回答:\n",
      " 2024年の戦略的テクノロジのトップ・トレンドは、「投資の保護」 (既存および将来の投資を保護／保全する)、「ビルダーの台頭」 (適切なステークホルダー向けに、適切なソリューションを、適切なタイミングで構築する)、「価値のデリバー」 (社内外の顧客の環境変化に応じて価値を提供する) という3つの包括的なビジネス・テーマの1つまたは複数に関連します。\n",
      "最終判定結果: Acceptable\n",
      "--------------------------------------------------\n",
      "使用モデル: gpt-3.5-turbo-0125\n"
     ]
    }
   ],
   "source": [
    "get_summary_of_search_results(question, research_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c289dd0-b9fa-4a7a-92c0-83bc0379efa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "検索結果を要約した回答: このブログ記事では、日本、中国、アメリカ、インド、ブラジル、ロシア、スペインの7カ国の新年の祝い方について探究しています。グレゴリオ暦に基づく日本のお正月や、各国のユニークな新年の祝い方、例えばスイスではアイスクリームを床に落とす、ギリシャではザクロを玄関に投げる、コロンビアではスーツケースを持って走るなどの風習が紹介されています。また、中国では春節が旧正月として祝われることや、その他多くの国々で独自の新年の祝い方があることが紹介されています。\n",
      "質問と回答の整合性チェック: Acceptable\n",
      "Handle all time by research. 10.019[s]\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"gpt-4-0125-preview\"\n",
    "\n",
    "question = \"\"\"世界の異なる国々で行われているユニークな新年の祝い方を3つ挙げ、\n",
    "それぞれの文化的背景を説明してください。\"\"\"\n",
    "\n",
    "with Timer(prefix=f'Handle all time by research.'):\n",
    "    research_res = research_agent(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c0e46b70-6efd-4543-854a-1a697cd4b8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "質問: 世界の異なる国々で行われているユニークな新年の祝い方を3つ挙げ、\n",
      "それぞれの文化的背景を説明してください。\n",
      "--------------------------------------------------\n",
      "検索に使用したクエリ:\n",
      " 世界の異なる国々で行われているユニークな新年の祝い方を3つ挙げ、\n",
      "それぞれの文化的背景を説明してください。\n",
      "検索結果を要約した最終回答:\n",
      " このブログ記事では、日本、中国、アメリカ、インド、ブラジル、ロシア、スペインの7カ国の新年の祝い方について探究しています。グレゴリオ暦に基づく日本のお正月や、各国のユニークな新年の祝い方、例えばスイスではアイスクリームを床に落とす、ギリシャではザクロを玄関に投げる、コロンビアではスーツケースを持って走るなどの風習が紹介されています。また、中国では春節が旧正月として祝われることや、その他多くの国々で独自の新年の祝い方があることが紹介されています。\n",
      "最終判定結果: Acceptable\n",
      "--------------------------------------------------\n",
      "使用モデル: gpt-4-0125-preview\n"
     ]
    }
   ],
   "source": [
    "get_summary_of_search_results(question, research_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "478bfb38-9db4-46b3-8405-0018dfabdb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "検索結果を要約した回答: 2024年には世界の総合インフレ率が5.8%へと減速し、2025年にはさらに4.4%へと鈍化する見込みである。この予測は以前より下方修正されており、ディスインフレと着実な経済成長に伴い、世界経済がハードランディングを避ける可能性が高まっている。しかし、財政政策の過度な緩和や構造改革の加速が新たなリスクを生じさせる可能性も指摘されている。一方で、IMFは2022年の世界のGDP成長率予測を複数回にわたり下方修正しており、ロシアのウクライナ侵攻やインフレの影響が反映されている。中国経済はゼロコロナ政策の解除後も回復が緩慢で、雇用や住宅市場の低迷が背景にある。全体として、世界経済は減速傾向にあり、インフレ抑制と経済成長のバランスを取ることが今後の課題となっている。\n",
      "質問と回答の整合性チェック: Not Acceptable\n",
      "--------------------------------------------------\n",
      "再検索クエリ: 世界経済, 動向, 市場, 注目, 産業, 予測, 理由, 解説\n",
      "検索結果を要約した回答: IMFの2022年の世界経済成長率予測は、ロシアのウクライナ侵略やインフレの影響を受けて下方修正され、2022年は3.6％に。2024年の成長率は2.4％と予想され、3年連続での減速が見込まれる。中東紛争の影響などで地政学的リスクが高まっている。2022年のインフレ率は先進国が5.7％、新興国が8.7％に上方修正された。新興国と発展途上国の成長率は2022年が4.6％、2023年が4.4％と予測され、パンデミック前のトレンドを下回る。2022年から2024年の間に先進国の成長率は減速し、新興市場国と発展途上国の成長率も鈍化する見込み。ナイジェリア、コロンビア、ポーランドは高成長が期待される経済大国として注目されている。\n",
      "質問と回答の整合性チェック: Not Acceptable\n",
      "Number of re-researches 1 : 37.229[s]\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "再検索クエリ: 世界経済, 動向, 分析, 市場, 注目, 産業, 予測, 理由, 説明\n",
      "検索結果を要約した回答: {'IMF_2022年GDP成長率予測': 'IMFによると、2022年の世界のGDP成長率予測は、ロシアによるウクライナ侵略やインフレなどの影響で、2022年内に累次にわたり下方修正されている。当初は4.4%の成長が見込まれていたが、4月の時点で3.6%へと下方修正された。', '世界経済の成長率予測': '2022年の世界経済成長率は3.5%で、2023年と2024年はそれぞれ3.0%と予測されている。インフレ対策のための金融政策の引き締めが経済活動の重しとなっており、総合インフレ率は2022年の8.7%から2024年には5.2%へと減少する見込みである。', 'グローバル経済と主要産業の動向': '2023年12月のグローバル経済動向報告によると、鉄鋼、オイル・ガス、石油化学、紙パルプ、医薬品、食品、電子部品・半導体、家電、不動産、アパレルなど主要産業の分析が行われている。', '2024年世界経済成長率予測': '2024年の世界経済成長率は2.4%と予測され、3年連続の減速が見込まれている。金融政策の引き締め、制約的な与信状況、貿易と投資の世界的な低迷が成長を抑制するとされている。', '先進国と新興国の成長率差': '先進国の成長率は2021年の5%から、2022年は3.8%、2023年には2.3%と減速する見込みである。一方、新興国・途上国の成長率は、2021年の6.3%から、2022年は4.6%、2023年には4.4%と予測されている。', '世界経済見通し': '2022年4月の世界経済見通しによると、ウクライナでの戦争が経済回復を抑制し、世界経済成長率は2021年の6.1%から2022年と2023年は3.6%に減速する見込みである。', '世界経済の動向': '2021年は新型コロナウイルスへの対応が進展し、世界経済が回復してきた一年であった。2020年初のコロナショック後、政府の支援により世界経済は力強く回復した。', '長期経済成長予測': '世界経済は2016年から2050年までに年平均実質成長率約2.5%で成長し、経済規模が2042年までに倍増すると予想されている。新興市場と開発途上国が主な成長のけん引役となる。'}\n",
      "質問と回答の整合性チェック: Not Acceptable\n",
      "Number of re-researches 2 : 66.893[s]\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "実行回数が3に達したため、処理を終了します。\n",
      "Number of re-researches 3 : 0.000[s]\n",
      "Handle all time by research. 123.149[s]\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"gpt-4-0125-preview\"\n",
    "\n",
    "question = \"\"\"最近の世界経済の動向を分析し、今後の市場で注目すべき3つの産業を予測してください。それぞれの産業が注目される理由も含めて説明してください。\"\"\"\n",
    "\n",
    "with Timer(prefix=f'Handle all time by research.'):\n",
    "    research_res = research_agent(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c514ee4e-7339-4fbc-b9e3-d5935641069a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "質問: 最近の世界経済の動向を分析し、今後の市場で注目すべき3つの産業を予測してください。それぞれの産業が注目される理由も含めて説明してください。\n",
      "--------------------------------------------------\n",
      "検索に使用したクエリ:\n",
      " 世界経済, 動向, 分析, 市場, 注目, 産業, 予測, 理由, 説明\n",
      "検索結果を要約した最終回答:\n",
      " {'IMF_2022年GDP成長率予測': 'IMFによると、2022年の世界のGDP成長率予測は、ロシアによるウクライナ侵略やインフレなどの影響で、2022年内に累次にわたり下方修正されている。当初は4.4%の成長が見込まれていたが、4月の時点で3.6%へと下方修正された。', '世界経済の成長率予測': '2022年の世界経済成長率は3.5%で、2023年と2024年はそれぞれ3.0%と予測されている。インフレ対策のための金融政策の引き締めが経済活動の重しとなっており、総合インフレ率は2022年の8.7%から2024年には5.2%へと減少する見込みである。', 'グローバル経済と主要産業の動向': '2023年12月のグローバル経済動向報告によると、鉄鋼、オイル・ガス、石油化学、紙パルプ、医薬品、食品、電子部品・半導体、家電、不動産、アパレルなど主要産業の分析が行われている。', '2024年世界経済成長率予測': '2024年の世界経済成長率は2.4%と予測され、3年連続の減速が見込まれている。金融政策の引き締め、制約的な与信状況、貿易と投資の世界的な低迷が成長を抑制するとされている。', '先進国と新興国の成長率差': '先進国の成長率は2021年の5%から、2022年は3.8%、2023年には2.3%と減速する見込みである。一方、新興国・途上国の成長率は、2021年の6.3%から、2022年は4.6%、2023年には4.4%と予測されている。', '世界経済見通し': '2022年4月の世界経済見通しによると、ウクライナでの戦争が経済回復を抑制し、世界経済成長率は2021年の6.1%から2022年と2023年は3.6%に減速する見込みである。', '世界経済の動向': '2021年は新型コロナウイルスへの対応が進展し、世界経済が回復してきた一年であった。2020年初のコロナショック後、政府の支援により世界経済は力強く回復した。', '長期経済成長予測': '世界経済は2016年から2050年までに年平均実質成長率約2.5%で成長し、経済規模が2042年までに倍増すると予想されている。新興市場と開発途上国が主な成長のけん引役となる。'}\n",
      "最終判定結果: Not Acceptable\n",
      "--------------------------------------------------\n",
      "使用モデル: gpt-4-0125-preview\n"
     ]
    }
   ],
   "source": [
    "get_summary_of_search_results(question, research_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62d7118-72ea-4108-903c-0dedccbf2db6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
