{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b28abd92-9f85-4f58-977e-3cbb33dfe26e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.2)\n",
      "Collecting pip\n",
      "  Downloading pip-24.3.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Downloading pip-24.3.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.2\n",
      "    Uninstalling pip-24.2:\n",
      "      Successfully uninstalled pip-24.2\n",
      "Successfully installed pip-24.3.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7f0f43f-0664-4dea-bac7-e2223a6f2f49",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting arxiv==2.1.0\n",
      "  Downloading arxiv-2.1.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting feedparser==6.0.10 (from arxiv==2.1.0)\n",
      "  Downloading feedparser-6.0.10-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting requests==2.31.0 (from arxiv==2.1.0)\n",
      "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting sgmllib3k (from feedparser==6.0.10->arxiv==2.1.0)\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->arxiv==2.1.0) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->arxiv==2.1.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->arxiv==2.1.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->arxiv==2.1.0) (2024.8.30)\n",
      "Downloading arxiv-2.1.0-py3-none-any.whl (11 kB)\n",
      "Downloading feedparser-6.0.10-py3-none-any.whl (81 kB)\n",
      "Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Building wheels for collected packages: sgmllib3k\n",
      "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6066 sha256=654c7a1e4c87890c5ce2ba169fa6feb4bb25a6df5be99e40c2a8fb27642ca1f3\n",
      "  Stored in directory: /root/.cache/pip/wheels/f0/69/93/a47e9d621be168e9e33c7ce60524393c0b92ae83cf6c6e89c5\n",
      "Successfully built sgmllib3k\n",
      "Installing collected packages: sgmllib3k, requests, feedparser, arxiv\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.32.3\n",
      "    Uninstalling requests-2.32.3:\n",
      "      Successfully uninstalled requests-2.32.3\n",
      "Successfully installed arxiv-2.1.0 feedparser-6.0.10 requests-2.31.0 sgmllib3k-1.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Downloading regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hDownloading regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (782 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m782.7/782.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m-:--:--\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: regex, python-dotenv, tiktoken\n",
      "Successfully installed python-dotenv-1.0.1 regex-2024.9.11 tiktoken-0.8.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting openai==1.45.0\n",
      "  Downloading openai-1.45.0-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.45.0) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.45.0) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.45.0) (0.27.2)\n",
      "Collecting jiter<1,>=0.4.0 (from openai==1.45.0)\n",
      "  Downloading jiter-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.45.0) (2.9.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.45.0) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.45.0) (4.66.5)\n",
      "Collecting typing-extensions<5,>=4.11 (from openai==1.45.0)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.45.0) (3.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.45.0) (1.2.2)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.45.0) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.45.0) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.45.0) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.45.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.45.0) (2.23.4)\n",
      "Downloading openai-1.45.0-py3-none-any.whl (374 kB)\n",
      "Downloading jiter-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (327 kB)\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: typing-extensions, jiter, openai\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.9.0\n",
      "    Uninstalling typing_extensions-4.9.0:\n",
      "      Successfully uninstalled typing_extensions-4.9.0\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.30.0\n",
      "    Uninstalling openai-1.30.0:\n",
      "      Successfully uninstalled openai-1.30.0\n",
      "Successfully installed jiter-0.7.0 openai-1.45.0 typing-extensions-4.12.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install arxiv==2.1.0\n",
    "!pip3 install python-dotenv tiktoken\n",
    "# !pip install openai==0.27.8\n",
    "# !pip install openai==1.3.4\n",
    "# !pip install openai==1.30.0\n",
    "!pip install openai==1.45.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a73f2f51-2af8-4924-939c-e5f08c62f9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import arxiv\n",
    "import openai\n",
    "import yaml\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25b052b9-0864-4791-b144-bbcce9933abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "891e7219-d84f-49d3-b928-3b54687ef89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "612b548f-a137-4909-a4eb-6028335e0635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65e30177-9973-42f1-88ef-ddb51edff296",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c94d88c-cace-48eb-ac0e-3b69e7625069",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM = \"\"\"\n",
    "### 指示 ###\n",
    "論文の内容を理解した上で，重要なポイントを箇条書きで3点書いてください。\n",
    "\n",
    "### 箇条書きの制約 ###\n",
    "- 最大3個\n",
    "- 日本語\n",
    "- 箇条書き1個を50文字以内\n",
    "\n",
    "### 対象とする論文の内容 ###\n",
    "{text}\n",
    "\n",
    "### 出力形式 ###\n",
    "タイトル(和名)\n",
    "\n",
    "- 箇条書き1\n",
    "- 箇条書き2\n",
    "- 箇条書き3\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ca866b4-777e-4e42-aa01-ae23811639de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arXivの更新頻度を加味して、5日前の論文を検索\n",
    "N_DAYS = 5\n",
    "# N_DAYS = 360\n",
    "\n",
    "# MAX_RESULT = 24  # 取得する論文数の上限\n",
    "# MAX_RESULT = 32  # 取得する論文数の上限\n",
    "\n",
    "MAX_RESULT = 64  # 取得する論文数の上限\n",
    "\n",
    "\n",
    "# MODEL_NAME = \"gpt-3.5-turbo-0613\"\n",
    "# MODEL_NAME = \"gpt-3.5-turbo-1106\"\n",
    "# MODEL_NAME = \"gpt-3.5-turbo-0125\"\n",
    "MODEL_NAME = \"gpt-4o-mini\"\n",
    "\n",
    "TEMPERATURE = 0.7\n",
    "# OpenAIクライアントの初期化\n",
    "client = OpenAI()\n",
    "\n",
    "# テンプレートを用意\n",
    "QUERY_TEMPLATE = '%28 ti:%22{}%22 OR abs:%22{}%22 %29 AND submittedDate: [{} TO {}]'\n",
    "\n",
    "# 検索を行い、結果を取得する関数\n",
    "def search_arxiv(keyword):\n",
    "    # Construct the default API client.\n",
    "    client = arxiv.Client()\n",
    "    # 2日前からN_DAYS前までの論文を検索\n",
    "    today = dt.datetime.today() - dt.timedelta(days=2)\n",
    "    # today = dt.datetime.today()\n",
    "    \n",
    "    base_date = today - dt.timedelta(days=N_DAYS)\n",
    "    query = QUERY_TEMPLATE.format(keyword, keyword, base_date.strftime(\"%Y%m%d%H%M%S\"), today.strftime(\"%Y%m%d%H%M%S\"))\n",
    "\n",
    "    search = arxiv.Search(\n",
    "        query=query,\n",
    "        max_results=MAX_RESULT,\n",
    "        sort_by=arxiv.SortCriterion.SubmittedDate,\n",
    "        sort_order=arxiv.SortOrder.Descending,\n",
    "    )\n",
    "\n",
    "    # results = []\n",
    "    # for result in search.results():\n",
    "    #     # カテゴリーチェック\n",
    "    #     # if not set(result.categories) & CATEGORIES:\n",
    "    #     #     continue\n",
    "    #     # 要約内でのキーワードの存在チェック\n",
    "    #     if keyword.lower() in result.summary.lower():\n",
    "    #         results.append(result)\n",
    "    results = client.results(search)\n",
    "    return results\n",
    "\n",
    "# 論文の要約を取得する関数\n",
    "def get_summary(result):\n",
    "    text = f\"title: {result.title}\\nbody: {result.summary}\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\" : \"system\", \"content\" : SYSTEM},\n",
    "        {\"role\": \"user\", \"content\": text}\n",
    "    ]\n",
    "    \n",
    "    # response = openai.ChatCompletion.create(\n",
    "    #     model=MODEL_NAME,\n",
    "    #     messages=messages,\n",
    "    #     temperature=TEMPERATURE,\n",
    "    # )\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages=messages,\n",
    "        temperature=TEMPERATURE,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "    # return response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d61038c2-cc52-4212-bd98-b89c36d9a270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary(result):\n",
    "    model_name=MODEL_NAME\n",
    "    text=result.summary\n",
    "    # 概要と提案手法名を生成する\n",
    "    prompt = [{'role': 'system', 'content': \"Please compile the following text into a research report so that it can be fully understood without any omissions. If a method is proposed, extract its name.\"}]\n",
    "    prompt.append({\"role\" : \"system\", \"content\" : 'Please generate the research report to include the following contents.\\n\"CHALLENGE\" The current situation faced by the researcher; it will normally include a Problem Statement, the Motivation, a Hypothesis and/or a Goal.\\n\"APPROACH\" How they intend to carry out the investigation, comments on a theoretical model or framework.\\n\"OUTCOME\" Overall conclusion that should reject or support the research hypothesis.'})    \n",
    "    prompt.append({\"role\" : \"system\", \"content\" : 'The text should be explained using language and mathematical formulas that a first-year college student can understand.'})\n",
    "    \n",
    "    prompt.append({\"role\" : \"system\", \"content\" : 'Please create a research report by referencing the example research report below, structuring it around three distinct aspects in order: \"Challenge,\" \"Approach,\" and \"Outcome.\"\\n\"Challenge\" Existing statistical phrasal orhierarchical machine translation system relies on a large set of translation rules which results in engineering challenges. \\n\"Approach\": The proposed method consistently outperforms existing methods in BLEU on various low-resource language translation tasks with less training data.\\n\"Outcome\" They propose to use factorized grammar from the field of linguistics as more general translation rules from XTAG English Grammar.'})\n",
    "    \n",
    "    prompt.append({\"role\": \"system\", \"content\": \"Results must be in Japanese.\"})\n",
    "    prompt.append({\"role\" : \"system\", \"content\" : \"Outputs should be generated in step by step.\"})\n",
    "    prompt.append({\"role\": \"system\", \"content\": \"Think the option as hypothesis. Whether it entails with those premises?\"})\n",
    "    prompt.append({\"role\" : \"system\", \"content\" : \"Please explain the research report in a way that is easy to understand for high school students, without making it complicated. It's okay if the explanation becomes lengthy.\"})\n",
    "    \n",
    "    prompt.append({\"role\": \"system\", \"content\": \"Please format the output in Markdown.\"})\n",
    "    prompt.append({\"role\": \"system\", \"content\": \"Results must be in Japanese.\"})\n",
    "    \n",
    "    prompt.append({\"role\": \"user\", \"content\": 'Based on the input text, generate a JSON containing two different pieces of information. First, use \"extract_summary\" as the schema to create a section that keys in the result of summarizing the content of the text accurately and completely. Next, use \"method_name\" as the schema to create a section that keys in the name of the method proposed or used within the text. Combine these pieces of information to output as a single JSON object. This JSON will be formatted as {\"extract_summary\": [the result of summarizing the text content], \"method_name\": [the name of the method proposed or used within the text]}.'})\n",
    "    \n",
    "    prompt.append({\"role\": \"user\", \"content\": f\"Input text: {text}\"})\n",
    "    prompt.append({\"role\": \"user\", \"content\": f\"Include:\\n- Overview\\n- Novelty\\n- Methodology\\n- Results\"})\n",
    "    prompt.append({\"role\": \"system\", \"content\": \"Results must be in Japanese.\"})\n",
    "    \"\"\"\n",
    "    システム\n",
    "    あなたは以下の text を過不足なく理解できるように調査報告書としてまとめ、提案されている手法がある場合はその名称を抽出してください。\n",
    "    文章は大学一年生が理解できる程度の言葉と数式を用いて説明してください。\n",
    "    調査報告書は以下の内容を含む形で生成してください\\n\n",
    "    • CHALLENGE: The current situation faced by the researcher; it will normally include a Problem Statement, the Motivation, a Hypothesis and/or a Goal.\\n\n",
    "    • APPROACH: How they intend to carry out the investigation, comments on a theoretical model or framework.\\n\n",
    "    • OUTCOME: Overall conclusion that should reject or support the research hypothesis.\n",
    "\n",
    "    調査報告書は以下の例を参考に「課題」「アプローチ」「結果」の3つの異なる側面を順番に作成してください。概要: [ACLSum: A New Dataset for Aspect-based Summarization of Scientific Publications](https://arxiv.org/abs/2403.05303v1)のデータセット例を一つ\n",
    "    出力は Markdown 形式にしてください。\n",
    "    \n",
    "    結果は日本語でなければならない。\n",
    "    user\n",
    "    入力されたテキストに基づき、二つの異なる情報を含むJSONを生成します。最初に、\"extract_summary\"をスキーマとして使用し、テキストの内容を過不足なく概要としてまとめた結果をキーとする部分を生成します。次に、\"method_name\"をスキーマとして使用し、テキスト内で提案されたり使用されている手法名をキーとする部分を生成します。これらの情報を組み合わせて、一つのJSONオブジェクトとして出力します。このJSONは、{\"extract_summary\": [テキストの内容を概要としてまとめた結果], \"method_name\": [テキスト内で提案されたり使用されている手法名]}の形式で表されます。\n",
    "    \n",
    "    入力されたテキスト: {text}\n",
    "    \"\"\"\n",
    "    \n",
    "    # 概要と提案手法名抽出用のプロンプトテンプレートを作成\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name, # model = \"deployment_name\".\n",
    "        messages=prompt,\n",
    "        # response_format={ \"type\": \"json_object\" },\n",
    "        temperature=TEMPERATURE,\n",
    "    )\n",
    "    summary_method_name_str = response.choices[0].message.content\n",
    "\n",
    "    return summary_method_name_str\n",
    "    # print(summary_method_name_str)\n",
    "    \n",
    "    # # JSON形式の文字列を辞書に変換\n",
    "    # summary_method_name = json.loads(summary_method_name_str)\n",
    "    \n",
    "    # 出力と新しいメッセージをステートに反映\n",
    "    # return summary_method_name[\"extract_summary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88fcab98-4988-4ae9-bff5-16fd4e90cb7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title: Controlling Language and Diffusion Models by Transporting Activations\n",
      "published: 2024-10-30 14:21:33+00:00\n",
      "abstruct: The increasing capabilities of large generative models and their ever more\n",
      "widespread deployment have raised concerns about their reliability, safety, and\n",
      "potential misuse. To address these issues, recent works have proposed to\n",
      "control model generation by steering model activations in order to effectively\n",
      "induce or prevent the emergence of concepts or behaviors in the generated\n",
      "output. In this paper we introduce Activation Transport (AcT), a general\n",
      "framework to steer activations guided by optimal transport theory that\n",
      "generalizes many previous activation-steering works. AcT is modality-agnostic\n",
      "and provides fine-grained control over the model behavior with negligible\n",
      "computational overhead, while minimally impacting model abilities. We\n",
      "experimentally show the effectiveness and versatility of our approach by\n",
      "addressing key challenges in large language models (LLMs) and text-to-image\n",
      "diffusion models (T2Is). For LLMs, we show that AcT can effectively mitigate\n",
      "toxicity, induce arbitrary concepts, and increase their truthfulness. In T2Is,\n",
      "we show how AcT enables fine-grained style control and concept negation.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.23054v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"本論文では、生成モデルの性能が向上し、それが広く普及する中で、信頼性、安全性、および潜在的な悪用に関する懸念が高まっていることを背景に、モデルの生成を制御する手法について述べています。\n",
      "特に、アクティベーションを誘導または防ぐためにモデルのアクティベーションを操作することで、生成出力における概念や行動の出現を効果的にコントロールする方法を提案しています。\n",
      "\",\n",
      "    \"Novelty\": \"新たに提案されたActivation Transport (AcT)は、最適輸送理論に基づくアクティベーション制御の一般的なフレームワークであり、以前の多くのアクティベーション制御手法を一般化しています。\n",
      "この手法は、モダリティに依存せず、計算コストをほとんどかけることなくモデルの動作を細かく制御できる点が新しい特徴です。\n",
      "\",\n",
      "    \"Methodology\": \"AcTは、モデルのアクティベーションを最適輸送理論に基づいて制御することで、生成プロセスにおいて必要な概念を導入したり、不要な概念を排除したりする方法を提供します。\n",
      "これにより、モデルの能力に最小限の影響を与えつつ、精緻な制御を実現します。\n",
      "\",\n",
      "    \"Results\": \"実験により、AcTの有効性と多様性が示され、大規模言語モデル（LLMs）やテキストから画像への拡散モデル（T2Is）における主要な課題に対して効果を発揮することが確認されました。\n",
      "具体的には、LLMsでは有害なコンテンツの軽減や任意の概念の導入、真実性の向上が可能であり、T2Isではスタイルの細かい制御や概念の否定が可能であることが示されました。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"Activation Transport (AcT)\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: Emotional RAG: Enhancing Role-Playing Agents through Emotional Retrieval\n",
      "published: 2024-10-30 14:08:50+00:00\n",
      "abstruct: As LLMs exhibit a high degree of human-like capability, increasing attention\n",
      "has been paid to role-playing research areas in which responses generated by\n",
      "LLMs are expected to mimic human replies. This has promoted the exploration of\n",
      "role-playing agents in various applications, such as chatbots that can engage\n",
      "in natural conversations with users and virtual assistants that can provide\n",
      "personalized support and guidance. The crucial factor in the role-playing task\n",
      "is the effective utilization of character memory, which stores characters'\n",
      "profiles, experiences, and historical dialogues. Retrieval Augmented Generation\n",
      "(RAG) technology is used to access the related memory to enhance the response\n",
      "generation of role-playing agents. Most existing studies retrieve related\n",
      "information based on the semantic similarity of memory to maintain characters'\n",
      "personalized traits, and few attempts have been made to incorporate the\n",
      "emotional factor in the retrieval argument generation (RAG) of LLMs. Inspired\n",
      "by the Mood-Dependent Memory theory, which indicates that people recall an\n",
      "event better if they somehow reinstate during recall the original emotion they\n",
      "experienced during learning, we propose a novel emotion-aware memory retrieval\n",
      "framework, termed Emotional RAG, which recalls the related memory with\n",
      "consideration of emotional state in role-playing agents. Specifically, we\n",
      "design two kinds of retrieval strategies, i.e., combination strategy and\n",
      "sequential strategy, to incorporate both memory semantic and emotional states\n",
      "during the retrieval process. Extensive experiments on three representative\n",
      "role-playing datasets demonstrate that our Emotional RAG framework outperforms\n",
      "the method without considering the emotional factor in maintaining the\n",
      "personalities of role-playing agents. This provides evidence to further\n",
      "reinforce the Mood-Dependent Memory theory in psychology.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.23041v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"大規模言語モデル（LLMs）が人間に似た能力を示す中で、ロールプレイングエージェントの研究が注目を集めている。\n",
      "これにより、ユーザーと自然な会話を行うチャットボットや、個別のサポートを提供するバーチャルアシスタントなど、さまざまなアプリケーションが探求されている。\n",
      "ロールプレイングタスクにおいて重要な要素は、キャラクターのプロフィール、経験、過去の対話を保存するキャラクターメモリの効果的な利用である。\n",
      "\",\n",
      "    \"Novelty\": \"本研究では、感情状態を考慮した新しいメモリリトリーバルフレームワーク「感情RAG（Emotional RAG）」を提案する。\n",
      "これは、ロールプレイングエージェントにおける感情の要素を取り入れたメモリのリトリーバルを行うもので、Mood-Dependent Memory理論にインスパイアされている。\n",
      "\",\n",
      "    \"Methodology\": \"感情RAGフレームワークでは、メモリの意味的な関連性と感情状態を考慮した二つのリトリーバル戦略（組み合わせ戦略と逐次戦略）を設計している。\n",
      "これにより、ロールプレイングエージェントの応答生成を強化することができる。\n",
      "\",\n",
      "    \"Results\": \"三つの代表的なロールプレイングデータセットにおける実験により、感情RAGフレームワークは、感情の要素を考慮しない従来の手法に比べて優れた性能を示し、心理学におけるMood-Dependent Memory理論をさらに支持する証拠を提供する。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"感情RAG（Emotional RAG）\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: Online Intrinsic Rewards for Decision Making Agents from Large Language Model Feedback\n",
      "published: 2024-10-30 13:52:43+00:00\n",
      "abstruct: Automatically synthesizing dense rewards from natural language descriptions\n",
      "is a promising paradigm in reinforcement learning (RL), with applications to\n",
      "sparse reward problems, open-ended exploration, and hierarchical skill design.\n",
      "Recent works have made promising steps by exploiting the prior knowledge of\n",
      "large language models (LLMs). However, these approaches suffer from important\n",
      "limitations: they are either not scalable to problems requiring billions of\n",
      "environment samples; or are limited to reward functions expressible by compact\n",
      "code, which may require source code and have difficulty capturing nuanced\n",
      "semantics; or require a diverse offline dataset, which may not exist or be\n",
      "impossible to collect. In this work, we address these limitations through a\n",
      "combination of algorithmic and systems-level contributions. We propose ONI, a\n",
      "distributed architecture that simultaneously learns an RL policy and an\n",
      "intrinsic reward function using LLM feedback. Our approach annotates the\n",
      "agent's collected experience via an asynchronous LLM server, which is then\n",
      "distilled into an intrinsic reward model. We explore a range of algorithmic\n",
      "choices for reward modeling with varying complexity, including hashing,\n",
      "classification, and ranking models. By studying their relative tradeoffs, we\n",
      "shed light on questions regarding intrinsic reward design for sparse reward\n",
      "problems. Our approach achieves state-of-the-art performance across a range of\n",
      "challenging, sparse reward tasks from the NetHack Learning Environment in a\n",
      "simple unified process, solely using the agent's gathered experience, without\n",
      "requiring external datasets nor source code. We make our code available at\n",
      "\\url{URL} (coming soon).\n",
      "PDFリンク: http://arxiv.org/pdf/2410.23022v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"自然言語記述から密な報酬を自動的に合成することは、強化学習(RL)における有望なパラダイムであり、スパース報酬問題、オープンエンド探索、階層的スキル設計に応用されます。\n",
      "最近の研究では、大規模言語モデル(LLM)の事前知識を利用して有望な進展が見られましたが、これらのアプローチには重要な制限があります。\n",
      "\",\n",
      "    \"Novelty\": \"本研究では、これらの制限を解決するために、アルゴリズムとシステムレベルの貢献の組み合わせを提案します。\n",
      "特に、LLMのフィードバックを使用してRLポリシーと内因的報酬関数を同時に学習する分散アーキテクチャONIを提案します。\n",
      "\",\n",
      "    \"Methodology\": \"我々のアプローチは、エージェントが収集した経験を非同期LLMサーバーを介して注釈付けし、それを内因的報酬モデルに蒸留します。\n",
      "報酬モデリングに関するさまざまなアルゴリズムの選択肢を探求し、その相対的なトレードオフを明らかにします。\n",
      "\",\n",
      "    \"Results\": \"我々のアプローチは、NetHack Learning Environmentの一連の挑戦的なスパース報酬タスクにおいて、最先端の性能を達成しました。\n",
      "このプロセスはシンプルで、エージェントの収集した経験のみを使用し、外部データセットやソースコードを必要としません。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"ONI\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: Long$^2$RAG: Evaluating Long-Context & Long-Form Retrieval-Augmented Generation with Key Point Recall\n",
      "published: 2024-10-30 13:29:36+00:00\n",
      "abstruct: Retrieval-augmented generation (RAG) is a promising approach to address the\n",
      "limitations of fixed knowledge in large language models (LLMs). However,\n",
      "current benchmarks for evaluating RAG systems suffer from two key deficiencies:\n",
      "(1) they fail to adequately measure LLMs' capability in handling long-context\n",
      "retrieval due to a lack of datasets that reflect the characteristics of\n",
      "retrieved documents, and (2) they lack a comprehensive evaluation method for\n",
      "assessing LLMs' ability to generate long-form responses that effectively\n",
      "exploits retrieved information. To address these shortcomings, we introduce the\n",
      "Long$^2$RAG benchmark and the Key Point Recall (KPR) metric. Long$^2$RAG\n",
      "comprises 280 questions spanning 10 domains and across 8 question categories,\n",
      "each associated with 5 retrieved documents with an average length of 2,444\n",
      "words. KPR evaluates the extent to which LLMs incorporate key points extracted\n",
      "from the retrieved documents into their generated responses, providing a more\n",
      "nuanced assessment of their ability to exploit retrieved information.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.23000v2\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"Retrieval-augmented generation (RAG)は、大規模言語モデル（LLM）の固定された知識の限界を克服するための有望なアプローチです。\n",
      "しかし、現在のRAGシステムの評価基準には2つの主要な欠陥があります。\n",
      "第一に、長いコンテキストの検索を扱うLLMの能力を十分に測定できていないこと、第二に、取得した情報を効果的に活用して長文の応答を生成するLLMの能力を評価する包括的なメソッドが不足していることです。\n",
      "\",\n",
      "    \"Novelty\": \"これらの欠点に対処するために、Long²RAGベンチマークとKey Point Recall (KPR)メトリックを導入しました。\n",
      "Long²RAGは、10のドメインにわたる280の質問を含み、8つの質問カテゴリーにまたがり、各質問には平均2,444語の長さの5つの取得文書が関連付けられています。\n",
      "\",\n",
      "    \"Methodology\": \"KPRは、LLMが生成した応答において取得した文書から抽出された重要なポイントをどの程度取り入れているかを評価するもので、取得した情報を活用する能力のより詳細な評価を提供します。\n",
      "\",\n",
      "    \"Results\": \"これにより、RAGシステムの評価の質が向上し、LLMの情報活用能力をより的確に測定できるようになります。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"Key Point Recall (KPR)\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: A Comparison of Prompt Engineering Techniques for Task Planning and Execution in Service Robotics\n",
      "published: 2024-10-30 13:22:55+00:00\n",
      "abstruct: Recent advances in LLM have been instrumental in autonomous robot control and\n",
      "human-robot interaction by leveraging their vast general knowledge and\n",
      "capabilities to understand and reason across a wide range of tasks and\n",
      "scenarios. Previous works have investigated various prompt engineering\n",
      "techniques for improving the performance of \\glspl{LLM} to accomplish tasks,\n",
      "while others have proposed methods that utilize LLMs to plan and execute tasks\n",
      "based on the available functionalities of a given robot platform. In this work,\n",
      "we consider both lines of research by comparing prompt engineering techniques\n",
      "and combinations thereof within the application of high-level task planning and\n",
      "execution in service robotics. We define a diverse set of tasks and a simple\n",
      "set of functionalities in simulation, and measure task completion accuracy and\n",
      "execution time for several state-of-the-art models.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22997v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"最近の大規模言語モデル（LLM）の進展は、自律ロボット制御や人間とロボットの相互作用において重要な役割を果たしています。\n",
      "これらのモデルは、幅広いタスクやシナリオを理解し、推論するための広範な知識と能力を活用しています。\n",
      "これまでの研究では、LLMの性能を向上させるためのさまざまなプロンプトエンジニアリング技術が調査されてきました。\n",
      "また、LLMを利用して特定のロボットプラットフォームの機能に基づいてタスクを計画し実行する方法も提案されています。\n",
      "本研究では、サービスロボティクスにおける高レベルのタスク計画と実行の応用において、プロンプトエンジニアリング技術とその組み合わせを比較します。\n",
      "\",\n",
      "    \"Novelty\": \"本研究の新規性は、高レベルタスクの計画と実行におけるプロンプトエンジニアリング技術の比較を行い、ロボットの機能を使用したタスクの達成精度と実行時間を測定する点にあります。\n",
      "\",\n",
      "    \"Methodology\": \"多様なタスクセットとシンプルな機能セットをシミュレーションで定義し、いくつかの最先端モデルについてタスク達成精度と実行時間を測定します。\n",
      "\",\n",
      "    \"Results\": \"研究の結果、プロンプトエンジニアリング技術の組み合わせが、サービスロボティクスにおけるタスクの達成精度と実行時間において有意な改善をもたらすことが示されました。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"プロンプトエンジニアリング技術の比較\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: VisAidMath: Benchmarking Visual-Aided Mathematical Reasoning\n",
      "published: 2024-10-30 13:19:44+00:00\n",
      "abstruct: Although previous research on large language models (LLMs) and large\n",
      "multi-modal models (LMMs) has systematically explored mathematical\n",
      "problem-solving (MPS) within visual contexts, the analysis of how these models\n",
      "process visual information during problem-solving remains insufficient. To\n",
      "address this gap, we present VisAidMath, a benchmark for evaluating the MPS\n",
      "process related to visual information. We follow a rigorous data curation\n",
      "pipeline involving both automated processes and manual annotations to ensure\n",
      "data quality and reliability. Consequently, this benchmark includes 1,200\n",
      "challenging problems from various mathematical branches, vision-aid\n",
      "formulations, and difficulty levels, collected from diverse sources such as\n",
      "textbooks, examination papers, and Olympiad problems. Based on the proposed\n",
      "benchmark, we conduct comprehensive evaluations on ten mainstream LLMs and\n",
      "LMMs, highlighting deficiencies in the visual-aided reasoning process. For\n",
      "example, GPT-4V only achieves 45.33% accuracy in the visual-aided reasoning\n",
      "task, even with a drop of 2 points when provided with golden visual aids.\n",
      "In-depth analysis reveals that the main cause of deficiencies lies in\n",
      "hallucination regarding the implicit visual reasoning process, shedding light\n",
      "on future research directions in the visual-aided MPS process.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22995v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"本研究では、視覚情報を用いた数学的問題解決（MPS）に焦点を当て、従来の大規模言語モデル（LLMs）と多モーダルモデル（LMMs）の研究のギャップを埋めるために、VisAidMathというベンチマークを提案します。\n",
      "このベンチマークは、視覚情報に関連するMPSプロセスを評価するために設計されています。\n",
      "\",\n",
      "    \"Novelty\": \"VisAidMathは、データの品質と信頼性を確保するために、自動化されたプロセスと手動アノテーションを組み合わせた厳密なデータキュレーションパイプラインを使用しています。\n",
      "これにより、異なる数学の分野、視覚補助の定式化、難易度を持つ1,200の問題が収集されました。\n",
      "\",\n",
      "    \"Methodology\": \"提案されたベンチマークを基に、10の主流のLLMとLMMについて包括的な評価を行いました。\n",
      "この評価では、視覚補助推論プロセスにおける欠陥が強調され、特にGPT-4Vは視覚補助推論タスクで45.33%の正確さしか達成できませんでした。\n",
      "\",\n",
      "    \"Results\": \"深層分析によると、欠陥の主な原因は、暗黙的な視覚推論プロセスに関する幻覚にあることが明らかになり、今後の視覚補助MPSプロセスにおける研究の方向性を示唆しています。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"VisAidMath\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: Bonafide at LegalLens 2024 Shared Task: Using Lightweight DeBERTa Based Encoder For Legal Violation Detection and Resolution\n",
      "published: 2024-10-30 12:42:38+00:00\n",
      "abstruct: In this work, we present two systems -- Named Entity Resolution (NER) and\n",
      "Natural Language Inference (NLI) -- for detecting legal violations within\n",
      "unstructured textual data and for associating these violations with potentially\n",
      "affected individuals, respectively. Both these systems are lightweight DeBERTa\n",
      "based encoders that outperform the LLM baselines. The proposed NER system\n",
      "achieved an F1 score of 60.01\\% on Subtask A of the LegalLens challenge, which\n",
      "focuses on identifying violations. The proposed NLI system achieved an F1 score\n",
      "of 84.73\\% on Subtask B of the LegalLens challenge, which focuses on resolving\n",
      "these violations by matching them with pre-existing legal complaints of class\n",
      "action cases. Our NER system ranked sixth and NLI system ranked fifth on the\n",
      "LegalLens leaderboard. We release the trained models and inference scripts.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22977v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"この研究では、法律違反を検出するための2つのシステム、すなわち名前付きエンティティ解決（NER）と自然言語推論（NLI）を提案しています。\n",
      "これらのシステムは、非構造化テキストデータ内の法律違反を特定し、それに関連する影響を受ける可能性のある個人に関連付けることを目的としています。\n",
      "\",\n",
      "    \"Novelty\": \"提案されたシステムは、軽量なDeBERTaベースのエンコーダーを使用しており、従来の大規模言語モデル（LLM）ベースラインを上回る性能を発揮しています。\n",
      "\",\n",
      "    \"Methodology\": \"NERシステムは、LegalLensチャレンジのサブタスクAで60.01%のF1スコアを達成し、違反の特定に焦点を当てています。\n",
      "一方、NLIシステムはサブタスクBで84.73%のF1スコアを達成し、これらの違反を既存の集団訴訟の法的苦情と照合することに重点を置いています。\n",
      "\",\n",
      "    \"Results\": \"NERシステムはLegalLensリーダーボードで6位に、NLIシステムは5位にランクインしました。\n",
      "また、トレーニング済みモデルと推論スクリプトも公開しています。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": [\n",
      "    \"Named Entity Resolution (NER)\",\n",
      "    \"Natural Language Inference (NLI)\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: Private Synthetic Text Generation with Diffusion Models\n",
      "published: 2024-10-30 12:38:49+00:00\n",
      "abstruct: How capable are diffusion models of generating synthetics texts? Recent\n",
      "research shows their strengths, with performance reaching that of\n",
      "auto-regressive LLMs. But are they also good in generating synthetic data if\n",
      "the training was under differential privacy? Here the evidence is missing, yet\n",
      "the promises from private image generation look strong. In this paper we\n",
      "address this open question by extensive experiments. At the same time, we\n",
      "critically assess (and reimplement) previous works on synthetic private text\n",
      "generation with LLMs and reveal some unmet assumptions that might have led to\n",
      "violating the differential privacy guarantees. Our results partly contradict\n",
      "previous non-private findings and show that fully open-source LLMs outperform\n",
      "diffusion models in the privacy regime. Our complete source codes, datasets,\n",
      "and experimental setup is publicly available to foster future research.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22971v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"この研究では、拡散モデルが合成テキストを生成する能力を検証しています。\n",
      "最近の研究では、拡散モデルが自己回帰型大規模言語モデル（LLM）と同等のパフォーマンスを発揮することが示されていますが、差分プライバシーの下での合成データ生成に関しては証拠が不足しています。\n",
      "この論文では、広範な実験を通じてこの未解決の問題に取り組んでいます。\n",
      "\",\n",
      "    \"Novelty\": \"本研究の新規性は、LLMを用いた合成プライベートテキスト生成に関する過去の研究を批判的に評価し、再実装することにあります。\n",
      "これにより、差分プライバシーの保証を侵害する可能性のある未満の仮定を明らかにしています。\n",
      "\",\n",
      "    \"Methodology\": \"実験では、拡散モデルとオープンソースのLLMのパフォーマンスを比較し、差分プライバシーの文脈での結果を評価しています。\n",
      "研究の結果は、完全なソースコード、データセット、実験セットアップが公開されており、将来の研究を促進することを目的としています。\n",
      "\",\n",
      "    \"Results\": \"結果として、完全にオープンソースのLLMがプライバシーの条件下で拡散モデルを上回ることが示され、以前の非プライベートな発見と部分的に矛盾しています。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"拡散モデル\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: Retrieval-Augmented Generation with Estimation of Source Reliability\n",
      "published: 2024-10-30 12:09:29+00:00\n",
      "abstruct: Retrieval-augmented generation (RAG) addresses key limitations of large\n",
      "language models (LLMs), such as hallucinations and outdated knowledge, by\n",
      "incorporating external databases. These databases typically consult multiple\n",
      "sources to encompass up-to-date and various information. However, standard RAG\n",
      "methods often overlook the heterogeneous source reliability in the multi-source\n",
      "database and retrieve documents solely based on relevance, making them prone to\n",
      "propagating misinformation. To address this, we propose Reliability-Aware RAG\n",
      "(RA-RAG) which estimates the reliability of multiple sources and incorporates\n",
      "this information into both retrieval and aggregation processes. Specifically,\n",
      "it iteratively estimates source reliability and true answers for a set of\n",
      "queries with no labelling. Then, it selectively retrieves relevant documents\n",
      "from a few of reliable sources and aggregates them using weighted majority\n",
      "voting, where the selective retrieval ensures scalability while not\n",
      "compromising the performance. We also introduce a benchmark designed to reflect\n",
      "real-world scenarios with heterogeneous source reliability and demonstrate the\n",
      "effectiveness of RA-RAG compared to a set of baselines.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22954v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"Retrieval-augmented generation (RAG)は、大規模言語モデル（LLM）の重要な制約である幻覚や古い知識の問題に取り組む手法です。\n",
      "これには、外部データベースを組み込むことで、最新かつ多様な情報を提供します。\n",
      "しかし、従来のRAG手法では、複数の情報源からの信頼性を考慮せず、関連性に基づいて文書を取得するため、誤情報が蔓延するリスクがあります。\n",
      "\",\n",
      "    \"Novelty\": \"本研究では、複数の情報源の信頼性を評価し、取得および集約プロセスにこの情報を組み込むReliability-Aware RAG（RA-RAG）を提案します。\n",
      "特に、ラベル付けなしでクエリのセットに対する情報源の信頼性と真の回答を反復的に推定します。\n",
      "\",\n",
      "    \"Methodology\": \"RA-RAGは、信頼性の高い情報源から関連文書を選択的に取得し、加重多数決を使用してそれらを集約します。\n",
      "この選択的取得は、パフォーマンスを損なうことなくスケーラビリティを確保します。\n",
      "また、異なる情報源の信頼性を反映したベンチマークを導入し、RA-RAGの効果を評価します。\n",
      "\",\n",
      "    \"Results\": \"RA-RAGは、従来のベースライン手法と比較して、信頼性の異なる情報源からの情報を効果的に統合し、より正確な結果を提供することを示しました。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"Reliability-Aware RAG (RA-RAG)\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: Focus On This, Not That! Steering LLMs With Adaptive Feature Specification\n",
      "published: 2024-10-30 12:01:48+00:00\n",
      "abstruct: Despite the success of Instruction Tuning (IT) in training large language\n",
      "models (LLMs) to perform arbitrary user-specified tasks, these models often\n",
      "still leverage spurious or biased features learned from their training data,\n",
      "leading to undesired behaviours when deploying them in new contexts. In this\n",
      "work, we introduce Focus Instruction Tuning (FIT), which trains LLMs to\n",
      "condition their responses by focusing on specific features whilst ignoring\n",
      "others, leading to different behaviours based on what features are specified.\n",
      "Across several experimental settings, we show that focus-tuned models can be\n",
      "adaptively steered by focusing on different features at inference-time: for\n",
      "instance, robustness can be improved by focusing on task-causal features and\n",
      "ignoring spurious features, and social bias can be mitigated by ignoring\n",
      "demographic categories. Furthermore, FIT can steer behaviour in new contexts,\n",
      "generalising under distribution shift and to new unseen features at inference\n",
      "time, and thereby facilitating more robust, fair, and controllable LLM\n",
      "applications in real-world environments.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22944v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"本研究では、Instruction Tuning (IT) の成功を背景に、特定の特徴に焦点を当てることによって大規模言語モデル (LLMs) の応答を条件付ける新しい手法であるFocus Instruction Tuning (FIT) を提案します。\n",
      "このアプローチは、訓練データから学んだ偏った特徴を無視することで、異なる文脈でのモデルの振る舞いを改善します。\n",
      "\",\n",
      "    \"Novelty\": \"FITは、モデルの応答が特定の特徴に基づいて異なる振る舞いを示すように調整できる点で新しいです。\n",
      "特に、FITはタスク因果特徴に焦点を当て、スプリアス特徴を無視することでロバスト性を向上させ、人口統計カテゴリーを無視することで社会的バイアスを軽減します。\n",
      "\",\n",
      "    \"Methodology\": \"FITは、異なる特徴に焦点を当てた推論時にモデルの振る舞いを適応的に制御する方法です。\n",
      "これにより、FITは分布の変化や新しい未見の特徴に対して一般化でき、現実の環境でのLLMアプリケーションのロバスト性、公平性、制御可能性を高めます。\n",
      "\",\n",
      "    \"Results\": \"実験設定において、焦点を当てたモデルは異なる特徴に基づいて適応的に制御可能であることが示されました。\n",
      "例えば、特定のタスク因果特徴に焦点を当てることでロバスト性が向上し、スプリアス特徴を無視することで社会的バイアスが軽減されました。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"Focus Instruction Tuning (FIT)\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: Multi-Agent Large Language Models for Conversational Task-Solving\n",
      "published: 2024-10-30 11:38:13+00:00\n",
      "abstruct: In an era where single large language models have dominated the landscape of\n",
      "artificial intelligence for years, multi-agent systems arise as new\n",
      "protagonists in conversational task-solving. While previous studies have\n",
      "showcased their potential in reasoning tasks and creative endeavors, an\n",
      "analysis of their limitations concerning the conversational paradigms and the\n",
      "impact of individual agents is missing. It remains unascertained how\n",
      "multi-agent discussions perform across tasks of varying complexity and how the\n",
      "structure of these conversations influences the process. To fill that gap, this\n",
      "work systematically evaluates multi-agent systems across various discussion\n",
      "paradigms, assessing their strengths and weaknesses in both generative tasks\n",
      "and question-answering tasks. Alongside the experiments, I propose a taxonomy\n",
      "of 20 multi-agent research studies from 2022 to 2024, followed by the\n",
      "introduction of a framework for deploying multi-agent LLMs in conversational\n",
      "task-solving. I demonstrate that while multi-agent systems excel in complex\n",
      "reasoning tasks, outperforming a single model by leveraging expert personas,\n",
      "they fail on basic tasks. Concretely, I identify three challenges that arise:\n",
      "1) While longer discussions enhance reasoning, agents fail to maintain\n",
      "conformity to strict task requirements, which leads to problem drift, making\n",
      "shorter conversations more effective for basic tasks. 2) Prolonged discussions\n",
      "risk alignment collapse, raising new safety concerns for these systems. 3) I\n",
      "showcase discussion monopolization through long generations, posing the problem\n",
      "of fairness in decision-making for tasks like summarization. This work uncovers\n",
      "both the potential and challenges that arise with multi-agent interaction and\n",
      "varying conversational paradigms, providing insights into how future research\n",
      "could improve the efficiency, performance, and safety of multi-agent LLMs.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22932v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"この研究は、従来の大規模言語モデルに代わり、会話タスク解決における新たな主役として登場したマルチエージェントシステムを評価するものである。\n",
      "これまでの研究では、マルチエージェントシステムの推論タスクや創造的な取り組みの潜在能力が示されているが、会話のパラダイムや個々のエージェントの影響に関する分析が不足している。\n",
      "本研究は、さまざまな議論のパラダイムにおけるマルチエージェントシステムの強みと弱みを体系的に評価し、生成タスクと質問応答タスクにおける性能を分析する。\n",
      "\",\n",
      "    \"Novelty\": \"2022年から2024年の20件のマルチエージェント研究を分類したタクソノミーを提案し、会話タスク解決におけるマルチエージェントLLMの導入フレームワークを紹介する点が新しい。\n",
      "これは、マルチエージェントシステムが複雑な推論タスクにおいて優れた性能を示す一方で、基本的なタスクでは失敗することを明らかにする。\n",
      "\",\n",
      "    \"Methodology\": \"本研究では、マルチエージェントシステムの長期的な議論が推論を強化する一方で、タスク要件に対する整合性を維持できないという問題、長引く議論によるアラインメント崩壊のリスク、そして長い生成による議論の独占化という問題を特定し、これらの課題を解決するための方法を提案する。\n",
      "\",\n",
      "    \"Results\": \"複雑な推論タスクにおいてはマルチエージェントシステムが単一モデルを上回るが、基本的なタスクでは短い会話の方が効果的であることが示された。\n",
      "さらに、これらのシステムにおける安全性の懸念も浮き彫りになり、今後の研究がマルチエージェントLLMの効率、性能、安全性を向上させるための洞察を提供する。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"マルチエージェントシステムの導入フレームワーク\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: Explainable Behavior Cloning: Teaching Large Language Model Agents through Learning by Demonstration\n",
      "published: 2024-10-30 11:14:33+00:00\n",
      "abstruct: Autonomous mobile app interaction has become increasingly important with\n",
      "growing complexity of mobile applications. Developing intelligent agents that\n",
      "can effectively navigate and interact with mobile apps remains a significant\n",
      "challenge. In this paper, we propose an Explainable Behavior Cloning LLM Agent\n",
      "(EBC-LLMAgent), a novel approach that combines large language models (LLMs)\n",
      "with behavior cloning by learning demonstrations to create intelligent and\n",
      "explainable agents for autonomous mobile app interaction. EBC-LLMAgent consists\n",
      "of three core modules: Demonstration Encoding, Code Generation, and UI Mapping,\n",
      "which work synergistically to capture user demonstrations, generate executable\n",
      "codes, and establish accurate correspondence between code and UI elements. We\n",
      "introduce the Behavior Cloning Chain Fusion technique to enhance the\n",
      "generalization capabilities of the agent. Extensive experiments on five popular\n",
      "mobile applications from diverse domains demonstrate the superior performance\n",
      "of EBC-LLMAgent, achieving high success rates in task completion, efficient\n",
      "generalization to unseen scenarios, and the generation of meaningful\n",
      "explanations.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22916v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"自律型モバイルアプリのインタラクションは、モバイルアプリケーションの複雑さが増す中で重要性を増しています。\n",
      "本論文では、モバイルアプリとの自律的なインタラクションのために、インテリジェントで説明可能なエージェントを作成する新しいアプローチである説明可能な行動クローンLLMエージェント（EBC-LLMAgent）を提案します。\n",
      "\",\n",
      "    \"Novelty\": \"EBC-LLMAgentは、大規模言語モデル（LLM）と行動クローンを組み合わせた革新的な方法であり、ユーザーのデモンストレーションを学習することで、インテリジェントで説明可能なエージェントを実現します。\n",
      "\",\n",
      "    \"Methodology\": \"EBC-LLMAgentは、デモンストレーションエンコーディング、コード生成、UIマッピングという三つのコアモジュールから構成されており、これらが協調してユーザーデモをキャプチャし、実行可能なコードを生成し、コードとUI要素の間の正確な対応を確立します。\n",
      "また、行動クローンチェインフュージョン技術を導入し、エージェントの一般化能力を向上させています。\n",
      "\",\n",
      "    \"Results\": \"多様なドメインの5つの人気モバイルアプリケーションに関する広範な実験により、EBC-LLMAgentは、タスク完了の成功率が高く、未見のシナリオへの効率的な一般化を実現し、意味のある説明を生成する優れた性能を示しました。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"説明可能な行動クローンLLMエージェント（EBC-LLMAgent）\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: Stealing User Prompts from Mixture of Experts\n",
      "published: 2024-10-30 10:25:35+00:00\n",
      "abstruct: Mixture-of-Experts (MoE) models improve the efficiency and scalability of\n",
      "dense language models by routing each token to a small number of experts in\n",
      "each layer. In this paper, we show how an adversary that can arrange for their\n",
      "queries to appear in the same batch of examples as a victim's queries can\n",
      "exploit Expert-Choice-Routing to fully disclose a victim's prompt. We\n",
      "successfully demonstrate the effectiveness of this attack on a two-layer\n",
      "Mixtral model, exploiting the tie-handling behavior of the torch.topk CUDA\n",
      "implementation. Our results show that we can extract the entire prompt using\n",
      "$O({VM}^2)$ queries (with vocabulary size $V$ and prompt length $M$) or 100\n",
      "queries on average per token in the setting we consider. This is the first\n",
      "attack to exploit architectural flaws for the purpose of extracting user\n",
      "prompts, introducing a new class of LLM vulnerabilities.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22884v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"Mixture-of-Experts (MoE)モデルは、各トークンを各レイヤーの少数の専門家にルーティングすることで、密な言語モデルの効率とスケーラビリティを向上させます。\n",
      "この論文では、攻撃者が自らのクエリを被害者のクエリと同じバッチに配置できる場合、Expert-Choice-Routingを悪用して被害者のプロンプトを完全に開示できることを示します。\n",
      "\",\n",
      "    \"Novelty\": \"この攻撃は、ユーザープロンプトを抽出する目的でアーキテクチャの欠陥を利用する初めての試みであり、新しいクラスの大規模言語モデル（LLM）脆弱性を導入します。\n",
      "\",\n",
      "    \"Methodology\": \"2層のMixtralモデルを用いた実験において、torch.topk CUDA実装のタイハンドリング動作を悪用して、この攻撃の効果を実証しました。\n",
      "\",\n",
      "    \"Results\": \"私たちの結果は、考慮した設定において、$O({VM}^2)$のクエリ、またはトークンあたり平均100のクエリでプロンプト全体を抽出できることを示しています。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"Expert-Choice-Routing\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: Eliciting Critical Reasoning in Retrieval-Augmented Language Models via Contrastive Explanations\n",
      "published: 2024-10-30 10:11:53+00:00\n",
      "abstruct: Retrieval-augmented generation (RAG) has emerged as a critical mechanism in\n",
      "contemporary NLP to support Large Language Models(LLMs) in systematically\n",
      "accessing richer factual context. However, the integration of RAG mechanisms\n",
      "brings its inherent challenges, as LLMs need to deal with potentially noisy\n",
      "contexts. Recent studies have shown that LLMs still struggle to critically\n",
      "analyse RAG-based in-context information, a limitation that may lead to\n",
      "incorrect inferences and hallucinations. In this paper, we investigate how to\n",
      "elicit critical reasoning in RAG via contrastive explanations. In particular,\n",
      "we propose Contrastive-RAG (C-RAG), a framework that (i) retrieves relevant\n",
      "documents given a query, (ii) selects and exemplifies relevant passages, and\n",
      "(iii) generates explanations that explicitly contrast the relevance of the\n",
      "passages to (iv) support the final answer. We show the impact of C-RAG building\n",
      "contrastive reasoning demonstrations from LLMs to instruct smaller models for\n",
      "retrieval-augmented tasks. Extensive experiments demonstrate that C-RAG\n",
      "improves state-of-the-art RAG models while (a) requiring significantly fewer\n",
      "prompts and demonstrations and (b) being robust to perturbations in the\n",
      "retrieved documents.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22874v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"Retrieval-augmented generation (RAG)は、現代の自然言語処理において大規模言語モデル（LLMs）がより豊富な事実的文脈に体系的にアクセスするための重要なメカニズムとして浮上しています。\n",
      "しかし、RAGメカニズムの統合には固有の課題があり、LLMsは潜在的にノイズの多い文脈に対処する必要があります。\n",
      "最近の研究では、LLMsがRAGベースの文脈情報を批判的に分析するのに苦労していることが示されており、これが誤った推論や幻覚を引き起こす可能性があります。\n",
      "\",\n",
      "    \"Novelty\": \"本論文では、対比説明を通じてRAGにおける批判的推論を引き出す方法を調査しています。\n",
      "特に、Contrastive-RAG（C-RAG）というフレームワークを提案し、これにより関連する文書をクエリに基づいて取得し、関連するパッセージを選択して例示し、最終的な答えをサポートするためにパッセージの関連性を明示的に対比する説明を生成します。\n",
      "\",\n",
      "    \"Methodology\": \"C-RAGは以下のプロセスで構成されています：(i) クエリに基づいて関連する文書を取得する、(ii) 関連するパッセージを選択して例示する、(iii) パッセージの関連性を対比する説明を生成する、(iv) 最終的な答えをサポートする。\n",
      "\",\n",
      "    \"Results\": \"C-RAGがLLMsから対比的推論デモンストレーションを構築し、より小さなモデルに対してRAGタスクを指導する影響を示しました。\n",
      "広範な実験により、C-RAGが最先端のRAGモデルを改善し、(a) 必要なプロンプトとデモンストレーションを大幅に削減し、(b) 取得された文書の摂動に対して堅牢であることが実証されました。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"Contrastive-RAG (C-RAG)\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: HijackRAG: Hijacking Attacks against Retrieval-Augmented Large Language Models\n",
      "published: 2024-10-30 09:15:51+00:00\n",
      "abstruct: Retrieval-Augmented Generation (RAG) systems enhance large language models\n",
      "(LLMs) by integrating external knowledge, making them adaptable and\n",
      "cost-effective for various applications. However, the growing reliance on these\n",
      "systems also introduces potential security risks. In this work, we reveal a\n",
      "novel vulnerability, the retrieval prompt hijack attack (HijackRAG), which\n",
      "enables attackers to manipulate the retrieval mechanisms of RAG systems by\n",
      "injecting malicious texts into the knowledge database. When the RAG system\n",
      "encounters target questions, it generates the attacker's pre-determined answers\n",
      "instead of the correct ones, undermining the integrity and trustworthiness of\n",
      "the system. We formalize HijackRAG as an optimization problem and propose both\n",
      "black-box and white-box attack strategies tailored to different levels of the\n",
      "attacker's knowledge. Extensive experiments on multiple benchmark datasets show\n",
      "that HijackRAG consistently achieves high attack success rates, outperforming\n",
      "existing baseline attacks. Furthermore, we demonstrate that the attack is\n",
      "transferable across different retriever models, underscoring the widespread\n",
      "risk it poses to RAG systems. Lastly, our exploration of various defense\n",
      "mechanisms reveals that they are insufficient to counter HijackRAG, emphasizing\n",
      "the urgent need for more robust security measures to protect RAG systems in\n",
      "real-world deployments.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22832v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"Retrieval-Augmented Generation (RAG)システムは、大規模言語モデル（LLM）を外部の知識と統合することで強化され、さまざまなアプリケーションに適応可能でコスト効率が良い。\n",
      " しかし、これらのシステムへの依存が高まることで、潜在的なセキュリティリスクも生じる。\n",
      "\",\n",
      "    \"Novelty\": \"本研究では、retrieval prompt hijack attack（HijackRAG）という新たな脆弱性を明らかにした。\n",
      "これは、攻撃者が悪意のあるテキストを知識データベースに注入することで、RAGシステムの情報取得メカニズムを操作することを可能にする。\n",
      "\",\n",
      "    \"Methodology\": \"HijackRAGを最適化問題として定式化し、攻撃者の知識レベルに応じたブラックボックスおよびホワイトボックス攻撃戦略の両方を提案した。\n",
      "\",\n",
      "    \"Results\": \"複数のベンチマークデータセットでの広範な実験により、HijackRAGは既存のベースライン攻撃を上回る高い攻撃成功率を達成することが示された。\n",
      "また、この攻撃は異なるリトリーバモデル間で移転可能であることが示され、RAGシステムに対する広範なリスクを強調した。\n",
      "さらに、さまざまな防御メカニズムを検討した結果、HijackRAGに対抗するには不十分であることが明らかになり、実際の展開におけるより堅牢なセキュリティ対策の必要性が強調された。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"retrieval prompt hijack attack (HijackRAG)\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: EvoCodeBench: An Evolving Code Generation Benchmark with Domain-Specific Evaluations\n",
      "published: 2024-10-30 08:57:59+00:00\n",
      "abstruct: How to evaluate Large Language Models (LLMs) in code generation remains an\n",
      "open question. Existing benchmarks have two limitations - data leakage and lack\n",
      "of domain-specific evaluation. The former hurts the fairness of benchmarks, and\n",
      "the latter hinders practitioners from selecting superior LLMs for specific\n",
      "programming domains. To address these two limitations, we propose a new\n",
      "benchmark - EvoCodeBench, which has the following advances: (1) Evolving data.\n",
      "EvoCodeBench will be dynamically updated every period (e.g., 6 months) to avoid\n",
      "data leakage. This paper releases the first version - EvoCodeBench-2403,\n",
      "containing 275 samples from 25 repositories. (2) A domain taxonomy and domain\n",
      "labels. Based on the statistics of open-source communities, we design a\n",
      "programming domain taxonomy consisting of 10 popular domains. Based on the\n",
      "taxonomy, we annotate each sample in EvoCodeBench with a domain label. (3)\n",
      "Domain-specific evaluations. Besides the Pass@k, we compute the Domain-Specific\n",
      "Improvement (DSI) and define LLMs' comfort and strange domains. These\n",
      "evaluations help practitioners select superior LLMs in specific domains and\n",
      "discover the shortcomings of existing LLMs. We evaluate 8 popular LLMs (e.g.,\n",
      "gpt-4, DeepSeek Coder) on EvoCodeBench and summarize some insights.\n",
      "EvoCodeBench reveals the actual abilities of these LLMs in real-world\n",
      "repositories. For example, the highest Pass@1 of gpt-4 on EvoCodeBench-2403 is\n",
      "only 20.74%. Besides, we evaluate LLMs in different domains and discover their\n",
      "comfort and strange domains. For example, gpt-4 performs best in most domains\n",
      "but falls behind others in the Internet domain. StarCoder 2-15B unexpectedly\n",
      "performs well in the Database domain and even outperforms 33B LLMs.\n",
      "EvoCodeBench has been released.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22821v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"大規模言語モデル（LLMs）をコード生成において評価する方法は、未解決の問題です。\n",
      "既存のベンチマークにはデータ漏洩とドメイン特化型評価の欠如という2つの制限があります。\n",
      "これにより、ベンチマークの公平性が損なわれ、特定のプログラミングドメインに対して優れたLLMsを選択することが困難になります。\n",
      "\",\n",
      "    \"Novelty\": \"この問題に対処するために、新しいベンチマークEvoCodeBenchを提案します。\n",
      "EvoCodeBenchは、データを定期的に動的に更新し（例：6ヶ月ごと）、データ漏洩を避けることができます。\n",
      "また、プログラミングドメインに基づく分類法とドメインラベルを設計し、各サンプルにドメインラベルを付けます。\n",
      "\",\n",
      "    \"Methodology\": \"EvoCodeBenchでは、Pass@kに加えて、ドメイン特化型の改善（DSI）を計算し、LLMsの快適なドメインと異常なドメインを定義します。\n",
      "これにより、特定のドメインにおいて優れたLLMsを選択する手助けをし、既存のLLMsの短所を発見します。\n",
      "8つの人気LLMs（例：gpt-4、DeepSeek Coder）をEvoCodeBenchで評価し、いくつかの洞察をまとめます。\n",
      "\",\n",
      "    \"Results\": \"EvoCodeBenchは、これらのLLMsの実際の能力を明らかにします。\n",
      "例えば、EvoCodeBench-2403でのgpt-4の最高Pass@1はわずか20.74%であり、LLMsを異なるドメインで評価することで、快適なドメインと異常なドメインを発見しました。\n",
      "gpt-4はほとんどのドメインで最も優れた性能を示しますが、インターネットドメインでは他のモデルに劣ります。\n",
      "StarCoder 2-15Bは、データベースドメインで予想外に良いパフォーマンスを発揮し、33BのLLMsをも上回ります。\n",
      "EvoCodeBenchは公開されています。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"EvoCodeBench\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: A test-free semantic mistakes localization framework in Neural Code Translation\n",
      "published: 2024-10-30 08:53:33+00:00\n",
      "abstruct: In the task of code translation, neural network-based models have been shown\n",
      "to frequently produce semantically erroneous code that deviates from the\n",
      "original logic of the source code. This issue persists even with advanced large\n",
      "models. Although a recent approach proposed using test cases to identify these\n",
      "semantic errors, it relies heavily on the quality of the test cases and is not\n",
      "applicable to code snippets without test cases in real-world scenarios.\n",
      "Therefore, We present EISP, a static analysis framework based on the Large\n",
      "Language Model (LLM).First, the framework generates a semantic mapping between\n",
      "source code and translated code. Next, each sub-code fragment is identified by\n",
      "recursively traversing the abstract syntax tree of the source code, and its\n",
      "corresponding translated code fragment is found through the semantic mapping.\n",
      "Finally, EISP connects each pair of sub-code fragments with fine-grained\n",
      "knowledge hints through an AI chain to assist LLMs in discovering semantic\n",
      "mistakes in the translated code. In our benchmark evaluation, the EISP\n",
      "framework, based on GPT-4o mini, achieved an accuracy of 82.3\\%, representing a\n",
      "20.3\\% improvement over baseline methods using the same base model, and a 7.4\\%\n",
      "improvement compared to dynamic analysis methods that require test cases and\n",
      "manual intervention. To our knowledge, EISP is the first tool to locate\n",
      "semantic errors in translated code without test cases or compilable code. This\n",
      "innovative tool provides the software engineering community with a new way to\n",
      "deal with code fragments without test cases.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22818v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"コード翻訳のタスクにおいて、ニューラルネットワークベースのモデルは、元のソースコードの論理から逸脱する意味的に誤ったコードを頻繁に生成することが示されています。\n",
      "この問題は、高度な大規模モデルでも持続しています。\n",
      "最近のアプローチでは、テストケースを使用してこれらの意味的エラーを特定することが提案されましたが、テストケースの質に大きく依存しており、実世界のシナリオでテストケースのないコードスニペットには適用できません。\n",
      "\",\n",
      "    \"Novelty\": \"EISPは、テストケースやコンパイル可能なコードなしで翻訳されたコード内の意味的エラーを特定する最初のツールです。\n",
      "この革新的なツールは、ソフトウェア工学コミュニティに対して、テストケースなしでコードフラグメントを扱う新しい方法を提供します。\n",
      "\",\n",
      "    \"Methodology\": \"EISPは、Large Language Model（LLM）に基づいた静的分析フレームワークです。\n",
      "最初に、フレームワークはソースコードと翻訳されたコードの間に意味的マッピングを生成します。\n",
      "次に、ソースコードの抽象構文木を再帰的にトラバースすることで各サブコードフラグメントを特定し、その対応する翻訳コードフラグメントを意味的マッピングを通じて見つけます。\n",
      "最後に、EISPはAIチェーンを介して各サブコードフラグメントのペアを微細な知識ヒントで接続し、LLMが翻訳コード内の意味的な誤りを発見するのを支援します。\n",
      "\",\n",
      "    \"Results\": \"EISPフレームワークは、GPT-4o miniをベースにしたベンチマーク評価において、82.3%の精度を達成し、同じベースモデルを使用したベースライン手法に対して20.3%の改善を示しました。\n",
      "また、テストケースと手動介入を必要とする動的分析手法に対しては7.4%の改善を達成しました。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"EISP\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: Towards Robust and Efficient Federated Low-Rank Adaptation with Heterogeneous Clients\n",
      "published: 2024-10-30 08:48:21+00:00\n",
      "abstruct: Federated fine-tuning for Large Language Models (LLMs) has recently gained\n",
      "attention due to the heavy communication overhead of transmitting large model\n",
      "updates. Low Rank Adaptation (LoRA) has been proposed as a solution, yet its\n",
      "application in federated learning is complicated by discordance in aggregation.\n",
      "Existing methods addressing this discordance often suffer from performance\n",
      "degradation at low ranks in heterogeneous data settings. In response, we\n",
      "introduce LoRA-A2 (Low Rank Adaptation with Alternating freeze and Adaptive\n",
      "rank selection), which demonstrates robustness in challenging settings with low\n",
      "ranks and high data heterogeneity. Our experimental findings reveal that\n",
      "LoRA-A2 maintains performance even under extreme heterogeneity and low rank\n",
      "conditions, achieving up to a 99.8% reduction in uploaded parameters compared\n",
      "to full fine-tuning without compromising performance. This adaptive mechanism\n",
      "boosts robustness and communication efficiency in federated fine-tuning,\n",
      "enabling the practical deployment of LLMs in resource-constrained environments.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22815v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"大規模言語モデル（LLM）のためのフェデレーテッドファインチューニングは、モデルの大きな更新を送信する際の通信オーバーヘッドのため、最近注目を集めています。\n",
      "低ランク適応（LoRA）が解決策として提案されていますが、フェデレーテッドラーニングにおけるその適用は、集約における不一致によって複雑になります。\n",
      "\",\n",
      "    \"Novelty\": \"私たちは、ローレンキュレーションと適応ランク選択を交互に行うLoRA-A2という新しい手法を導入し、低ランクかつ高データ異質性の厳しい環境でも堅牢性を示します。\n",
      "\",\n",
      "    \"Methodology\": \"LoRA-A2は、極端な異質性と低ランク条件下でもパフォーマンスを維持し、完全なファインチューニングと比較してアップロードされるパラメータを最大99.8%削減します。\n",
      "この適応メカニズムは、フェデレーテッドファインチューニングにおける堅牢性と通信効率を向上させ、リソースが制約された環境でのLLMの実用的な展開を可能にします。\n",
      "\",\n",
      "    \"Results\": \"実験結果は、LoRA-A2が低ランク条件下でもパフォーマンスを損なうことなく、通信効率を大幅に改善することを示しています。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"LoRA-A2\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: Causality-Enhanced Behavior Sequence Modeling in LLMs for Personalized Recommendation\n",
      "published: 2024-10-30 08:41:13+00:00\n",
      "abstruct: Recent advancements in recommender systems have focused on leveraging Large\n",
      "Language Models (LLMs) to improve user preference modeling, yielding promising\n",
      "outcomes. However, current LLM-based approaches struggle to fully leverage user\n",
      "behavior sequences, resulting in suboptimal preference modeling for\n",
      "personalized recommendations. In this study, we propose a novel Counterfactual\n",
      "Fine-Tuning (CFT) method to address this issue by explicitly emphasizing the\n",
      "role of behavior sequences when generating recommendations. Specifically, we\n",
      "employ counterfactual reasoning to identify the causal effects of behavior\n",
      "sequences on model output and introduce a task that directly fits the\n",
      "ground-truth labels based on these effects, achieving the goal of explicit\n",
      "emphasis. Additionally, we develop a token-level weighting mechanism to adjust\n",
      "the emphasis strength for different item tokens, reflecting the diminishing\n",
      "influence of behavior sequences from earlier to later tokens during predicting\n",
      "an item. Extensive experiments on real-world datasets demonstrate that CFT\n",
      "effectively improves behavior sequence modeling. Our codes are available at\n",
      "https://github.com/itsmeyjt/CFT.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22809v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"最近の推薦システムの進展は、大規模言語モデル（LLM）を活用してユーザーの嗜好モデルを改善することに焦点を当てていますが、現在のLLMベースのアプローチはユーザー行動シーケンスを十分に活用できておらず、パーソナライズされた推薦に対して最適ではありません。\n",
      "\",\n",
      "    \"Novelty\": \"本研究では、行動シーケンスの役割を明示的に強調する新しい反事実的ファインチューニング（CFT）手法を提案します。\n",
      "これは、モデル出力に対する行動シーケンスの因果効果を特定するために反事実的推論を使用し、これらの効果に基づいて真実のラベルに直接適合するタスクを導入することで、明示的な強調の目標を達成します。\n",
      "\",\n",
      "    \"Methodology\": \"さらに、異なるアイテムトークンに対する強調の強さを調整するためのトークンレベルの重み付けメカニズムを開発し、アイテムを予測する際に、初期から後期のトークンにかけて行動シーケンスの影響が減少することを反映します。\n",
      "\",\n",
      "    \"Results\": \"実世界のデータセットに関する広範な実験により、CFTが行動シーケンスのモデリングを効果的に改善することが示されています。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"反事実的ファインチューニング（CFT）\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: Less is More: DocString Compression in Code Generation\n",
      "published: 2024-10-30 08:17:10+00:00\n",
      "abstruct: The widespread use of Large Language Models (LLMs) in software engineering\n",
      "has intensified the need for improved model and resource efficiency. In\n",
      "particular, for neural code generation, LLMs are used to translate\n",
      "function/method signature and DocString to executable code. DocStrings which\n",
      "capture user re quirements for the code and used as the prompt for LLMs, often\n",
      "contains redundant information. Recent advancements in prompt compression have\n",
      "shown promising results in Natural Language Processing (NLP), but their\n",
      "applicability to code generation remains uncertain. Our empirical study show\n",
      "that the state-of-the-art prompt compression methods achieve only about 10%\n",
      "reduction, as further reductions would cause significant performance\n",
      "degradation. In our study, we propose a novel compression method, ShortenDoc,\n",
      "dedicated to DocString compression for code generation. Our extensive\n",
      "experiments on six code generation datasets, five open-source LLMs (1B to 10B\n",
      "parameters), and one closed-source LLM GPT-4o confirm that ShortenDoc achieves\n",
      "25-40% compression while preserving the quality of generated code,\n",
      "outperforming other baseline methods at similar compression levels. The benefit\n",
      "of this research is to improve efficiency and reduce the cost while maintaining\n",
      "the quality of the generated code, especially when calling third-party APIs,\n",
      "and is able to reduce the token processing cost by 25-40%.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22793v2\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"大規模言語モデル（LLMs）のソフトウェア工学における広範な利用は、モデルとリソースの効率性向上へのニーズを強めています。\n",
      "特に、神経コード生成において、LLMsは関数/メソッドの署名とDocStringを実行可能なコードに変換するために使用されます。\n",
      "DocStringはコードのユーザー要件を捉え、LLMsのプロンプトとして機能しますが、冗長な情報を含むことが多いです。\n",
      "最近のプロンプト圧縮の進展は自然言語処理（NLP）で有望な結果を示していますが、コード生成への適用可能性は不確かです。\n",
      "\",\n",
      "    \"Novelty\": \"私たちの実証研究では、最先端のプロンプト圧縮手法は約10%の圧縮しか達成できないことがわかりました。\n",
      "さらなる圧縮はパフォーマンスの大幅な劣化を引き起こすため、従来の方法が限界に達していることを示しています。\n",
      "私たちは、コード生成のためのDocString圧縮に特化した新しい圧縮手法ShortenDocを提案します。\n",
      "\",\n",
      "    \"Methodology\": \"この研究では、6つのコード生成データセット、5つのオープンソースLLMs（1Bから10Bパラメータ）、およびクローズドソースのLLM GPT-4oを用いて広範な実験を行いました。\n",
      "ShortenDocは、生成されたコードの品質を維持しながら25-40%の圧縮を実現し、同様の圧縮レベルでの他のベースライン手法を上回る性能を示しました。\n",
      "\",\n",
      "    \"Results\": \"この研究の利点は、第三者APIを呼び出す際に生成されたコードの品質を維持しながら効率を改善し、コストを削減することです。\n",
      "また、トークン処理コストを25-40%削減できることが確認されました。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"ShortenDoc\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: MALoRA: Mixture of Asymmetric Low-Rank Adaptation for Enhanced Multi-Task Learning\n",
      "published: 2024-10-30 07:53:52+00:00\n",
      "abstruct: Parameter-Efficient Fine-Tuning (PEFT) methods like LoRA have significantly\n",
      "improved the adaptation of LLMs to downstream tasks in a resource-efficient\n",
      "manner. However, in multi-task scenarios, challenges such as training imbalance\n",
      "and the seesaw effect frequently emerge. Mixture-of-LoRA (MoLoRA), which\n",
      "combines LoRA with sparse Mixture-of-Experts, mitigates some of these issues by\n",
      "promoting task-specific learning across experts. Despite this, MoLoRA remains\n",
      "inefficient in terms of training speed, parameter utilization, and overall\n",
      "multi-task performance. In this paper, we propose Mixture of Asymmetric\n",
      "Low-Rank Adaptaion (MALoRA), a flexible fine-tuning framework that leverages\n",
      "asymmetric optimization across LoRA experts. MALoRA reduces the number of\n",
      "trainable parameters by 30% to 48%, increases training speed by 1.2x, and\n",
      "matches the computational efficiency of single-task LoRA models. Additionally,\n",
      "MALoRA addresses overfitting issues commonly seen in high-rank configurations,\n",
      "enhancing performance stability. Extensive experiments across diverse\n",
      "multi-task learning scenarios demonstrate that MALoRA consistently outperforms\n",
      "all baseline methods in both inter-domain and intra-domain tasks.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22782v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"Parameter-Efficient Fine-Tuning (PEFT)手法は、LoRAのように、リソース効率の良い方法で大規模言語モデル（LLMs）を下流タスクに適応させることを大幅に改善しました。\n",
      "しかし、マルチタスクシナリオでは、トレーニングの不均衡やシーソー効果といった課題がしばしば発生します。\n",
      "Mixture-of-LoRA (MoLoRA)は、LoRAをスパースなMixture-of-Expertsと組み合わせることで、専門家間でのタスク特化型学習を促進し、これらの問題のいくつかを緩和します。\n",
      "それにもかかわらず、MoLoRAはトレーニング速度、パラメータ利用率、全体的なマルチタスクパフォーマンスにおいて依然として非効率的です。\n",
      "\",\n",
      "    \"Novelty\": \"本論文では、非対称最適化をLoRA専門家間で活用する柔軟なファインチューニングフレームワークであるMixture of Asymmetric Low-Rank Adaptation (MALoRA)を提案します。\n",
      "MALoRAは、トレーニング可能なパラメータの数を30%から48%削減し、トレーニング速度を1.2倍向上させ、単一タスクLoRAモデルと同等の計算効率を実現します。\n",
      "\",\n",
      "    \"Methodology\": \"MALoRAは、非対称最適化を利用しており、高ランク構成で一般的に見られるオーバーフィッティングの問題に対処し、パフォーマンスの安定性を向上させます。\n",
      "多様なマルチタスク学習シナリオでの広範な実験により、MALoRAは、異なるドメイン間および同一ドメインタスクにおいて、すべてのベースライン手法を一貫して上回ることが示されました。\n",
      "\",\n",
      "    \"Results\": \"MALoRAは、パラメータの数を減少させ、トレーニング速度を向上させ、オーバーフィッティングの問題を解決することで、安定したパフォーマンスを実現しました。\n",
      "実験結果は、MALoRAが従来の手法よりも優れていることを示しています。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"Mixture of Asymmetric Low-Rank Adaptation (MALoRA)\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: InjecGuard: Benchmarking and Mitigating Over-defense in Prompt Injection Guardrail Models\n",
      "published: 2024-10-30 07:39:42+00:00\n",
      "abstruct: Prompt injection attacks pose a critical threat to large language models\n",
      "(LLMs), enabling goal hijacking and data leakage. Prompt guard models, though\n",
      "effective in defense, suffer from over-defense -- falsely flagging benign\n",
      "inputs as malicious due to trigger word bias. To address this issue, we\n",
      "introduce NotInject, an evaluation dataset that systematically measures\n",
      "over-defense across various prompt guard models. NotInject contains 339 benign\n",
      "samples enriched with trigger words common in prompt injection attacks,\n",
      "enabling fine-grained evaluation. Our results show that state-of-the-art models\n",
      "suffer from over-defense issues, with accuracy dropping close to random\n",
      "guessing levels (60%). To mitigate this, we propose InjecGuard, a novel prompt\n",
      "guard model that incorporates a new training strategy, Mitigating Over-defense\n",
      "for Free (MOF), which significantly reduces the bias on trigger words.\n",
      "InjecGuard demonstrates state-of-the-art performance on diverse benchmarks\n",
      "including NotInject, surpassing the existing best model by 30.8%, offering a\n",
      "robust and open-source solution for detecting prompt injection attacks. The\n",
      "code and datasets are released at https://github.com/SaFoLab-WISC/InjecGuard.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22770v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"プロンプトインジェクション攻撃は、大規模言語モデル（LLMs）にとって重大な脅威であり、目標の乗っ取りやデータ漏洩を可能にします。\n",
      "プロンプトガードモデルは防御に効果的ですが、トリガーワードバイアスのために無害な入力を悪意のあるものとして誤ってフラグ付けする過剰防御の問題があります。\n",
      "\",\n",
      "    \"Novelty\": \"この問題に対処するために、NotInjectという評価データセットを導入しました。\n",
      "このデータセットは、プロンプトインジェクション攻撃で一般的なトリガーワードを用いて339の無害なサンプルを含んでおり、様々なプロンプトガードモデルの過剰防御を体系的に測定します。\n",
      "\",\n",
      "    \"Methodology\": \"新しいトレーニング戦略である「Mitigating Over-defense for Free (MOF)」を組み込んだ新しいプロンプトガードモデルInjecGuardを提案します。\n",
      "これはトリガーワードに対するバイアスを大幅に低減します。\n",
      "\",\n",
      "    \"Results\": \"InjecGuardはNotInjectを含む多様なベンチマークで最先端の性能を示し、既存の最良モデルを30.8%上回ります。\n",
      "また、プロンプトインジェクション攻撃を検出するための堅牢でオープンソースのソリューションを提供します。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"InjecGuard\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: Beyond Ontology in Dialogue State Tracking for Goal-Oriented Chatbot\n",
      "published: 2024-10-30 07:36:23+00:00\n",
      "abstruct: Goal-oriented chatbots are essential for automating user tasks, such as\n",
      "booking flights or making restaurant reservations. A key component of these\n",
      "systems is Dialogue State Tracking (DST), which interprets user intent and\n",
      "maintains the dialogue state. However, existing DST methods often rely on fixed\n",
      "ontologies and manually compiled slot values, limiting their adaptability to\n",
      "open-domain dialogues. We propose a novel approach that leverages instruction\n",
      "tuning and advanced prompt strategies to enhance DST performance, without\n",
      "relying on any predefined ontologies. Our method enables Large Language Model\n",
      "(LLM) to infer dialogue states through carefully designed prompts and includes\n",
      "an anti-hallucination mechanism to ensure accurate tracking in diverse\n",
      "conversation contexts. Additionally, we employ a Variational Graph Auto-Encoder\n",
      "(VGAE) to model and predict subsequent user intent. Our approach achieved\n",
      "state-of-the-art with a JGA of 42.57% outperforming existing ontology-less DST\n",
      "models, and performed well in open-domain real-world conversations. This work\n",
      "presents a significant advancement in creating more adaptive and accurate\n",
      "goal-oriented chatbots.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22767v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"目標指向型チャットボットは、フライトの予約やレストランの予約など、ユーザーのタスクを自動化するために重要です。\n",
      "これらのシステムの重要な要素は、ユーザーの意図を解釈し、対話の状態を維持するための対話状態追跡（DST）です。\n",
      "\",\n",
      "    \"Novelty\": \"従来のDST手法は固定されたオントロジーと手動で作成されたスロット値に依存しており、オープンドメインの対話への適応性が制限されています。\n",
      "私たちの提案する新しいアプローチは、指示調整と高度なプロンプト戦略を活用して、事前定義されたオントロジーに依存せずにDSTのパフォーマンスを向上させることです。\n",
      "\",\n",
      "    \"Methodology\": \"私たちの方法では、大規模言語モデル（LLM）が慎重に設計されたプロンプトを通じて対話状態を推論できるようにし、多様な会話コンテキストでの正確な追跡を保証するための反ハルシネーションメカニズムを含んでいます。\n",
      "また、次のユーザーの意図をモデル化し予測するために変分グラフオートエンコーダ（VGAE）を採用しています。\n",
      "\",\n",
      "    \"Results\": \"私たちのアプローチは、既存のオントロジーなしのDSTモデルを上回り、42.57%のJGAで最先端の成果を達成し、オープンドメインの実世界の会話でも良好に機能しました。\n",
      "この研究は、より適応的かつ正確な目標指向型チャットボットの作成において重要な進展を示しています。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"指示調整と高度なプロンプト戦略\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: Improving Uncertainty Quantification in Large Language Models via Semantic Embeddings\n",
      "published: 2024-10-30 04:41:46+00:00\n",
      "abstruct: Accurately quantifying uncertainty in large language models (LLMs) is crucial\n",
      "for their reliable deployment, especially in high-stakes applications. Current\n",
      "state-of-the-art methods for measuring semantic uncertainty in LLMs rely on\n",
      "strict bidirectional entailment criteria between multiple generated responses\n",
      "and also depend on sequence likelihoods. While effective, these approaches\n",
      "often overestimate uncertainty due to their sensitivity to minor wording\n",
      "differences, additional correct information, and non-important words in the\n",
      "sequence. We propose a novel approach that leverages semantic embeddings to\n",
      "achieve smoother and more robust estimation of semantic uncertainty in LLMs. By\n",
      "capturing semantic similarities without depending on sequence likelihoods, our\n",
      "method inherently reduces any biases introduced by irrelevant words in the\n",
      "answers. Furthermore, we introduce an amortised version of our approach by\n",
      "explicitly modelling semantics as latent variables in a joint probabilistic\n",
      "model. This allows for uncertainty estimation in the embedding space with a\n",
      "single forward pass, significantly reducing computational overhead compared to\n",
      "existing multi-pass methods. Experiments across multiple question-answering\n",
      "datasets and frontier LLMs demonstrate that our embedding-based methods provide\n",
      "more accurate and nuanced uncertainty quantification than traditional\n",
      "approaches.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22685v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"大規模言語モデル（LLMs）における不確実性の正確な定量化は、高リスクなアプリケーションでの信頼性のある展開にとって重要である。\n",
      "現在の最先端の方法は、生成された複数の応答間の双方向的な含意基準に依存しており、シーケンスの尤度にも依存している。\n",
      "\",\n",
      "    \"Novelty\": \"提案された新しいアプローチは、意味的埋め込みを活用して、LLMsにおける意味的不確実性のより滑らかで堅牢な推定を実現するものである。\n",
      "これにより無関係な単語によって導入されるバイアスが減少する。\n",
      "\",\n",
      "    \"Methodology\": \"我々のアプローチは、潜在変数としての意味を明示的にモデル化し、共同確率モデル内でのアモチュライズ版を導入する。\n",
      "この方法により、埋め込み空間での不確実性の推定が単一のフォワードパスで行えるため、既存のマルチパス手法に比べて計算負荷が大幅に軽減される。\n",
      "\",\n",
      "    \"Results\": \"複数の質問応答データセットおよび最前線のLLMsにおける実験により、提案された埋め込みベースの方法が従来のアプローチよりもより正確でニュアンスのある不確実性の定量化を提供することが示された。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"意味的埋め込みを活用した不確実性推定法\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: $\\textbf{EMOS}$: $\\textbf{E}$mbodiment-aware Heterogeneous $\\textbf{M}$ulti-robot $\\textbf{O}$perating $\\textbf{S}$ystem with LLM Agents\n",
      "published: 2024-10-30 03:20:01+00:00\n",
      "abstruct: Heterogeneous multi-robot systems (HMRS) have emerged as a powerful approach\n",
      "for tackling complex tasks that single robots cannot manage alone. Current\n",
      "large-language-model-based multi-agent systems (LLM-based MAS) have shown\n",
      "success in areas like software development and operating systems, but applying\n",
      "these systems to robot control presents unique challenges. In particular, the\n",
      "capabilities of each agent in a multi-robot system are inherently tied to the\n",
      "physical composition of the robots, rather than predefined roles. To address\n",
      "this issue, we introduce a novel multi-agent framework designed to enable\n",
      "effective collaboration among heterogeneous robots with varying embodiments and\n",
      "capabilities, along with a new benchmark named Habitat-MAS. One of our key\n",
      "designs is $\\textit{Robot Resume}$: Instead of adopting human-designed role\n",
      "play, we propose a self-prompted approach, where agents comprehend robot URDF\n",
      "files and call robot kinematics tools to generate descriptions of their physics\n",
      "capabilities to guide their behavior in task planning and action execution. The\n",
      "Habitat-MAS benchmark is designed to assess how a multi-agent framework handles\n",
      "tasks that require embodiment-aware reasoning, which includes 1) manipulation,\n",
      "2) perception, 3) navigation, and 4) comprehensive multi-floor object\n",
      "rearrangement. The experimental results indicate that the robot's resume and\n",
      "the hierarchical design of our multi-agent system are essential for the\n",
      "effective operation of the heterogeneous multi-robot system within this\n",
      "intricate problem context.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22662v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"異種多ロボットシステム（HMRS）は、単一のロボットが独力で管理できない複雑なタスクに対処するための強力なアプローチとして登場しています。\n",
      "現在の大規模言語モデルに基づくマルチエージェントシステム（LLMベースのMAS）は、ソフトウェア開発やオペレーティングシステムなどの分野で成功を収めていますが、これらのシステムをロボット制御に適用することには独自の課題があります。\n",
      "特に、マルチロボットシステム内の各エージェントの能力は、あらかじめ定義された役割ではなく、ロボットの物理的構成に固有のものです。\n",
      "\",\n",
      "    \"Novelty\": \"この問題に対処するために、異なる形態と能力を持つロボット間の効果的な協力を可能にする新しいマルチエージェントフレームワークと、Habitat-MASという新しいベンチマークを導入します。\n",
      "重要な設計の一つは「ロボット履歴書」であり、人間が設計した役割を採用する代わりに、エージェントがロボットのURDFファイルを理解し、ロボットの運動学ツールを呼び出して物理的能力の説明を生成し、タスク計画と行動実行を導く自己促進アプローチを提案しています。\n",
      "\",\n",
      "    \"Methodology\": \"Habitat-MASベンチマークは、身体に基づいた推論を必要とするタスクを処理するマルチエージェントフレームワークを評価するために設計されています。\n",
      "この評価には、1) 操作、2) 知覚、3) ナビゲーション、4) 複合的な多階層オブジェクト再配置が含まれます。\n",
      "\",\n",
      "    \"Results\": \"実験結果は、ロボットの履歴書とマルチエージェントシステムの階層的設計が、複雑な問題コンテキスト内で異種多ロボットシステムの効果的な運用に不可欠であることを示しています。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"ロボット履歴書\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: Linguistics Theory Meets LLM: Code-Switched Text Generation via Equivalence Constrained Large Language Models\n",
      "published: 2024-10-30 03:03:32+00:00\n",
      "abstruct: Code-switching, the phenomenon of alternating between two or more languages\n",
      "in a single conversation, presents unique challenges for Natural Language\n",
      "Processing (NLP). Most existing research focuses on either syntactic\n",
      "constraints or neural generation, with few efforts to integrate linguistic\n",
      "theory with large language models (LLMs) for generating natural code-switched\n",
      "text. In this paper, we introduce EZSwitch, a novel framework that combines\n",
      "Equivalence Constraint Theory (ECT) with LLMs to produce linguistically valid\n",
      "and fluent code-switched text. We evaluate our method using both human\n",
      "judgments and automatic metrics, demonstrating a significant improvement in the\n",
      "quality of generated code-switching sentences compared to baseline LLMs. To\n",
      "address the lack of suitable evaluation metrics, we conduct a comprehensive\n",
      "correlation study of various automatic metrics against human scores, revealing\n",
      "that current metrics often fail to capture the nuanced fluency of code-switched\n",
      "text. Additionally, we create CSPref, a human preference dataset based on human\n",
      "ratings and analyze model performance across ``hard`` and ``easy`` examples.\n",
      "Our findings indicate that incorporating linguistic constraints into LLMs leads\n",
      "to more robust and human-aligned generation, paving the way for scalable\n",
      "code-switching text generation across diverse language pairs.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22660v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"コードスイッチングとは、単一の会話の中で2つ以上の言語を交互に使用する現象であり、自然言語処理（NLP）において独特の課題を呈します。\n",
      "既存の研究の多くは、構文的制約またはニューラル生成に焦点を当てており、言語理論と大規模言語モデル（LLM）を統合して自然なコードスイッチテキストを生成する試みは少ないです。\n",
      "\",\n",
      "    \"Novelty\": \"本論文では、等価制約理論（ECT）とLLMを組み合わせる新しいフレームワークEZSwitchを提案し、言語的に妥当で流暢なコードスイッチテキストを生成します。\n",
      "\",\n",
      "    \"Methodology\": \"私たちは、人間の評価および自動メトリクスを使用してこの手法を評価し、基準となるLLMと比較して生成されたコードスイッチ文の品質が大幅に向上したことを示します。\n",
      "また、評価メトリクスの不足を解決するために、さまざまな自動メトリクスと人間のスコアとの相関研究を実施し、現在のメトリクスがコードスイッチテキストの微妙な流暢さを捉えられないことが明らかになりました。\n",
      "\",\n",
      "    \"Results\": \"さらに、私たちは人間の評価に基づいたCSPrefという人間の好みデータセットを作成し、「難しい」と「簡単な」例に対するモデルのパフォーマンスを分析しました。\n",
      "私たちの調査結果は、言語的制約をLLMに組み込むことで、より堅牢で人間に合った生成が可能になり、多様な言語ペア間でのスケーラブルなコードスイッチテキスト生成への道を開くことを示しています。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"EZSwitch\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: Automatic programming via large language models with population self-evolution for dynamic job shop scheduling problem\n",
      "published: 2024-10-30 02:54:31+00:00\n",
      "abstruct: Heuristic dispatching rules (HDRs) are widely regarded as effective methods\n",
      "for solving dynamic job shop scheduling problems (DJSSP) in real-world\n",
      "production environments. However, their performance is highly\n",
      "scenario-dependent, often requiring expert customization. To address this,\n",
      "genetic programming (GP) and gene expression programming (GEP) have been\n",
      "extensively used for automatic algorithm design. Nevertheless, these approaches\n",
      "often face challenges due to high randomness in the search process and limited\n",
      "generalization ability, hindering the application of trained dispatching rules\n",
      "to new scenarios or dynamic environments. Recently, the integration of large\n",
      "language models (LLMs) with evolutionary algorithms has opened new avenues for\n",
      "prompt engineering and automatic algorithm design. To enhance the capabilities\n",
      "of LLMs in automatic HDRs design, this paper proposes a novel population\n",
      "self-evolutionary (SeEvo) method, a general search framework inspired by the\n",
      "self-reflective design strategies of human experts. The SeEvo method\n",
      "accelerates the search process and enhances exploration capabilities.\n",
      "Experimental results show that the proposed SeEvo method outperforms GP, GEP,\n",
      "end-to-end deep reinforcement learning methods, and more than 10 common HDRs\n",
      "from the literature, particularly in unseen and dynamic scenarios.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22657v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"本研究は、動的ジョブショップスケジューリング問題（DJSSP）を解決するための新しいアプローチを提案しています。\n",
      "従来のヒューリスティックディスパッチングルール（HDR）は効果的ですが、性能がシナリオに依存し、専門家によるカスタマイズが必要です。\n",
      "この問題に対処するために、遺伝的プログラミング（GP）や遺伝子発現プログラミング（GEP）が自動アルゴリズム設計に広く使用されていますが、これらの手法は探索プロセスの高いランダム性と一般化能力の制限という課題に直面しています。\n",
      "\",\n",
      "    \"Novelty\": \"本論文では、大規模言語モデル（LLM）と進化アルゴリズムの統合によって、HDRの自動設計能力を向上させる新しい手法である「自己進化的方法（SeEvo）」を提案します。\n",
      "この手法は、人間の専門家の自己反省的な設計戦略に触発されています。\n",
      "\",\n",
      "    \"Methodology\": \"SeEvo法は、検索プロセスを加速し、探索能力を向上させる一般的な検索フレームワークです。\n",
      "実験において、SeEvo法はGP、GEP、エンドツーエンドの深層強化学習手法、文献からの10以上の一般的なHDRを特に未見の動的シナリオにおいて上回りました。\n",
      "\",\n",
      "    \"Results\": \"実験結果は、提案されたSeEvo法が他の手法に対して優れたパフォーマンスを示し、特に新しいシナリオや動的環境において効果的であることを示しました。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"自己進化的方法（SeEvo）\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: PV-VTT: A Privacy-Centric Dataset for Mission-Specific Anomaly Detection and Natural Language Interpretation\n",
      "published: 2024-10-30 01:02:20+00:00\n",
      "abstruct: Video crime detection is a significant application of computer vision and\n",
      "artificial intelligence. However, existing datasets primarily focus on\n",
      "detecting severe crimes by analyzing entire video clips, often neglecting the\n",
      "precursor activities (i.e., privacy violations) that could potentially prevent\n",
      "these crimes. To address this limitation, we present PV-VTT (Privacy Violation\n",
      "Video To Text), a unique multimodal dataset aimed at identifying privacy\n",
      "violations. PV-VTT provides detailed annotations for both video and text in\n",
      "scenarios. To ensure the privacy of individuals in the videos, we only provide\n",
      "video feature vectors, avoiding the release of any raw video data. This\n",
      "privacy-focused approach allows researchers to use the dataset while protecting\n",
      "participant confidentiality. Recognizing that privacy violations are often\n",
      "ambiguous and context-dependent, we propose a Graph Neural Network (GNN)-based\n",
      "video description model. Our model generates a GNN-based prompt with image for\n",
      "Large Language Model (LLM), which deliver cost-effective and high-quality video\n",
      "descriptions. By leveraging a single video frame along with relevant text, our\n",
      "method reduces the number of input tokens required, maintaining descriptive\n",
      "quality while optimizing LLM API-usage. Extensive experiments validate the\n",
      "effectiveness and interpretability of our approach in video description tasks\n",
      "and flexibility of our PV-VTT dataset.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22623v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"ビデオ犯罪検出はコンピュータビジョンと人工知能の重要な応用です。\n",
      "しかし、既存のデータセットは主に重大犯罪の検出に焦点を当てており、犯罪を防ぐ可能性のある前兆活動（プライバシー侵害など）を無視しています。\n",
      "これに対処するために、PV-VTT（プライバシー侵害ビデオからテキストへの変換）という独自のマルチモーダルデータセットを提案します。\n",
      "このデータセットは、シナリオにおけるビデオとテキストの詳細な注釈を提供します。\n",
      "個人のプライバシーを守るために、生のビデオデータを公開せず、ビデオの特徴ベクトルのみを提供します。\n",
      "\",\n",
      "    \"Novelty\": \"プライバシー侵害はしばしばあいまいで文脈依存であるため、GNN（グラフニューラルネットワーク）に基づくビデオ記述モデルを提案します。\n",
      "このモデルは、画像を伴ったGNNベースのプロンプトを生成し、コスト効率が良く高品質なビデオ記述を提供します。\n",
      "\",\n",
      "    \"Methodology\": \"単一のビデオフレームと関連するテキストを活用することで、必要な入力トークンの数を削減し、記述の質を維持しつつLLM（大規模言語モデル）APIの使用を最適化します。\n",
      "\",\n",
      "    \"Results\": \"広範な実験により、ビデオ記述タスクにおける我々のアプローチの効果と解釈性、及びPV-VTTデータセットの柔軟性が検証されました。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"GNN（グラフニューラルネットワーク）に基づくビデオ記述モデル\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: Are Large-Language Models Graph Algorithmic Reasoners?\n",
      "published: 2024-10-29 23:28:37+00:00\n",
      "abstruct: We seek to address a core challenge facing current Large Language Models\n",
      "(LLMs). LLMs have demonstrated superior performance in many tasks, yet continue\n",
      "to struggle with reasoning problems on explicit graphs that require multiple\n",
      "steps. To address this gap, we introduce a novel benchmark designed to evaluate\n",
      "LLM performance on classical algorithmic reasoning tasks on explicit graphs.\n",
      "Our benchmark encompasses five fundamental algorithms: Breadth-First Search\n",
      "(BFS) and Depth-First Search (DFS) for connectivity, Dijkstra's algorithm and\n",
      "Floyd-Warshall algorithm for all nodes shortest path, and Prim's Minimum\n",
      "Spanning Tree (MST-Prim's) algorithm. Through extensive experimentation, we\n",
      "assess the capabilities of state-of-the-art LLMs in executing these algorithms\n",
      "step-by-step and systematically evaluate their performance at each stage. Our\n",
      "findings highlight the persistent challenges LLMs face in this domain and\n",
      "underscore the necessity for advanced prompting techniques and algorithmic\n",
      "instruction to enhance their graph reasoning abilities. This work presents\n",
      "MAGMA, the first comprehensive benchmark focused on LLMs completing classical\n",
      "graph algorithms, and provides a critical step toward understanding and\n",
      "improving their structured problem-solving skills.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22597v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"本研究は、現在の大規模言語モデル（LLM）が直面している主要な課題に対処することを目指しています。\n",
      "LLMは多くのタスクで優れた性能を発揮していますが、複数のステップを必要とする明示的なグラフ上の推論問題に苦しんでいます。\n",
      "これを解決するために、古典的なアルゴリズム推論タスクに対するLLMの性能を評価するための新しいベンチマークを導入しました。\n",
      "\",\n",
      "    \"Novelty\": \"このベンチマークは、接続性のための幅優先探索（BFS）および深さ優先探索（DFS）、すべてのノードの最短経路のためのダイクストラ法およびフロイド・ワーシャル法、最小全域木のためのプリム法（MST-プリム）を含む五つの基本的なアルゴリズムを網羅しています。\n",
      "これにより、LLMが古典的なグラフアルゴリズムを段階的に実行する能力を評価することが可能になります。\n",
      "\",\n",
      "    \"Methodology\": \"広範な実験を通じて、最先端のLLMがこれらのアルゴリズムをどのように実行するかを段階的に評価し、その性能を体系的に評価しました。\n",
      "これにより、LLMがこの分野で直面する持続的な課題を明らかにし、グラフ推論能力を向上させるために進んだプロンプティング技術やアルゴリズム指導の必要性を強調しました。\n",
      "\",\n",
      "    \"Results\": \"この研究は、LLMが古典的なグラフアルゴリズムを完了することに焦点を当てた最初の包括的なベンチマークであるMAGMAを提示し、構造的な問題解決能力の理解と改善に向けた重要なステップを提供します。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"MAGMA\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: BENCHAGENTS: Automated Benchmark Creation with Agent Interaction\n",
      "published: 2024-10-29 22:56:18+00:00\n",
      "abstruct: Evaluations are limited by benchmark availability. As models evolve, there is\n",
      "a need to create benchmarks that can measure progress on new generative\n",
      "capabilities. However, creating new benchmarks through human annotations is\n",
      "slow and expensive, restricting comprehensive evaluations for any capability.\n",
      "We introduce BENCHAGENTS, a framework that methodically leverages large\n",
      "language models (LLMs) to automate benchmark creation for complex capabilities\n",
      "while inherently ensuring data and metric quality. BENCHAGENTS decomposes the\n",
      "benchmark creation process into planning, generation, data verification, and\n",
      "evaluation, each of which is executed by an LLM agent. These agents interact\n",
      "with each other and utilize human-in-the-loop feedback from benchmark\n",
      "developers to explicitly improve and flexibly control data diversity and\n",
      "quality. We use BENCHAGENTS to create benchmarks to evaluate capabilities\n",
      "related to planning and constraint satisfaction during text generation. We then\n",
      "use these benchmarks to study seven state-of-the-art models and extract new\n",
      "insights on common failure modes and model differences.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22584v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"この研究では、生成能力の進展を測定するための新しいベンチマークの作成が必要であるが、従来の人間による注釈作成は遅く高価であるため、包括的な評価が制限されていることを説明しています。\n",
      "そこで、BENCHAGENTSというフレームワークを提案し、大規模言語モデル（LLM）を活用してベンチマークの自動作成を行います。\n",
      "このフレームワークは、計画、生成、データ検証、および評価の各プロセスをLLMエージェントによって実行し、データの多様性と質を改善するために人間のフィードバックを利用します。\n",
      "\",\n",
      "    \"Novelty\": \"BENCHAGENTSの新規性は、ベンチマーク作成プロセスを計画、生成、データ検証、評価に分解し、それぞれをLLMエージェントによって実行する点にあります。\n",
      "これにより、データの質と多様性を確保しつつ、ベンチマークの作成を自動化することが可能になります。\n",
      "\",\n",
      "    \"Methodology\": \"このフレームワークでは、エージェント同士が相互に作用し、ベンチマーク開発者からのフィードバックを取り入れることで、データの多様性と質を明示的に改善し、柔軟に制御します。\n",
      "具体的には、テキスト生成における計画と制約満足に関連する能力を評価するためのベンチマークを作成し、それを用いて最先端の7つのモデルを研究します。\n",
      "\",\n",
      "    \"Results\": \"BENCHAGENTSを使用することで、生成能力に関する新しい洞察が得られ、モデル間の一般的な失敗モードや違いを明らかにすることができました。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"BENCHAGENTS\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: Auto-Intent: Automated Intent Discovery and Self-Exploration for Large Language Model Web Agents\n",
      "published: 2024-10-29 21:37:04+00:00\n",
      "abstruct: In this paper, we introduce Auto-Intent, a method to adapt a pre-trained\n",
      "large language model (LLM) as an agent for a target domain without direct\n",
      "fine-tuning, where we empirically focus on web navigation tasks. Our approach\n",
      "first discovers the underlying intents from target domain demonstrations\n",
      "unsupervisedly, in a highly compact form (up to three words). With the\n",
      "extracted intents, we train our intent predictor to predict the next intent\n",
      "given the agent's past observations and actions. In particular, we propose a\n",
      "self-exploration approach where top-k probable intent predictions are provided\n",
      "as a hint to the pre-trained LLM agent, which leads to enhanced decision-making\n",
      "capabilities. Auto-Intent substantially improves the performance of GPT-{3.5,\n",
      "4} and Llama-3.1-{70B, 405B} agents on the large-scale real-website navigation\n",
      "benchmarks from Mind2Web and online navigation tasks from WebArena with its\n",
      "cross-benchmark generalization from Mind2Web.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22552v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"本論文では、Auto-Intentという手法を紹介します。\n",
      "この手法は、事前に訓練された大規模言語モデル（LLM）を、直接的なファインチューニングなしで特定のドメインに適応させることを目指しています。\n",
      "主にウェブナビゲーションタスクに焦点を当てています。\n",
      "\",\n",
      "    \"Novelty\": \"Auto-Intentの新しさは、ターゲットドメインのデモンストレーションから意図を無監督で発見し、意図を非常にコンパクトな形（最大3語）で表現できる点です。\n",
      "また、自己探索アプローチを提案し、過去の観察や行動に基づいて次の意図を予測します。\n",
      "\",\n",
      "    \"Methodology\": \"Auto-Intentでは、抽出した意図を用いて意図予測器を訓練し、エージェントの過去の観察と行動に基づいて次の意図を予測します。\n",
      "特に、最も可能性の高いk個の意図予測を事前訓練されたLLMエージェントへのヒントとして提供する自己探索アプローチを提案します。\n",
      "\",\n",
      "    \"Results\": \"Auto-Intentは、Mind2Webからの大規模なリアルウェブナビゲーションベンチマークやWebArenaからのオンラインナビゲーションタスクにおいて、GPT-{3.5, 4}およびLlama-3.1-{70B, 405B}エージェントのパフォーマンスを大幅に向上させました。\n",
      "特に、Mind2Webからのクロスベンチマーク一般化が見られました。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"Auto-Intent\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: Efficient Learned Query Execution over Text and Tables [Technical Report]\n",
      "published: 2024-10-29 20:29:18+00:00\n",
      "abstruct: In this paper, we present ELEET, a novel execution engine that allows one to\n",
      "seamlessly query and process text as a first-class citizen along with tables.\n",
      "To enable such a seamless integration of text and tables, ELEET leverages\n",
      "learned multi-modal operators (MMOps) such as joins and unions that seamlessly\n",
      "combine structured with unstructured textual data. While large language models\n",
      "(LLM) such as GPT-4 are interesting candidates to enable such learned\n",
      "multimodal operations, we deliberately do not follow this trend to enable\n",
      "MMOps, since it would result in high overhead at query runtime. Instead, to\n",
      "enable MMOps, ELEET comes with a more efficient small language model (SLM) that\n",
      "is targeted to extract structured data from text. Thanks to our novel\n",
      "architecture and pre-training procedure, the ELEET-model enables high-accuracy\n",
      "extraction with low overheads. In our evaluation, we compare query execution\n",
      "based on ELEET to baselines leveraging LLMs such as GPT-4 and show that ELEET\n",
      "can speed up multi-modal queries over tables and text by up to 575x without\n",
      "sacrificing accuracy.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22522v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"この論文では、ELEETという新しい実行エンジンを紹介します。\n",
      "このエンジンは、テキストを第一級の市民として扱い、テーブルとシームレスに照会および処理できる機能を提供します。\n",
      "\",\n",
      "    \"Novelty\": \"ELEETは、構造化データと非構造化テキストデータを組み合わせるために、学習されたマルチモーダルオペレーター（MMOps）を利用します。\n",
      "特に、ELEETは大規模言語モデル（LLM）に依存するのではなく、効率的な小型言語モデル（SLM）を使用して、テキストから構造化データを抽出します。\n",
      "\",\n",
      "    \"Methodology\": \"ELEETのアーキテクチャと事前学習手法により、高精度な抽出が低オーバーヘッドで実現されます。\n",
      "ELEETのクエリ実行をLLMに基づくベースラインと比較し、性能を評価します。\n",
      "\",\n",
      "    \"Results\": \"評価の結果、ELEETはテーブルとテキストに対するマルチモーダルクエリを最大575倍のスピードで実行でき、精度を犠牲にすることなく効率を向上させることが示されました。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"ELEET\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: Attention Speaks Volumes: Localizing and Mitigating Bias in Language Models\n",
      "published: 2024-10-29 20:15:56+00:00\n",
      "abstruct: We explore the internal mechanisms of how bias emerges in large language\n",
      "models (LLMs) when provided with ambiguous comparative prompts: inputs that\n",
      "compare or enforce choosing between two or more entities without providing\n",
      "clear context for preference. Most approaches for bias mitigation focus on\n",
      "either post-hoc analysis or data augmentation. However, these are transient\n",
      "solutions, without addressing the root cause: the model itself. Numerous prior\n",
      "works show the influence of the attention module towards steering generations.\n",
      "We believe that analyzing attention is also crucial for understanding bias, as\n",
      "it provides insight into how the LLM distributes its focus across different\n",
      "entities and how this contributes to biased decisions. To this end, we first\n",
      "introduce a metric to quantify the LLM's preference for one entity over\n",
      "another. We then propose $\\texttt{ATLAS}$ (Attention-based Targeted Layer\n",
      "Analysis and Scaling), a technique to localize bias to specific layers of the\n",
      "LLM by analyzing attention scores and then reduce bias by scaling attention in\n",
      "these biased layers. To evaluate our method, we conduct experiments across 3\n",
      "datasets (BBQ, Crows-Pairs, and WinoGender) using $\\texttt{GPT-2 XL}$ (1.5B),\n",
      "$\\texttt{GPT-J}$ (6B), $\\texttt{LLaMA-2}$ (7B) and $\\texttt{LLaMA-3}$ (8B). Our\n",
      "experiments demonstrate that bias is concentrated in the later layers,\n",
      "typically around the last third. We also show how $\\texttt{ATLAS}$ effectively\n",
      "mitigates bias through targeted interventions without compromising downstream\n",
      "performance and an average increase of only 0.82% in perplexity when the\n",
      "intervention is applied. We see an average improvement of 0.28 points in the\n",
      "bias score across all the datasets.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22517v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"本研究では、大規模言語モデル（LLMs）におけるバイアスの発生メカニズムを探求します。\n",
      "特に、明確な文脈を提供せずに二つ以上のエンティティを比較または選択させるあいまいな比較プロンプトが与えられた場合のバイアスに焦点を当てています。\n",
      "従来のバイアス軽減手法は、後処理分析やデータ拡張に依存しており、根本的な問題であるモデル自体に対処していません。\n",
      "\",\n",
      "    \"Novelty\": \"本研究では、注意メカニズムを分析することがバイアス理解において重要であるとし、LLMが異なるエンティティにどのように焦点を合わせるかを洞察することを提案します。\n",
      "特に、エンティティ間の優先度を定量化するための新しい指標を導入し、バイアスを特定の層に局所化する手法であるATLAS（Attention-based Targeted Layer Analysis and Scaling）を提案します。\n",
      "\",\n",
      "    \"Methodology\": \"ATLASは、注意スコアを分析してバイアスのある層を特定し、その層の注意をスケーリングすることでバイアスを軽減します。\n",
      "評価のために、BBQ、Crows-Pairs、WinoGenderの3つのデータセットを使用し、GPT-2 XL（1.5B）、GPT-J（6B）、LLaMA-2（7B）、LLaMA-3（8B）で実験を行いました。\n",
      "\",\n",
      "    \"Results\": \"実験の結果、バイアスは通常、最後の三分の一の層に集中していることが分かりました。\n",
      "また、ATLASは、下流のパフォーマンスを損なうことなく、バイアスを効果的に軽減することを示しました。\n",
      "介入を適用した際の困惑度は平均でわずか0.82%増加し、すべてのデータセットでバイアススコアが平均0.28ポイント改善されました。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"ATLAS（Attention-based Targeted Layer Analysis and Scaling）\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: VL-Cache: Sparsity and Modality-Aware KV Cache Compression for Vision-Language Model Inference Acceleration\n",
      "published: 2024-10-29 20:04:34+00:00\n",
      "abstruct: Vision-Language Models (VLMs) have demonstrated impressive performance across\n",
      "a versatile set of tasks. A key challenge in accelerating VLMs is storing and\n",
      "accessing the large Key-Value (KV) cache that encodes long visual contexts,\n",
      "such as images or videos. While existing KV cache compression methods are\n",
      "effective for Large Language Models (LLMs), directly migrating them to VLMs\n",
      "yields suboptimal accuracy and speedup. To bridge the gap, we propose VL-Cache,\n",
      "a novel KV cache compression recipe tailored for accelerating VLM inference. In\n",
      "this paper, we first investigate the unique sparsity pattern of VLM attention\n",
      "by distinguishing visual and text tokens in prefill and decoding phases. Based\n",
      "on these observations, we introduce a layer-adaptive sparsity-aware cache\n",
      "budget allocation method that effectively distributes the limited cache budget\n",
      "across different layers, further reducing KV cache size without compromising\n",
      "accuracy. Additionally, we develop a modality-aware token scoring policy to\n",
      "better evaluate the token importance. Empirical results on multiple benchmark\n",
      "datasets demonstrate that retaining only 10% of KV cache achieves accuracy\n",
      "comparable to that with full cache. In a speed benchmark, our method\n",
      "accelerates end-to-end latency of generating 100 tokens by up to 2.33x and\n",
      "speeds up decoding by up to 7.08x, while reducing the memory footprint of KV\n",
      "cache in GPU by 90%.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.23317v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"Vision-Language Models (VLMs)は、さまざまなタスクで優れたパフォーマンスを示していますが、大量のキー-バリュー(KV)キャッシュの保存とアクセスが課題となっています。\n",
      "既存のKVキャッシュ圧縮手法は大規模言語モデル(LLMs)には効果的ですが、VLMにそのまま適用すると精度や速度で劣ります。\n",
      "\",\n",
      "    \"Novelty\": \"本研究では、VLM推論を加速するために新しいKVキャッシュ圧縮手法であるVL-Cacheを提案します。\n",
      "これは、VLMの注意機構の特有のスパースパターンを調査し、視覚トークンとテキストトークンを区別することに基づいています。\n",
      "\",\n",
      "    \"Methodology\": \"提案手法では、レイヤー適応型のスパース意識キャッシュ予算配分手法を導入し、異なるレイヤー間で限られたキャッシュ予算を効果的に配分します。\n",
      "また、トークンの重要性を評価するためのモダリティ意識トークンスコアリングポリシーも開発しています。\n",
      "\",\n",
      "    \"Results\": \"実験結果は、KVキャッシュの10%を保持することで、フルキャッシュと同等の精度を達成できることを示しています。\n",
      "また、100トークン生成のエンドツーエンドのレイテンシを最大2.33倍、デコーディング速度を最大7.08倍に加速し、GPUのKVキャッシュのメモリフットプリントを90%削減しました。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"VL-Cache\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: Anticipating Future with Large Language Model for Simultaneous Machine Translation\n",
      "published: 2024-10-29 19:42:30+00:00\n",
      "abstruct: Simultaneous machine translation (SMT) takes streaming input utterances and\n",
      "incrementally produces target text. Existing SMT methods only use the partial\n",
      "utterance that has already arrived at the input and the generated hypothesis.\n",
      "Motivated by human interpreters' technique to forecast future words before\n",
      "hearing them, we propose $\\textbf{T}$ranslation by $\\textbf{A}$nticipating\n",
      "$\\textbf{F}$uture (TAF), a method to improve translation quality while\n",
      "retraining low latency. Its core idea is to use a large language model (LLM) to\n",
      "predict future source words and opportunistically translate without introducing\n",
      "too much risk. We evaluate our TAF and multiple baselines of SMT on four\n",
      "language directions. Experiments show that TAF achieves the best translation\n",
      "quality-latency trade-off and outperforms the baselines by up to 5 BLEU points\n",
      "at the same latency (three words).\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22499v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"同時機械翻訳（SMT）は、ストリーミング入力の発話を受け取り、ターゲットテキストを段階的に生成します。\n",
      "従来のSMT手法は、すでに入力された部分発話と生成された仮説のみを使用します。\n",
      "\",\n",
      "    \"Novelty\": \"人間の通訳者が未来の単語を聞く前に予測する技術に触発され、翻訳の質を改善しつつ低遅延を維持する新しい手法「TAF（未来の予測による翻訳）」を提案します。\n",
      "\",\n",
      "    \"Methodology\": \"TAFの核心的なアイデアは、大規模言語モデル（LLM）を使用して未来のソース単語を予測し、リスクを過度に導入することなく機会を捉えて翻訳することです。\n",
      "\",\n",
      "    \"Results\": \"TAFと複数のSMTベースラインを四つの言語方向で評価した結果、TAFは翻訳の質と遅延のトレードオフにおいて最良の成果を上げ、同じ遅延（3単語）でベースラインを最大5 BLEUポイント上回ることが示されました。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"TAF（未来の予測による翻訳）\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: Scaling LLM Inference with Optimized Sample Compute Allocation\n",
      "published: 2024-10-29 19:17:55+00:00\n",
      "abstruct: Sampling is a basic operation in many inference-time algorithms of large\n",
      "language models (LLMs). To scale up inference efficiently with a limited\n",
      "compute, it is crucial to find an optimal allocation for sample compute\n",
      "budgets: Which sampling configurations (model, temperature, language, etc.) do\n",
      "we use? How many samples do we generate in each configuration? We formulate\n",
      "these choices as a learning problem and propose OSCA, an algorithm that\n",
      "Optimizes Sample Compute Allocation by finding an optimal mix of different\n",
      "inference configurations. Our experiments show that with our learned mixed\n",
      "allocation, we can achieve accuracy better than the best single configuration\n",
      "with 128x less compute on code generation and 25x less compute on 4 reasoning\n",
      "tasks. OSCA is also shown to be effective in agentic workflows beyond\n",
      "single-turn tasks, achieving a better accuracy on SWE-Bench with 3x less\n",
      "compute than the default configuration. Our code and generations are released\n",
      "at https://github.com/LeiLiLab/OSCA.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22480v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"サンプリングは、大規模言語モデル（LLMs）の多くの推論時アルゴリズムにおいて基本的な操作です。\n",
      "限られた計算資源で効率的に推論をスケールアップするためには、サンプル計算の予算を最適に配分することが重要です。\n",
      "これには、使用するサンプリング設定（モデル、温度、言語など）や、各設定で生成するサンプル数を決定する必要があります。\n",
      "\",\n",
      "    \"Novelty\": \"本研究では、これらの選択肢を学習問題として定式化し、異なる推論設定の最適な組み合わせを見つけるOSCAというアルゴリズムを提案します。\n",
      "\",\n",
      "    \"Methodology\": \"OSCAは、学習した混合配分を用いて、128倍少ない計算資源でコード生成タスクの精度を向上させ、4つの推論タスクでは25倍少ない計算資源で良好な結果を達成します。\n",
      "\",\n",
      "    \"Results\": \"OSCAは、単一のターンのタスクを超えたエージェントワークフローにおいても効果的であり、デフォルト設定よりも3倍少ない計算資源でSWE-Benchの精度を向上させることが示されています。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"OSCA\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: Advancing Agentic Systems: Dynamic Task Decomposition, Tool Integration and Evaluation using Novel Metrics and Dataset\n",
      "published: 2024-10-29 18:45:13+00:00\n",
      "abstruct: Advancements in Large Language Models (LLMs) are revolutionizing the\n",
      "development of autonomous agentic systems by enabling dynamic, context-aware\n",
      "task decomposition and automated tool selection. These sophisticated systems\n",
      "possess significant automation potential across various industries, managing\n",
      "complex tasks, interacting with external systems to enhance knowledge, and\n",
      "executing actions independently. This paper presents three primary\n",
      "contributions to advance this field:\n",
      "  - Advanced Agentic Framework: A system that handles multi-hop queries,\n",
      "generates and executes task graphs, selects appropriate tools, and adapts to\n",
      "real-time changes.\n",
      "  - Novel Evaluation Metrics: Introduction of Node F1 Score, Structural\n",
      "Similarity Index (SSI), and Tool F1 Score to comprehensively assess agentic\n",
      "systems.\n",
      "  - Specialized Dataset: Development of an AsyncHow-based dataset for analyzing\n",
      "agent behavior across different task complexities.\n",
      "  Our findings reveal that asynchronous and dynamic task graph decomposition\n",
      "significantly enhances system responsiveness and scalability, particularly for\n",
      "complex, multi-step tasks. Detailed analysis shows that structural and\n",
      "node-level metrics are crucial for sequential tasks, while tool-related metrics\n",
      "are more important for parallel tasks. Specifically, the Structural Similarity\n",
      "Index (SSI) is the most significant predictor of performance in sequential\n",
      "tasks, and the Tool F1 Score is essential for parallel tasks. These insights\n",
      "highlight the need for balanced evaluation methods that capture both structural\n",
      "and operational dimensions of agentic systems. Additionally, our evaluation\n",
      "framework, validated through empirical analysis and statistical testing,\n",
      "provides valuable insights for improving the adaptability and reliability of\n",
      "agentic systems in dynamic environments.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22457v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"この研究は、大規模言語モデル（LLMs）が自律エージェントシステムの開発に革命をもたらし、動的で文脈に応じたタスク分解や自動ツール選択を可能にすることを示しています。\n",
      "これらの高度なシステムは、さまざまな業界での自動化の可能性を持ち、複雑なタスクを管理し、外部システムと相互作用して知識を強化し、独立してアクションを実行できます。\n",
      "\",\n",
      "    \"Novelty\": \"本論文は、複数のホップクエリを処理し、タスクグラフを生成および実行し、適切なツールを選択し、リアルタイムの変化に適応する高度なエージェントフレームワークを提案しています。\n",
      "また、エージェントシステムを包括的に評価するための新しい評価指標（Node F1 Score、Structural Similarity Index（SSI）、Tool F1 Score）を紹介しています。\n",
      "さらに、さまざまなタスクの複雑性におけるエージェントの行動を分析するためのAsyncHowに基づいたデータセットを開発しました。\n",
      "\",\n",
      "    \"Methodology\": \"非同期かつ動的なタスクグラフ分解が、特に複雑なマルチステップタスクにおいてシステムの応答性とスケーラビリティを大幅に向上させることを明らかにしました。\n",
      "構造的およびノードレベルの指標は逐次タスクにとって重要であり、ツール関連の指標は並列タスクにとってより重要であることが詳細な分析によって示されています。\n",
      "\",\n",
      "    \"Results\": \"特に、構造的類似性インデックス（SSI）は逐次タスクの性能の最も重要な予測因子であり、ツールF1スコアは並列タスクにとって不可欠であることが分かりました。\n",
      "これらの洞察は、エージェントシステムの構造的および操作的次元の両方を捉えるバランスの取れた評価方法の必要性を強調しています。\n",
      "また、経験的分析と統計的テストによって検証された評価フレームワークは、動的環境におけるエージェントシステムの適応性と信頼性を向上させるための貴重な洞察を提供します。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"高度なエージェントフレームワーク\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: Do Large Language Models Align with Core Mental Health Counseling Competencies?\n",
      "published: 2024-10-29 18:27:11+00:00\n",
      "abstruct: The rapid evolution of Large Language Models (LLMs) offers promising\n",
      "potential to alleviate the global scarcity of mental health professionals.\n",
      "However, LLMs' alignment with essential mental health counseling competencies\n",
      "remains understudied. We introduce CounselingBench, a novel NCMHCE-based\n",
      "benchmark evaluating LLMs across five key mental health counseling\n",
      "competencies. Testing 22 general-purpose and medical-finetuned LLMs, we find\n",
      "frontier models exceed minimum thresholds but fall short of expert-level\n",
      "performance, with significant variations: they excel in Intake, Assessment &\n",
      "Diagnosis yet struggle with Core Counseling Attributes and Professional\n",
      "Practice & Ethics. Medical LLMs surprisingly underperform generalist models\n",
      "accuracy-wise, while at the same time producing slightly higher-quality\n",
      "justifications but making more context-related errors. Our findings highlight\n",
      "the complexities of developing AI systems for mental health counseling,\n",
      "particularly for competencies requiring empathy and contextual understanding.\n",
      "We found that frontier LLMs perform at a level exceeding the minimal required\n",
      "level of aptitude for all key mental health counseling competencies, but fall\n",
      "short of expert-level performance, and that current medical LLMs do not\n",
      "significantly improve upon generalist models in mental health counseling\n",
      "competencies. This underscores the critical need for specialized, mental health\n",
      "counseling-specific fine-tuned LLMs that rigorously aligns with core\n",
      "competencies combined with appropriate human supervision before any responsible\n",
      "real-world deployment can be considered.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22446v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"この研究は、急速に進化する大規模言語モデル（LLM）が、メンタルヘルス専門家の不足を緩和する可能性を持っていることを示していますが、LLMがメンタルヘルスカウンセリングの重要な能力にどの程度適合しているかはあまり研究されていません。\n",
      "\",\n",
      "    \"Novelty\": \"CounselingBenchという新しいNCMHCEベースのベンチマークを導入し、5つの主要なメンタルヘルスカウンセリング能力を評価します。\n",
      "\",\n",
      "    \"Methodology\": \"22の一般的な用途および医療向けに微調整されたLLMをテストし、それぞれの能力におけるパフォーマンスを評価しました。\n",
      "\",\n",
      "    \"Results\": \"最先端のモデルは最低限の閾値を超えていますが、専門家レベルのパフォーマンスには達していません。\n",
      "特に、インテーク、評価、診断では優れている一方、コアカウンセリング属性や専門的な実践と倫理においては苦戦しています。\n",
      "また、医療LLMは一般的なモデルに比べて正確性の点で驚くほど低い結果を示しましたが、わずかに高品質な説明を生成しつつも、文脈関連のエラーが多く見られました。\n",
      "これにより、AIシステムをメンタルヘルスカウンセリングに適用する際の複雑さが浮き彫りになりました。\n",
      "現在の医療LLMは、メンタルヘルスカウンセリング能力において一般的なモデルを大きく改善することはなく、専門的なメンタルヘルスカウンセリングに特化した微調整されたLLMの必要性が強調されます。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"CounselingBench\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: AAAR-1.0: Assessing AI's Potential to Assist Research\n",
      "published: 2024-10-29 17:58:29+00:00\n",
      "abstruct: Numerous studies have assessed the proficiency of AI systems, particularly\n",
      "large language models (LLMs), in facilitating everyday tasks such as email\n",
      "writing, question answering, and creative content generation. However,\n",
      "researchers face unique challenges and opportunities in leveraging LLMs for\n",
      "their own work, such as brainstorming research ideas, designing experiments,\n",
      "and writing or reviewing papers. In this study, we introduce AAAR-1.0, a\n",
      "benchmark dataset designed to evaluate LLM performance in three fundamental,\n",
      "expertise-intensive research tasks: (i) EquationInference, assessing the\n",
      "correctness of equations based on the contextual information in paper\n",
      "submissions; (ii) ExperimentDesign, designing experiments to validate research\n",
      "ideas and solutions; (iii) PaperWeakness, identifying weaknesses in paper\n",
      "submissions; and (iv) REVIEWCRITIQUE, identifying each segment in human reviews\n",
      "is deficient or not. AAAR-1.0 differs from prior benchmarks in two key ways:\n",
      "first, it is explicitly research-oriented, with tasks requiring deep domain\n",
      "expertise; second, it is researcher-oriented, mirroring the primary activities\n",
      "that researchers engage in on a daily basis. An evaluation of both open-source\n",
      "and proprietary LLMs reveals their potential as well as limitations in\n",
      "conducting sophisticated research tasks. We will keep iterating AAAR-1.0 to new\n",
      "versions.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22394v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"本研究では、AIシステム、特に大規模言語モデル（LLMs）の能力を評価するためのベンチマークデータセットAAAR-1.0を紹介します。\n",
      "このデータセットは、研究者の日常的な活動に役立つ3つの重要なタスクを評価します。\n",
      "\",\n",
      "    \"Novelty\": \"AAAR-1.0は、従来のベンチマークと異なり、深い専門知識を必要とする研究志向のタスクを明示的に含んでいます。\n",
      "また、研究者の活動を反映した設計になっています。\n",
      "\",\n",
      "    \"Methodology\": \"この研究では、EquationInference、ExperimentDesign、PaperWeakness、REVIEWCRITIQUEという4つのタスクを用いて、LLMのパフォーマンスを評価します。\n",
      "これにより、研究アイデアのブレインストーミング、実験の設計、論文のレビューなどの活動をサポートします。\n",
      "\",\n",
      "    \"Results\": \"オープンソースおよび商用のLLMの評価により、これらのモデルが高度な研究タスクを実施する際の可能性と限界が明らかになりました。\n",
      "今後、AAAR-1.0は新しいバージョンに向けて継続的に改良される予定です。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"AAAR-1.0\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: Online Detecting LLM-Generated Texts via Sequential Hypothesis Testing by Betting\n",
      "published: 2024-10-29 17:55:14+00:00\n",
      "abstruct: Developing algorithms to differentiate between machine-generated texts and\n",
      "human-written texts has garnered substantial attention in recent years.\n",
      "Existing methods in this direction typically concern an offline setting where a\n",
      "dataset containing a mix of real and machine-generated texts is given upfront,\n",
      "and the task is to determine whether each sample in the dataset is from a large\n",
      "language model (LLM) or a human. However, in many practical scenarios, sources\n",
      "such as news websites, social media accounts, or on other forums publish\n",
      "content in a streaming fashion. Therefore, in this online scenario, how to\n",
      "quickly and accurately determine whether the source is an LLM with strong\n",
      "statistical guarantees is crucial for these media or platforms to function\n",
      "effectively and prevent the spread of misinformation and other potential misuse\n",
      "of LLMs. To tackle the problem of online detection, we develop an algorithm\n",
      "based on the techniques of sequential hypothesis testing by betting that not\n",
      "only builds upon and complements existing offline detection techniques but also\n",
      "enjoys statistical guarantees, which include a controlled false positive rate\n",
      "and the expected time to correctly identify a source as an LLM. Experiments\n",
      "were conducted to demonstrate the effectiveness of our method.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22318v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"機械生成されたテキストと人間が書いたテキストを区別するアルゴリズムの開発は、近年大きな注目を集めています。\n",
      "従来の方法はオフライン設定に依存しており、実際のデータセットを用いて、各サンプルが大規模言語モデル（LLM）からのものであるか人間からのものであるかを判断します。\n",
      "しかし、ニュースサイトやSNSなどでは、コンテンツがストリーミング方式で公開されるため、オンラインシナリオで迅速かつ正確にLLMのソースを特定することが重要です。\n",
      "\",\n",
      "    \"Novelty\": \"本研究の新規性は、オンライン検出の問題に取り組むために、既存のオフライン検出技術を補完・強化するアルゴリズムを開発したことです。\n",
      "これは、強力な統計的保証を伴うものであり、誤検知率の制御とLLMとしてのソースを正しく識別するための期待時間を含みます。\n",
      "\",\n",
      "    \"Methodology\": \"提案するアルゴリズムは、逐次仮説検定の手法に基づいており、既存のオフライン検出技術に基づいています。\n",
      "このアルゴリズムは、ストリーミングデータを用いて、リアルタイムでのLLMの識別を行うことができます。\n",
      "\",\n",
      "    \"Results\": \"実験により、提案した手法の有効性が示されました。\n",
      "統計的保証を持ちながら、迅速かつ正確にLLMを識別することができることが確認されました。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"逐次仮説検定に基づくアルゴリズム\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: Understanding Synthetic Context Extension via Retrieval Heads\n",
      "published: 2024-10-29 17:55:00+00:00\n",
      "abstruct: Long-context LLMs are increasingly in demand for applications such as\n",
      "retrieval-augmented generation. To defray the cost of pretraining LLMs over\n",
      "long contexts, recent work takes an approach of synthetic context extension:\n",
      "fine-tuning LLMs with synthetically generated long-context data in a\n",
      "post-training stage. However, it remains unclear how and why this synthetic\n",
      "context extension imparts abilities for downstream long-context tasks. In this\n",
      "paper, we investigate fine-tuning on synthetic data for three long-context\n",
      "tasks that require retrieval and reasoning. We vary the realism of \"needle\"\n",
      "concepts to be retrieved and diversity of the surrounding \"haystack\" context,\n",
      "from using LLMs to construct synthetic documents to using templated relations\n",
      "and creating symbolic datasets. We find that models trained on synthetic data\n",
      "fall short of the real data, but surprisingly, the mismatch can be interpreted\n",
      "and even predicted in terms of a special set of attention heads that are\n",
      "responsible for retrieval over long context: retrieval heads (Wu et al., 2024).\n",
      "The retrieval heads learned on synthetic data are mostly subsets of the\n",
      "retrieval heads learned on real data, and there is a strong correlation between\n",
      "the recall of heads learned and the downstream performance of a model.\n",
      "Furthermore, with attention knockout and activation patching, we\n",
      "mechanistically show that retrieval heads are necessary and explain model\n",
      "performance, although they are not totally sufficient. Our results shed light\n",
      "on how to interpret synthetic data fine-tuning performance and how to approach\n",
      "creating better data for learning real-world capabilities over long contexts.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22316v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"長いコンテキストを持つ大規模言語モデル（LLMs）は、リトリーバル拡張生成などのアプリケーションでの需要が高まっています。\n",
      "この研究では、合成コンテキスト拡張というアプローチを用いて、LLMsを長いコンテキストデータで微調整する方法を探ります。\n",
      "これは、ポストトレーニング段階で合成データを使用して行われます。\n",
      "しかし、この合成コンテキスト拡張がどのように長いコンテキストタスクに対して能力を与えるのかは明らかではありません。\n",
      "\",\n",
      "    \"Novelty\": \"本研究の新規性は、リトリーバルと推論を必要とする三つの長いコンテキストタスクに対して、合成データでの微調整を行い、その効果を実証的に評価する点にあります。\n",
      "合成データのリアリズムとコンテキストの多様性を変化させて実験を行いました。\n",
      "\",\n",
      "    \"Methodology\": \"合成データでの微調整が実際のデータにどのように劣るかを調査します。\n",
      "また、リトリーバルヘッドという特別な注意ヘッドのセットを通じて、その不一致を解釈・予測できることを示します。\n",
      "注意ノックアウトと活性化パッチングを用いて、リトリーバルヘッドの重要性を機械的に示します。\n",
      "\",\n",
      "    \"Results\": \"合成データで訓練されたモデルは実データに劣りますが、取得されたヘッドのリコールとモデルのパフォーマンスには強い相関があります。\n",
      "この結果は、合成データでの微調整のパフォーマンスを解釈する方法や、実世界の能力を学ぶためのより良いデータの作成方法に光を当てます。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"合成コンテキスト拡張\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: Natural Language Inference Improves Compositionality in Vision-Language Models\n",
      "published: 2024-10-29 17:54:17+00:00\n",
      "abstruct: Compositional reasoning in Vision-Language Models (VLMs) remains challenging\n",
      "as these models often struggle to relate objects, attributes, and spatial\n",
      "relationships. Recent methods aim to address these limitations by relying on\n",
      "the semantics of the textual description, using Large Language Models (LLMs) to\n",
      "break them down into subsets of questions and answers. However, these methods\n",
      "primarily operate on the surface level, failing to incorporate deeper lexical\n",
      "understanding while introducing incorrect assumptions generated by the LLM. In\n",
      "response to these issues, we present Caption Expansion with Contradictions and\n",
      "Entailments (CECE), a principled approach that leverages Natural Language\n",
      "Inference (NLI) to generate entailments and contradictions from a given\n",
      "premise. CECE produces lexically diverse sentences while maintaining their core\n",
      "meaning. Through extensive experiments, we show that CECE enhances\n",
      "interpretability and reduces overreliance on biased or superficial features. By\n",
      "balancing CECE along the original premise, we achieve significant improvements\n",
      "over previous methods without requiring additional fine-tuning, producing\n",
      "state-of-the-art results on benchmarks that score agreement with human\n",
      "judgments for image-text alignment, and achieving an increase in performance on\n",
      "Winoground of +19.2% (group score) and +12.9% on EqBen (group score) over the\n",
      "best prior work (finetuned with targeted data).\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22315v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"視覚と言語モデル（VLM）における構成的推論は依然として難しい課題です。\n",
      "これらのモデルは、物体、属性、空間関係を関連付けるのに苦労しています。\n",
      "最近の手法は、大規模言語モデル（LLM）を使用してテキスト記述の意味を解析し、質問と回答のサブセットに分解することを目指していますが、主に表面的なレベルで動作し、深い語彙的理解を取り入れず、LLMによって生成された誤った仮定を導入しています。\n",
      "\",\n",
      "    \"Novelty\": \"この問題に対処するために、自然言語推論（NLI）を活用して与えられた前提から含意と矛盾を生成する「Caption Expansion with Contradictions and Entailments（CECE）」という原則に基づいたアプローチを提案します。\n",
      "CECEは、核心的な意味を維持しつつ、語彙的に多様な文を生成します。\n",
      "\",\n",
      "    \"Methodology\": \"広範な実験を通じて、CECEは解釈性を向上させ、偏ったまたは表面的な特徴への過度の依存を減少させることを示しています。\n",
      "CECEを元の前提に沿ってバランスを取ることで、追加のファインチューニングを必要とせずに前の手法に比べて著しい改善を達成しました。\n",
      "\",\n",
      "    \"Results\": \"画像とテキストの整合性に関する人間の評価と一致するベンチマークで最先端の結果を生成し、Winogroundで+19.2%（グループスコア）、EqBenで+12.9%（グループスコア）向上しました。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"Caption Expansion with Contradictions and Entailments (CECE)\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: GPT-4o reads the mind in the eyes\n",
      "published: 2024-10-29 17:53:10+00:00\n",
      "abstruct: Large Language Models (LLMs) are capable of reproducing human-like\n",
      "inferences, including inferences about emotions and mental states, from text.\n",
      "Whether this capability extends beyond text to other modalities remains\n",
      "unclear. Humans possess a sophisticated ability to read the mind in the eyes of\n",
      "other people. Here we tested whether this ability is also present in GPT-4o, a\n",
      "multimodal LLM. Using two versions of a widely used theory of mind test, the\n",
      "Reading the Mind in Eyes Test and the Multiracial Reading the Mind in the Eyes\n",
      "Test, we found that GPT-4o outperformed humans in interpreting mental states\n",
      "from upright faces but underperformed humans when faces were inverted. While\n",
      "humans in our sample showed no difference between White and Non-white faces,\n",
      "GPT-4o's accuracy was higher for White than for Non-white faces. GPT-4o's\n",
      "errors were not random but revealed a highly consistent, yet incorrect,\n",
      "processing of mental-state information across trials, with an\n",
      "orientation-dependent error structure that qualitatively differed from that of\n",
      "humans for inverted faces but not for upright faces. These findings highlight\n",
      "how advanced mental state inference abilities and human-like face processing\n",
      "signatures, such as inversion effects, coexist in GPT-4o alongside substantial\n",
      "differences in information processing compared to humans.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22309v2\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"大規模言語モデル（LLMs）は、テキストから感情や精神状態に関する推論を再現する能力を持っています。\n",
      "しかし、この能力がテキスト以外のモダリティにも及ぶかどうかは不明です。\n",
      "本研究では、GPT-4oというマルチモーダルLLMが他者の精神を読み取る能力を持つかどうかをテストしました。\n",
      "\",\n",
      "    \"Novelty\": \"本研究では、既存の理論を基にした2つのバージョンの「目の中の心を読むテスト」を使用し、GPT-4oが人間の精神状態を解釈する能力を評価しました。\n",
      "特に、顔の向きが結果に与える影響を調査しました。\n",
      "\",\n",
      "    \"Methodology\": \"被験者には、顔が正面を向いている場合と逆さまの場合の両方で、GPT-4oと人間の精神状態認識能力を比較しました。\n",
      "正面の顔に対する解釈ではGPT-4oが人間よりも優れた結果を示しましたが、逆さまの顔に対しては劣りました。\n",
      "\",\n",
      "    \"Results\": \"結果として、GPT-4oは正面の顔に対しては高い精度を示しましたが、逆さまの顔に対しては人間に劣りました。\n",
      "また、白人と非白人の顔に対する精度には差があり、GPT-4oは白人の顔に対して高い精度を示しました。\n",
      "GPT-4oのエラーはランダムではなく、一貫した不正確な情報処理を示しており、顔の向きによって異なるエラー構造が観察されました。\n",
      "これらの発見は、GPT-4oが高度な精神状態推論能力を持ちつつも、人間とは異なる情報処理の特徴を有していることを示しています。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"目の中の心を読むテスト\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: SVIP: Towards Verifiable Inference of Open-source Large Language Models\n",
      "published: 2024-10-29 17:52:45+00:00\n",
      "abstruct: Open-source Large Language Models (LLMs) have recently demonstrated\n",
      "remarkable capabilities in natural language understanding and generation,\n",
      "leading to widespread adoption across various domains. However, their\n",
      "increasing model sizes render local deployment impractical for individual\n",
      "users, pushing many to rely on computing service providers for inference\n",
      "through a blackbox API. This reliance introduces a new risk: a computing\n",
      "provider may stealthily substitute the requested LLM with a smaller, less\n",
      "capable model without consent from users, thereby delivering inferior outputs\n",
      "while benefiting from cost savings. In this paper, we formalize the problem of\n",
      "verifiable inference for LLMs. Existing verifiable computing solutions based on\n",
      "cryptographic or game-theoretic techniques are either computationally\n",
      "uneconomical or rest on strong assumptions. We introduce SVIP, a secret-based\n",
      "verifiable LLM inference protocol that leverages intermediate outputs from LLM\n",
      "as unique model identifiers. By training a proxy task on these outputs and\n",
      "requiring the computing provider to return both the generated text and the\n",
      "processed intermediate outputs, users can reliably verify whether the computing\n",
      "provider is acting honestly. In addition, the integration of a secret mechanism\n",
      "further enhances the security of our protocol. We thoroughly analyze our\n",
      "protocol under multiple strong and adaptive adversarial scenarios. Our\n",
      "extensive experiments demonstrate that SVIP is accurate, generalizable,\n",
      "computationally efficient, and resistant to various attacks. Notably, SVIP\n",
      "achieves false negative rates below 5% and false positive rates below 3%, while\n",
      "requiring less than 0.01 seconds per query for verification.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22307v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"オープンソースの大規模言語モデル（LLM）は、自然言語の理解と生成において顕著な能力を示し、さまざまな分野で広く採用されています。\n",
      "しかし、モデルのサイズが増加することで、個々のユーザーにとってローカルでのデプロイが実用的でなくなり、多くの人がブラックボックスAPIを通じて計算サービスプロバイダーに依存しています。\n",
      "この依存は、新たなリスクをもたらし、計算プロバイダーがユーザーの同意なしに要求されたLLMを小型で能力の低いモデルにすり替える可能性があります。\n",
      "本論文では、LLMに対する検証可能な推論の問題を正式に定義します。\n",
      "\",\n",
      "    \"Novelty\": \"既存の暗号技術やゲーム理論に基づく検証可能な計算ソリューションは、計算的に非経済的であったり、強い仮定に依存しています。\n",
      "本研究では、LLMの中間出力をユニークなモデル識別子として活用する秘密ベースの検証可能なLLM推論プロトコル（SVIP）を提案します。\n",
      "\",\n",
      "    \"Methodology\": \"このプロトコルでは、LLMから生成されたテキストと処理された中間出力の両方を計算プロバイダーに返すことを要求し、ユーザーが計算プロバイダーの誠実さを信頼できるようにします。\n",
      "さらに、秘密メカニズムの統合により、プロトコルのセキュリティが強化されます。\n",
      "\",\n",
      "    \"Results\": \"複数の強力で適応的な敵対的シナリオの下でプロトコルを徹底的に分析し、広範な実験を行いました。\n",
      "その結果、SVIPは正確で一般化可能、計算的に効率的であり、さまざまな攻撃に対して抵抗力があります。\n",
      "特に、SVIPは偽陰性率が5%未満、偽陽性率が3%未満を達成し、検証にかかる時間はクエリごとに0.01秒未満です。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"SVIP\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: Flow-DPO: Improving LLM Mathematical Reasoning through Online Multi-Agent Learning\n",
      "published: 2024-10-29 17:50:31+00:00\n",
      "abstruct: Mathematical reasoning is a crucial capability for Large Language Models\n",
      "(LLMs), yet generating detailed and accurate reasoning traces remains a\n",
      "significant challenge. This paper introduces a novel approach to produce\n",
      "high-quality reasoning traces for LLM fine-tuning using online learning\n",
      "\\textbf{Flows}. Our method employs an incremental output production Flow, where\n",
      "component LLMs collaboratively construct solutions through iterative\n",
      "communication. We train the Flow using online Direct Preference Optimization\n",
      "(DPO) learning with rollouts, generating DPO pairs for each training example\n",
      "and updating models in real-time. We directly compare the quality of reasoning\n",
      "traces generated by our method with those produced through direct model\n",
      "inference, demonstrating the effectiveness of our approach in improving LLM\n",
      "performance in mathematical reasoning tasks.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22304v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"大規模言語モデル（LLM）のための数学的推論は重要な能力ですが、詳細かつ正確な推論トレースを生成することは依然として大きな課題です。\n",
      "この論文では、オンライン学習フローを使用してLLMのファインチューニングのために高品質な推論トレースを生成する新しいアプローチを導入します。\n",
      "\",\n",
      "    \"Novelty\": \"提案されたアプローチは、コンポーネントLLMが反復的なコミュニケーションを通じて解決策を共同で構築する、逐次的な出力生成フローを採用している点が新しいです。\n",
      "\",\n",
      "    \"Methodology\": \"このフローは、オンラインの直接的な嗜好最適化（DPO）学習を用いて訓練され、各トレーニング例に対してDPOペアを生成し、リアルタイムでモデルを更新します。\n",
      "\",\n",
      "    \"Results\": \"提案手法によって生成された推論トレースの質を、直接的なモデル推論で生成されたものと比較し、数学的推論タスクにおけるLLMの性能向上に対する効果を実証しました。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"オンライン学習フロー\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: LLMs are Highly-Constrained Biophysical Sequence Optimizers\n",
      "published: 2024-10-29 17:45:57+00:00\n",
      "abstruct: Large language models (LLMs) have recently shown significant potential in\n",
      "various biological tasks such as protein engineering and molecule design. These\n",
      "tasks typically involve black-box discrete sequence optimization, where the\n",
      "challenge lies in generating sequences that are not only biologically feasible\n",
      "but also adhere to hard fine-grained constraints. However, LLMs often struggle\n",
      "with such constraints, especially in biological contexts where verifying\n",
      "candidate solutions is costly and time-consuming. In this study, we explore the\n",
      "possibility of employing LLMs as highly-constrained bilevel optimizers through\n",
      "a methodology we refer to as Language Model Optimization with Margin\n",
      "Expectation (LLOME). This approach combines both offline and online\n",
      "optimization, utilizing limited oracle evaluations to iteratively enhance the\n",
      "sequences generated by the LLM. We additionally propose a novel training\n",
      "objective -- Margin-Aligned Expectation (MargE) -- that trains the LLM to\n",
      "smoothly interpolate between the reward and reference distributions. Lastly, we\n",
      "introduce a synthetic test suite that bears strong geometric similarity to real\n",
      "biophysical problems and enables rapid evaluation of LLM optimizers without\n",
      "time-consuming lab validation. Our findings reveal that, in comparison to\n",
      "genetic algorithm baselines, LLMs achieve significantly lower regret solutions\n",
      "while requiring fewer test function evaluations. However, we also observe that\n",
      "LLMs exhibit moderate miscalibration, are susceptible to generator collapse,\n",
      "and have difficulty finding the optimal solution when no explicit ground truth\n",
      "rewards are available.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22296v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"本研究では、大規模言語モデル（LLMs）が生物学的タスクにおいて重要な可能性を示していることを述べています。\n",
      "これらのタスクは、ブラックボックスの離散シーケンス最適化を含み、生物学的に実現可能であり、厳密な制約を満たすシーケンスを生成することが課題となります。\n",
      "\",\n",
      "    \"Novelty\": \"新たな手法として、LLMsを高度に制約された二階最適化器として利用する方法を提案します。\n",
      "この方法は、オフラインとオンラインの最適化を組み合わせており、限られたオラクル評価を利用してLLMが生成するシーケンスを反復的に改善します。\n",
      "\",\n",
      "    \"Methodology\": \"提案された方法は、Margin Expectationによる言語モデル最適化（LLOME）と呼ばれ、LLMを訓練するための新しい目的関数であるMargin-Aligned Expectation（MargE）を用います。\n",
      "この目的関数は、報酬分布と参照分布の間をスムーズに補間することを目指しています。\n",
      "\",\n",
      "    \"Results\": \"実験の結果、遺伝的アルゴリズムのベースラインと比較して、LLMsは有意に低い後悔値を達成し、テスト関数評価の回数を少なくすることができました。\n",
      "しかし、LLMsは中程度の誤校正を示し、生成器の崩壊に対して脆弱であり、明示的な真実報酬がない場合には最適解を見つけるのが難しいことも観察されました。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"言語モデル最適化によるマージン期待 (LLOME)\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: Fine-Tuning LLMs for Code Mutation: A New Era of Cyber Threats\n",
      "published: 2024-10-29 17:43:06+00:00\n",
      "abstruct: Recent advancements in Large Language Models (LLMs) have significantly\n",
      "improved their capabilities in natural language processing and code synthesis,\n",
      "enabling more complex applications across different fields. This paper explores\n",
      "the application of LLMs in the context of code mutation, a process where the\n",
      "structure of program code is altered without changing its functionality.\n",
      "Traditionally, code mutation has been employed to increase software robustness\n",
      "in mission-critical applications. Additionally, mutation engines have been\n",
      "exploited by malware developers to evade the signature-based detection methods\n",
      "employed by malware detection systems. Existing code mutation engines, often\n",
      "used by such threat actors, typically result in only limited variations in the\n",
      "malware, which can still be identified through static code analysis. However,\n",
      "the agility demonstrated by an LLM-based code synthesizer could significantly\n",
      "change this threat landscape by allowing for more complex code mutations that\n",
      "are not easily detected using static analysis. One can increase variations of\n",
      "codes synthesized by a pre-trained LLM through fine-tuning and retraining. This\n",
      "process is what we refer to as code mutation training. In this paper, we\n",
      "propose a novel definition of code mutation training tailored for pre-trained\n",
      "LLM-based code synthesizers and demonstrate this training on a lightweight\n",
      "pre-trained model. Our approach involves restructuring (i.e., mutating) code at\n",
      "the subroutine level, which allows for more manageable mutations while\n",
      "maintaining the semantic integrity verified through unit testing. Our\n",
      "experimental results illustrate the effectiveness of our approach in improving\n",
      "code mutation capabilities of LLM-based program synthesizers in producing\n",
      "varied and functionally correct code solutions, showcasing their potential to\n",
      "transform the landscape of code mutation and the threats associated with it.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22293v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"最近の大規模言語モデル（LLM）の進展により、自然言語処理やコード合成の能力が大幅に向上し、さまざまな分野でより複雑なアプリケーションが可能になりました。\n",
      "本論文では、機能を変更せずにプログラムコードの構造を変更するコード変異の文脈におけるLLMの応用を探求します。\n",
      "従来、コード変異はミッションクリティカルなアプリケーションのソフトウェアの堅牢性を高めるために使用されてきました。\n",
      "\",\n",
      "    \"Novelty\": \"本論文では、事前学習されたLLMベースのコード合成器に特化した新たな定義のコード変異トレーニングを提案し、軽量な事前学習モデルでこのトレーニングを実証します。\n",
      "これにより、従来のコード変異エンジンと比較して、より複雑で検出されにくいコード変異を実現する可能性があります。\n",
      "\",\n",
      "    \"Methodology\": \"アプローチは、サブルーチンレベルでコードを再構築（すなわち変異）することを含み、これは意味的な整合性を保ちながら管理可能な変異を実現します。\n",
      "単体テストを通じてその整合性が確認されます。\n",
      "\",\n",
      "    \"Results\": \"実験結果は、LLMベースのプログラム合成器のコード変異能力が改善され、変化に富み、機能的に正しいコードソリューションを生成する能力が向上したことを示しています。\n",
      "これにより、コード変異とそれに関連する脅威の状況を変革する潜在能力が明らかになりました。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"コード変異トレーニング\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: Embedding-based classifiers can detect prompt injection attacks\n",
      "published: 2024-10-29 17:36:59+00:00\n",
      "abstruct: Large Language Models (LLMs) are seeing significant adoption in every type of\n",
      "organization due to their exceptional generative capabilities. However, LLMs\n",
      "are found to be vulnerable to various adversarial attacks, particularly prompt\n",
      "injection attacks, which trick them into producing harmful or inappropriate\n",
      "content. Adversaries execute such attacks by crafting malicious prompts to\n",
      "deceive the LLMs. In this paper, we propose a novel approach based on\n",
      "embedding-based Machine Learning (ML) classifiers to protect LLM-based\n",
      "applications against this severe threat. We leverage three commonly used\n",
      "embedding models to generate embeddings of malicious and benign prompts and\n",
      "utilize ML classifiers to predict whether an input prompt is malicious. Out of\n",
      "several traditional ML methods, we achieve the best performance with\n",
      "classifiers built using Random Forest and XGBoost. Our classifiers outperform\n",
      "state-of-the-art prompt injection classifiers available in open-source\n",
      "implementations, which use encoder-only neural networks.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22284v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"大規模言語モデル（LLMs）は、その優れた生成能力により、さまざまな組織で広く採用されています。\n",
      "しかし、LLMsはプロンプトインジェクション攻撃などのさまざまな脅威に対して脆弱であり、悪意のあるプロンプトによって誤った内容を生成させることができます。\n",
      "本論文では、LLMベースのアプリケーションをこの脅威から保護するために、埋め込みベースの機械学習（ML）分類器に基づく新しいアプローチを提案します。\n",
      "\",\n",
      "    \"Novelty\": \"提案されたアプローチは、悪意のあるプロンプトと無害なプロンプトの埋め込みを生成するために、3つの一般的な埋め込みモデルを活用し、入力プロンプトが悪意のあるものであるかどうかを予測するためにML分類器を利用します。\n",
      "これにより、従来のML手法と比較して、特にランダムフォレストとXGBoostを使用した分類器が優れた性能を発揮します。\n",
      "\",\n",
      "    \"Methodology\": \"本研究では、悪意のあるプロンプトと無害なプロンプトの埋め込みを生成するために、3つの埋め込みモデルを使用し、ML分類器を用いて入力プロンプトの悪意を予測します。\n",
      "具体的には、いくつかの従来のML手法を用いて、ランダムフォレストとXGBoostを使用した場合の性能を評価します。\n",
      "\",\n",
      "    \"Results\": \"提案された分類器は、エンコーダーのみのニューラルネットワークを使用したオープンソース実装の最先端のプロンプトインジェクション分類器を上回る性能を示しました。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"埋め込みベースの機械学習分類器\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: Whose ChatGPT? Unveiling Real-World Educational Inequalities Introduced by Large Language Models\n",
      "published: 2024-10-29 17:35:46+00:00\n",
      "abstruct: The universal availability of ChatGPT and other similar tools since late 2022\n",
      "has prompted tremendous public excitement and experimental effort about the\n",
      "potential of large language models (LLMs) to improve learning experience and\n",
      "outcomes, especially for learners from disadvantaged backgrounds. However,\n",
      "little research has systematically examined the real-world impacts of LLM\n",
      "availability on educational equity beyond theoretical projections and\n",
      "controlled studies of innovative LLM applications. To depict trends of post-LLM\n",
      "inequalities, we analyze 1,140,328 academic writing submissions from 16,791\n",
      "college students across 2,391 courses between 2021 and 2024 at a public,\n",
      "minority-serving institution in the US. We find that students' overall writing\n",
      "quality gradually increased following the availability of LLMs and that the\n",
      "writing quality gaps between linguistically advantaged and disadvantaged\n",
      "students became increasingly narrower. However, this equitizing effect was more\n",
      "concentrated on students with higher socioeconomic status. These findings shed\n",
      "light on the digital divides in the era of LLMs and raise questions about the\n",
      "equity benefits of LLMs in early stages and highlight the need for researchers\n",
      "and practitioners on developing responsible practices to improve educational\n",
      "equity through LLMs.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22282v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"この研究は、2022年末以降に普及したChatGPTや他の大規模言語モデル（LLM）が教育の平等性に与える影響を調査しています。\n",
      "特に、経済的に不利な背景を持つ学習者に対する学習経験と成果の向上が期待されていますが、実際の影響を体系的に検討した研究はほとんどありません。\n",
      "\",\n",
      "    \"Novelty\": \"この研究は、LLMの利用が教育に与える実際の影響を、理論的な予測や制御された研究の枠を超えて、実際のデータに基づいて評価しています。\n",
      "特に、大学生の学術的な執筆提出物のトレンドを分析することで、LLMが教育の平等性にどのように寄与するかを探ります。\n",
      "\",\n",
      "    \"Methodology\": \"2021年から2024年までの間に、米国の公立のマイノリティサービス教育機関での2,391のコースにわたる16,791人の大学生からの1,140,328件の学術的な執筆提出物を分析しました。\n",
      "\",\n",
      "    \"Results\": \"研究の結果、LLMの利用が始まった後、学生の執筆の質が徐々に向上し、言語的に有利な学生と不利な学生との間の執筆の質のギャップが狭まっていることがわかりました。\n",
      "しかし、この均等化の効果は、社会経済的に高い地位にある学生により集中していることも明らかになりました。\n",
      "この結果は、LLMの時代におけるデジタル格差を明らかにし、LLMが教育の平等性を促進するための責任ある実践の必要性を強調しています。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"大規模言語モデル（LLM）の分析\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: Fourier Head: Helping Large Language Models Learn Complex Probability Distributions\n",
      "published: 2024-10-29 17:27:58+00:00\n",
      "abstruct: As the quality of large language models has improved, there has been\n",
      "increased interest in using them to model non-linguistic tokens. For example,\n",
      "the Decision Transformer recasts agentic decision making as a sequence modeling\n",
      "problem, using a decoder-only LLM to model the distribution over the discrete\n",
      "action space for an Atari agent. However, when adapting LLMs to non-linguistic\n",
      "domains, it remains unclear if softmax over discrete bins captures the\n",
      "continuous structure of the tokens and the potentially complex distributions\n",
      "needed for high quality token generation. We introduce a neural network layer,\n",
      "constructed using Fourier series, which we can easily substitute for any linear\n",
      "layer if we want the outputs to have a more continuous structure. We perform\n",
      "extensive analysis on synthetic datasets, as well as on large-scale decision\n",
      "making and time series forecasting tasks. We also provide theoretical evidence\n",
      "that this layer can better learn signal from data while ignoring high-frequency\n",
      "noise. All of our results support the effectiveness of our proposed Fourier\n",
      "head in scenarios where the underlying data distribution has a natural\n",
      "continuous structure. For example, the Fourier head improves a Decision\n",
      "Transformer agent's returns by 46% on the Atari Seaquest game, and increases a\n",
      "state-of-the-art times series foundation model's forecasting performance by\n",
      "3.5% across 20 benchmarks unseen during training.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22269v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"大規模言語モデルの品質が向上する中、非言語トークンをモデル化するための利用が増えている。\n",
      "特に、Decision Transformerはエージェントの意思決定をシーケンスモデリングの問題として再構成し、Atariエージェントの離散アクション空間の分布をモデル化するためにデコーダ専用のLLMを使用している。\n",
      "しかし、LLMを非言語領域に適応させる際、離散ビンに対するソフトマックスがトークンの連続的な構造や高品質なトークン生成に必要な複雑な分布を捉えられるかは不明である。\n",
      "\",\n",
      "    \"Novelty\": \"本研究では、連続的な構造を持つ出力が得られるように、Fourier級数を使用して構築したニューラルネットワーク層を提案する。\n",
      "この層は、任意の線形層の代わりに簡単に置き換えることができる。\n",
      "\",\n",
      "    \"Methodology\": \"合成データセットおよび大規模な意思決定と時系列予測タスクにおいて広範な分析を行った。\n",
      "また、この層がデータから信号をより良く学習し、高周波ノイズを無視できるという理論的証拠も提供した。\n",
      "\",\n",
      "    \"Results\": \"提案するFourier headは、基となるデータ分布が自然な連続構造を持つシナリオにおいて効果的であることを支持する結果が得られた。\n",
      "具体的には、Fourier headはAtari SeaquestゲームにおいてDecision Transformerエージェントのリターンを46%向上させ、トレーニング中に見られなかった20のベンチマークにおいて最先端の時系列基盤モデルの予測性能を3.5%向上させた。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"Fourier head\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: Are Decoder-Only Large Language Models the Silver Bullet for Code Search?\n",
      "published: 2024-10-29 17:05:25+00:00\n",
      "abstruct: Code search is crucial for code reuse, enabling developers to efficiently\n",
      "locate relevant snippets. Current methods rely on encoder-based models, which\n",
      "suffer from limitations such as poor generalization and restricted input\n",
      "lengths. Decoder-only large language models (LLMs), with their extensive\n",
      "pre-training, larger size, and longer input capabilities, offer potential\n",
      "solutions to these issues, yet their effectiveness in code search remains\n",
      "underexplored. To fill this gap, our study presents the first systematic\n",
      "exploration of decoder-only LLMs for code search. We evaluate nine\n",
      "state-of-the-art decoder-only models using two fine-tuning methods, two\n",
      "datasets (CSN and CoSQA$^+$), and three model sizes. Our findings reveal that\n",
      "fine-tuned CodeGemma significantly outperforms encoder-only models like\n",
      "UniXcoder, achieving a 5.57% improvement in MRR on CSN and a 49.6% increase in\n",
      "MAP on CoSQA$^+$ compared to zero-shot UniXcoder. These results highlight the\n",
      "superior performance and adaptability of decoder-only models. Additionally, we\n",
      "provide valuable insights into optimizing these models for code search,\n",
      "covering aspects such as model selection, fine-tuning methods, training data,\n",
      "and model size, and discussing their strengths and limitations.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22240v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"コード検索はコードの再利用にとって重要であり、開発者が関連するコードスニペットを効率的に見つけることを可能にします。\n",
      "現在の手法はエンコーダーベースのモデルに依存しており、一般化能力の低さや入力長の制約といった限界があります。\n",
      "デコーダー専用の大規模言語モデル（LLM）は、その広範な事前学習、大きなサイズ、長い入力能力を持ち、これらの問題を解決する可能性がありますが、コード検索におけるその有効性はまだ十分に探求されていません。\n",
      "\",\n",
      "    \"Novelty\": \"本研究は、デコーダー専用のLLMを使用したコード検索の初めての体系的な探求を提示します。\n",
      "これにより、従来のエンコーダーモデルと比較して、デコーダーモデルの優れた性能を明らかにしています。\n",
      "\",\n",
      "    \"Methodology\": \"9つの最先端のデコーダー専用モデルを評価し、2つの微調整方法、2つのデータセット（CSNおよびCoSQA$^+$）、および3つのモデルサイズを使用しました。\n",
      "\",\n",
      "    \"Results\": \"微調整されたCodeGemmaは、UniXcoderのようなエンコーダー専用モデルに対して、CSNでのMRRで5.57%の改善、CoSQA$^+$でのMAPで49.6%の増加を達成しました。\n",
      "これにより、デコーダー専用モデルの優れた性能と適応性が強調されます。\n",
      "また、モデル選択、微調整方法、トレーニングデータ、モデルサイズなどの観点から、コード検索のためのこれらのモデルの最適化に関する貴重な洞察も提供されています。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"CodeGemma\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: CaStL: Constraints as Specifications through LLM Translation for Long-Horizon Task and Motion Planning\n",
      "published: 2024-10-29 16:54:15+00:00\n",
      "abstruct: Large Language Models (LLMs) have demonstrated remarkable ability in\n",
      "long-horizon Task and Motion Planning (TAMP) by translating clear and\n",
      "straightforward natural language problems into formal specifications such as\n",
      "the Planning Domain Definition Language (PDDL). However, real-world problems\n",
      "are often ambiguous and involve many complex constraints. In this paper, we\n",
      "introduce Constraints as Specifications through LLMs (CaStL), a framework that\n",
      "identifies constraints such as goal conditions, action ordering, and action\n",
      "blocking from natural language in multiple stages. CaStL translates these\n",
      "constraints into PDDL and Python scripts, which are solved using an custom PDDL\n",
      "solver. Tested across three PDDL domains, CaStL significantly improves\n",
      "constraint handling and planning success rates from natural language\n",
      "specification in complex scenarios.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22225v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"この研究は、大規模言語モデル(LLMs)が、明確で簡潔な自然言語の問題を計画ドメイン定義言語(PDDL)などの形式的な仕様に変換することで、長期的なタスクと動作計画(TAMP)において優れた能力を示していることに注目しています。\n",
      "ただし、実世界の問題はしばしば曖昧で、複雑な制約が含まれています。\n",
      "\",\n",
      "    \"Novelty\": \"本論文では、自然言語から目標条件、行動の順序、行動のブロッキングなどの制約を特定する新しいフレームワーク「Constraints as Specifications through LLMs (CaStL)」を提案しています。\n",
      "これは複数の段階を経て制約を特定することができ、既存の手法に対する画期的な進歩を示しています。\n",
      "\",\n",
      "    \"Methodology\": \"CaStLは、自然言語から得られた制約をPDDLおよびPythonスクリプトに変換し、カスタムPDDLソルバーを使用して解決します。\n",
      "これにより、複雑なシナリオでの計画成功率を向上させることを目的としています。\n",
      "\",\n",
      "    \"Results\": \"三つのPDDLドメインでテストした結果、CaStLは自然言語仕様からの制約処理と計画成功率を大幅に改善しました。\n",
      "これは、自然言語による問題設定の複雑さに対処するための効果的な手法であることを示しています。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"Constraints as Specifications through LLMs (CaStL)\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: Towards Unifying Understanding and Generation in the Era of Vision Foundation Models: A Survey from the Autoregression Perspective\n",
      "published: 2024-10-29 16:48:22+00:00\n",
      "abstruct: Autoregression in large language models (LLMs) has shown impressive\n",
      "scalability by unifying all language tasks into the next token prediction\n",
      "paradigm. Recently, there is a growing interest in extending this success to\n",
      "vision foundation models. In this survey, we review the recent advances and\n",
      "discuss future directions for autoregressive vision foundation models. First,\n",
      "we present the trend for next generation of vision foundation models, i.e.,\n",
      "unifying both understanding and generation in vision tasks. We then analyze the\n",
      "limitations of existing vision foundation models, and present a formal\n",
      "definition of autoregression with its advantages. Later, we categorize\n",
      "autoregressive vision foundation models from their vision tokenizers and\n",
      "autoregression backbones. Finally, we discuss several promising research\n",
      "challenges and directions. To the best of our knowledge, this is the first\n",
      "survey to comprehensively summarize autoregressive vision foundation models\n",
      "under the trend of unifying understanding and generation. A collection of\n",
      "related resources is available at https://github.com/EmmaSRH/ARVFM.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22217v2\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"本調査では、自動回帰に基づくビジョン基盤モデルの最近の進展をレビューし、その将来の方向性について議論します。\n",
      "特に、理解と生成の両方を統一した次世代ビジョン基盤モデルのトレンドを提示し、既存のモデルの限界を分析します。\n",
      "\",\n",
      "    \"Novelty\": \"この調査は、理解と生成を統一するトレンドの下で、自動回帰ビジョン基盤モデルを包括的に要約する初の調査です。\n",
      "\",\n",
      "    \"Methodology\": \"自動回帰の定義とその利点を提示し、ビジョントークナイザーと自動回帰バックボーンによる自動回帰ビジョン基盤モデルの分類を行います。\n",
      "\",\n",
      "    \"Results\": \"調査の結果、今後の研究課題や方向性がいくつか有望であることが示され、関連リソースが提供されています。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"自動回帰ビジョン基盤モデル\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: ProMQA: Question Answering Dataset for Multimodal Procedural Activity Understanding\n",
      "published: 2024-10-29 16:39:28+00:00\n",
      "abstruct: Multimodal systems have great potential to assist humans in procedural\n",
      "activities, where people follow instructions to achieve their goals. Despite\n",
      "diverse application scenarios, systems are typically evaluated on traditional\n",
      "classification tasks, e.g., action recognition or temporal action segmentation.\n",
      "In this paper, we present a novel evaluation dataset, ProMQA, to measure system\n",
      "advancements in application-oriented scenarios. ProMQA consists of 401\n",
      "multimodal procedural QA pairs on user recording of procedural activities\n",
      "coupled with their corresponding instruction. For QA annotation, we take a\n",
      "cost-effective human-LLM collaborative approach, where the existing annotation\n",
      "is augmented with LLM-generated QA pairs that are later verified by humans. We\n",
      "then provide the benchmark results to set the baseline performance on ProMQA.\n",
      "Our experiment reveals a significant gap between human performance and that of\n",
      "current systems, including competitive proprietary multimodal models. We hope\n",
      "our dataset sheds light on new aspects of models' multimodal understanding\n",
      "capabilities.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22211v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"この研究では、手順に従って目標を達成するために人間を支援するマルチモーダルシステムの可能性について探求しています。\n",
      "これまでのシステム評価は、アクション認識や時間的アクションセグメンテーションなどの伝統的な分類タスクに依存していました。\n",
      "\",\n",
      "    \"Novelty\": \"本研究では、ProMQAと呼ばれる新しい評価データセットを提案し、マルチモーダルシステムの進展を、実用的なシナリオにおいて測定することが目的です。\n",
      "ProMQAは、手順活動のユーザー記録とそれに対応する指示に基づいた401のマルチモーダル手順QAペアで構成されています。\n",
      "\",\n",
      "    \"Methodology\": \"QAアノテーションには、コスト効果の高い人間と大規模言語モデル（LLM）との協力的アプローチを採用し、既存のアノテーションをLLM生成のQAペアで増強し、後に人間によって検証されます。\n",
      "さらに、ProMQAにおけるベンチマーク結果を提供し、基準性能を設定します。\n",
      "\",\n",
      "    \"Results\": \"実験の結果、現在のシステム、特に競争力のある商業用マルチモーダルモデルのパフォーマンスと人間のパフォーマンスとの間に大きなギャップがあることが明らかになりました。\n",
      "このデータセットがモデルのマルチモーダル理解能力の新たな側面を明らかにすることを期待しています。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"人間-LLM共同アプローチ\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: Synthetic Data Generation with Large Language Models for Personalized Community Question Answering\n",
      "published: 2024-10-29 16:19:08+00:00\n",
      "abstruct: Personalization in Information Retrieval (IR) is a topic studied by the\n",
      "research community since a long time. However, there is still a lack of\n",
      "datasets to conduct large-scale evaluations of personalized IR; this is mainly\n",
      "due to the fact that collecting and curating high-quality user-related\n",
      "information requires significant costs and time investment. Furthermore, the\n",
      "creation of datasets for Personalized IR (PIR) tasks is affected by both\n",
      "privacy concerns and the need for accurate user-related data, which are often\n",
      "not publicly available. Recently, researchers have started to explore the use\n",
      "of Large Language Models (LLMs) to generate synthetic datasets, which is a\n",
      "possible solution to generate data for low-resource tasks. In this paper, we\n",
      "investigate the potential of Large Language Models (LLMs) for generating\n",
      "synthetic documents to train an IR system for a Personalized Community Question\n",
      "Answering task. To study the effectiveness of IR models fine-tuned on\n",
      "LLM-generated data, we introduce a new dataset, named Sy-SE-PQA. We build\n",
      "Sy-SE-PQA based on an existing dataset, SE-PQA, which consists of questions and\n",
      "answers posted on the popular StackExchange communities. Starting from\n",
      "questions in SE-PQA, we generate synthetic answers using different prompt\n",
      "techniques and LLMs. Our findings suggest that LLMs have high potential in\n",
      "generating data tailored to users' needs. The synthetic data can replace\n",
      "human-written training data, even if the generated data may contain incorrect\n",
      "information.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22182v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"情報検索 (IR) におけるパーソナライズは、研究コミュニティによって長い間研究されてきましたが、高品質なユーザー関連情報の収集とキュレーションに significant なコストと時間が必要であるため、大規模な評価を行うためのデータセットが不足しています。\n",
      "さらに、パーソナライズされた IR (PIR) タスクのためのデータセットの作成は、プライバシーへの懸念と正確なユーザー関連データの必要性によって影響を受けています。\n",
      "最近、研究者たちは大規模言語モデル (LLM) を使用して合成データセットを生成することを探求し始めており、これはリソースが限られたタスクのためのデータ生成の可能な解決策です。\n",
      "\",\n",
      "    \"Novelty\": \"本論文では、パーソナライズされたコミュニティ質問応答タスクのために IR システムを訓練するために、LLM によって生成された合成文書の可能性を調査しています。\n",
      "新しいデータセット Sy-SE-PQA を導入し、既存のデータセット SE-PQA に基づいて構築されました。\n",
      "\",\n",
      "    \"Methodology\": \"Sy-SE-PQA は、人気のある StackExchange コミュニティに投稿された質問と回答から構成される SE-PQA に基づいています。\n",
      "SE-PQA の質問から出発し、さまざまなプロンプト技術と LLM を使用して合成回答を生成します。\n",
      "\",\n",
      "    \"Results\": \"研究結果は、LLM がユーザーのニーズに合わせたデータを生成する高い可能性を持っていることを示唆しています。\n",
      "合成データは、人間が書いた訓練データの代わりに使用できる可能性があり、生成されたデータが間違った情報を含む場合があるにもかかわらず有用です。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"Large Language Models (LLMs)\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: Analyzing Multimodal Interaction Strategies for LLM-Assisted Manipulation of 3D Scenes\n",
      "published: 2024-10-29 16:15:59+00:00\n",
      "abstruct: As more applications of large language models (LLMs) for 3D content for\n",
      "immersive environments emerge, it is crucial to study user behaviour to\n",
      "identify interaction patterns and potential barriers to guide the future design\n",
      "of immersive content creation and editing systems which involve LLMs. In an\n",
      "empirical user study with 12 participants, we combine quantitative usage data\n",
      "with post-experience questionnaire feedback to reveal common interaction\n",
      "patterns and key barriers in LLM-assisted 3D scene editing systems. We identify\n",
      "opportunities for improving natural language interfaces in 3D design tools and\n",
      "propose design recommendations for future LLM-integrated 3D content creation\n",
      "systems. Through an empirical study, we demonstrate that LLM-assisted\n",
      "interactive systems can be used productively in immersive environments.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22177v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"3Dコンテンツの没入型環境における大規模言語モデル（LLMs）のアプリケーションが増える中、ユーザーの行動を研究し、相互作用のパターンや潜在的な障壁を特定することが重要です。\n",
      "これにより、LLMsを含む没入型コンテンツ作成と編集システムの将来の設計が導かれます。\n",
      "\",\n",
      "    \"Novelty\": \"本研究では、12人の参加者との実証的ユーザー研究を通じて、定量的な使用データと体験後の質問票のフィードバックを組み合わせて、LLM支援の3Dシーン編集システムにおける一般的な相互作用パターンと主要な障壁を明らかにしました。\n",
      "\",\n",
      "    \"Methodology\": \"参加者からのフィードバックと使用データを組み合わせることで、3Dデザインツールにおける自然言語インターフェースの改善機会を特定し、将来のLLM統合3Dコンテンツ作成システムに対する設計推奨を提案しました。\n",
      "\",\n",
      "    \"Results\": \"実証研究を通じて、LLM支援のインタラクティブシステムは没入型環境で生産的に使用できることを示しました。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"実証的ユーザー研究\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: Training LLMs for Generating IEC 61131-3 Structured Text with Online Feedback\n",
      "published: 2024-10-29 15:54:09+00:00\n",
      "abstruct: The advent of large language models (LLMs), such as GPT-4, has enabled\n",
      "significant advancements in generating code across various domains. However,\n",
      "these models face unique challenges when generating IEC 61131-3 Structured Text\n",
      "(ST) code due to limited data in public training datasets and the complexity of\n",
      "ST language syntax. This paper proposes a novel approach to training LLMs that\n",
      "emphasizes improving the quality of learning data through an online process\n",
      "involving compiler feedback and evaluation from a secondary LLM. In this\n",
      "framework, the primary LLM generates new training samples, which are\n",
      "subsequently evaluated by a compiler for syntactical correctness and by a\n",
      "specialized LLM that excels at assessing semantic accuracy, though it is not\n",
      "optimized for code generation itself. Through iterative refinement of the\n",
      "training data, this approach results in marked improvements for the trained\n",
      "LLM, leading to higher compilation success rates and better semantic precision.\n",
      "As a result, the framework proves highly suitable for industrial automation\n",
      "applications and outperforms state-of-the-art models.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22159v2\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"大規模言語モデル（LLMs）、特にGPT-4の登場により、さまざまな分野でのコード生成が大幅に進展しました。\n",
      "しかし、IEC 61131-3構造化テキスト（ST）コードの生成には、公開トレーニングデータセットのデータが限られていることや、ST言語の構文の複雑さから特有の課題があります。\n",
      "\",\n",
      "    \"Novelty\": \"この論文は、コンパイラのフィードバックと二次的なLLMからの評価を含むオンラインプロセスを通じて、学習データの質を向上させることを強調した、LLMのトレーニングに関する新しいアプローチを提案しています。\n",
      "\",\n",
      "    \"Methodology\": \"このフレームワークでは、主要なLLMが新しいトレーニングサンプルを生成し、その後、構文的正確性のためにコンパイラによって評価され、コード生成自体には最適化されていないが、意味的正確性を評価するのが得意な専門のLLMによって評価されます。\n",
      "トレーニングデータの反復的な洗練を通じて、このアプローチはトレーニングされたLLMに顕著な改善をもたらし、コンパイル成功率の向上と意味的な精度の向上を実現します。\n",
      "\",\n",
      "    \"Results\": \"その結果、このフレームワークは産業用自動化アプリケーションに非常に適しており、最先端のモデルを上回る性能を示しています。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"オンラインプロセスを通じてのLLMトレーニングアプローチ\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: Benchmarking LLM Guardrails in Handling Multilingual Toxicity\n",
      "published: 2024-10-29 15:51:24+00:00\n",
      "abstruct: With the ubiquity of Large Language Models (LLMs), guardrails have become\n",
      "crucial to detect and defend against toxic content. However, with the\n",
      "increasing pervasiveness of LLMs in multilingual scenarios, their effectiveness\n",
      "in handling multilingual toxic inputs remains unclear. In this work, we\n",
      "introduce a comprehensive multilingual test suite, spanning seven datasets and\n",
      "over ten languages, to benchmark the performance of state-of-the-art\n",
      "guardrails. We also investigates the resilience of guardrails against recent\n",
      "jailbreaking techniques, and assess the impact of in-context safety policies\n",
      "and language resource availability on guardrails' performance. Our findings\n",
      "show that existing guardrails are still ineffective at handling multilingual\n",
      "toxicity and lack robustness against jailbreaking prompts. This work aims to\n",
      "identify the limitations of guardrails and to build a more reliable and\n",
      "trustworthy LLMs in multilingual scenarios.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22153v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"この研究では、大規模言語モデル（LLMs）の普及に伴い、有害コンテンツを検出し防御するためのガードレールの重要性が増していることを述べています。\n",
      "特に、多言語シナリオにおけるLLMsの効果が不明であることを指摘しています。\n",
      "\",\n",
      "    \"Novelty\": \"この研究の新規性は、7つのデータセットと10を超える言語を網羅した包括的な多言語テストスイートを導入した点です。\n",
      "これにより、最先端のガードレールのパフォーマンスをベンチマークすることが可能になります。\n",
      "\",\n",
      "    \"Methodology\": \"研究では、ガードレールの最近のジャイルブレイキング技術に対する耐性を調査し、文脈内安全ポリシーと言語リソースの可用性がガードレールのパフォーマンスに与える影響を評価します。\n",
      "\",\n",
      "    \"Results\": \"結果として、既存のガードレールは多言語の有害性を処理するのに効果がなく、ジャイルブレイキングプロンプトに対するロバスト性も欠けていることが示されました。\n",
      "この研究は、ガードレールの限界を特定し、多言語シナリオにおいてより信頼性の高いLLMsを構築することを目指しています。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"包括的な多言語テストスイート\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: AmpleGCG-Plus: A Strong Generative Model of Adversarial Suffixes to Jailbreak LLMs with Higher Success Rates in Fewer Attempts\n",
      "published: 2024-10-29 15:40:07+00:00\n",
      "abstruct: Although large language models (LLMs) are typically aligned, they remain\n",
      "vulnerable to jailbreaking through either carefully crafted prompts in natural\n",
      "language or, interestingly, gibberish adversarial suffixes. However, gibberish\n",
      "tokens have received relatively less attention despite their success in\n",
      "attacking aligned LLMs. Recent work, AmpleGCG~\\citep{liao2024amplegcg},\n",
      "demonstrates that a generative model can quickly produce numerous customizable\n",
      "gibberish adversarial suffixes for any harmful query, exposing a range of\n",
      "alignment gaps in out-of-distribution (OOD) language spaces. To bring more\n",
      "attention to this area, we introduce AmpleGCG-Plus, an enhanced version that\n",
      "achieves better performance in fewer attempts. Through a series of exploratory\n",
      "experiments, we identify several training strategies to improve the learning of\n",
      "gibberish suffixes. Our results, verified under a strict evaluation setting,\n",
      "show that it outperforms AmpleGCG on both open-weight and closed-source models,\n",
      "achieving increases in attack success rate (ASR) of up to 17\\% in the white-box\n",
      "setting against Llama-2-7B-chat, and more than tripling ASR in the black-box\n",
      "setting against GPT-4. Notably, AmpleGCG-Plus jailbreaks the newer GPT-4o\n",
      "series of models at similar rates to GPT-4, and, uncovers vulnerabilities\n",
      "against the recently proposed circuit breakers defense. We publicly release\n",
      "AmpleGCG-Plus along with our collected training datasets.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22143v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"大規模言語モデル（LLMs）は通常、整合性が取れていますが、巧妙に作成されたプロンプトや、興味深いことに、無意味な敵対的サフィックスによる脱獄に対して脆弱です。\n",
      "無意味なトークンは、整合性のあるLLMsを攻撃する成功にもかかわらず、比較的少ない注目を集めています。\n",
      "最近の研究、AmpleGCGは、生成モデルが迅速にカスタマイズ可能な無意味な敵対的サフィックスを生成できることを示し、分布外（OOD）言語空間における整合性のギャップを明らかにしています。\n",
      "\",\n",
      "    \"Novelty\": \"私たちは、AmpleGCGの強化版であるAmpleGCG-Plusを紹介します。\n",
      "これにより、試行回数を減らしながら性能が向上します。\n",
      "この研究は無意味なサフィックスの学習を改善するいくつかのトレーニング戦略を特定するための探索的実験を通じて行われました。\n",
      "\",\n",
      "    \"Methodology\": \"AmpleGCG-Plusは、オープンウェイトおよびクローズドソースモデルの両方でAmpleGCGを上回る結果を示し、Llama-2-7B-chatに対するホワイトボックス設定で攻撃成功率（ASR）が最大17%向上し、GPT-4に対するブラックボックス設定でASRが3倍以上に増加します。\n",
      "\",\n",
      "    \"Results\": \"特に、AmpleGCG-Plusは新しいGPT-4oシリーズモデルをGPT-4と同様の速度で脱獄し、最近提案された回路ブレーカーディフェンスに対する脆弱性を明らかにします。\n",
      "また、私たちはAmpleGCG-Plusと収集したトレーニングデータセットを公開します。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"AmpleGCG-Plus\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: ProMoE: Fast MoE-based LLM Serving using Proactive Caching\n",
      "published: 2024-10-29 15:31:27+00:00\n",
      "abstruct: The promising applications of large language models are often constrained by\n",
      "the limited GPU memory capacity available on edge devices. Mixture-of-Experts\n",
      "(MoE) models help mitigate this issue by activating only a subset of the\n",
      "model's parameters during computation, allowing the unused parameters to be\n",
      "offloaded to host memory and reducing overall GPU memory demand. However,\n",
      "existing cache-based offloading solutions handle cache misses reactively and\n",
      "significantly impact system performance. In this paper, we propose ProMoE, a\n",
      "novel proactive caching system that leverages intermediate model results to\n",
      "predict subsequent parameter usage. By proactively fetching experts in advance,\n",
      "ProMoE removes the loading time from the critical path and diminishes the\n",
      "performance overhead of offloading. Our evaluations demonstrate that ProMoE\n",
      "achieves an average speedup of 2.13x and 2.84x in the prefill and decode stages\n",
      "respectively, compared to existing offloading solutions.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22134v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"大規模言語モデルの有望な応用は、エッジデバイス上の限られたGPUメモリ容量によって制約されています。\n",
      "Mixture-of-Experts (MoE) モデルは、計算中にモデルのパラメータのサブセットのみを活性化することでこの問題を軽減し、未使用のパラメータをホストメモリにオフロードすることができ、全体のGPUメモリ需要を減少させます。\n",
      "しかし、既存のキャッシュベースのオフロードソリューションは、キャッシュミスを反応的に処理し、システムパフォーマンスに大きな影響を与えます。\n",
      "\",\n",
      "    \"Novelty\": \"本論文では、ProMoEという新しいプロアクティブキャッシングシステムを提案します。\n",
      "これは、中間モデル結果を利用して次のパラメータ使用を予測します。\n",
      "事前に専門家をプロアクティブに取得することで、ProMoEはクリティカルパスから読み込み時間を排除し、オフロードによるパフォーマンスオーバーヘッドを減少させます。\n",
      "\",\n",
      "    \"Methodology\": \"ProMoEは、モデルの中間結果を活用して、次に必要となるパラメータの使用を予測し、先に専門家を取得することでシステムのパフォーマンスを向上させます。\n",
      "この手法により、オフロードの影響を最小限に抑えつつ、全体の計算速度を向上させることが可能になります。\n",
      "\",\n",
      "    \"Results\": \"評価の結果、ProMoEは既存のオフロードソリューションと比較して、プレフィル及びデコード段階でそれぞれ平均2.13倍及び2.84倍のスピードアップを達成しました。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"ProMoE\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: Improving Performance of Commercially Available AI Products in a Multi-Agent Configuration\n",
      "published: 2024-10-29 15:28:19+00:00\n",
      "abstruct: In recent years, with the rapid advancement of large language models (LLMs),\n",
      "multi-agent systems have become increasingly more capable of practical\n",
      "application. At the same time, the software development industry has had a\n",
      "number of new AI-powered tools developed that improve the software development\n",
      "lifecycle (SDLC). Academically, much attention has been paid to the role of\n",
      "multi-agent systems to the SDLC. And, while single-agent systems have\n",
      "frequently been examined in real-world applications, we have seen comparatively\n",
      "few real-world examples of publicly available commercial tools working together\n",
      "in a multi-agent system with measurable improvements. In this experiment we\n",
      "test context sharing between Crowdbotics PRD AI, a tool for generating software\n",
      "requirements using AI, and GitHub Copilot, an AI pair-programming tool. By\n",
      "sharing business requirements from PRD AI, we improve the code suggestion\n",
      "capabilities of GitHub Copilot by 13.8% and developer task success rate by\n",
      "24.5% -- demonstrating a real-world example of commercially-available AI\n",
      "systems working together with improved outcomes.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22129v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"最近、ラージランゲージモデル（LLM）の急速な進展に伴い、マルチエージェントシステムが実用的な応用能力を高めてきています。\n",
      "また、ソフトウェア開発業界では、ソフトウェア開発ライフサイクル（SDLC）を改善するAI駆動の新しいツールがいくつか開発されています。\n",
      "学術的には、SDLCにおけるマルチエージェントシステムの役割に多くの注意が払われていますが、実際のアプリケーションでは単一エージェントシステムがよく検討されているのに対し、マルチエージェントシステムが協力している実際の商用ツールの例は比較的少ないです。\n",
      "\",\n",
      "    \n",
      "    \"Novelty\": \"本研究では、Crowdbotics PRD AI（AIを使用してソフトウェア要件を生成するツール）とGitHub Copilot（AIペアプログラミングツール）間でのコンテキスト共有をテストします。\n",
      "このアプローチは、商用利用可能なAIシステムが協力して、実際の成果を向上させる新しい例を示しています。\n",
      "\",\n",
      "    \n",
      "    \"Methodology\": \"実験では、PRD AIからビジネス要件を共有することで、GitHub Copilotのコード提案能力を向上させることを目指しています。\n",
      "具体的には、ビジネス要件を元にして、プログラミング支援を行う手法を用いています。\n",
      "\",\n",
      "    \n",
      "    \"Results\": \"その結果、GitHub Copilotのコード提案能力が13.8%向上し、開発者のタスク成功率が24.5%向上しました。\n",
      "これは、商用AIシステムが協力した際の改善された成果を示しています。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"コンテキスト共有\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: The Impact of Inference Acceleration Strategies on Bias of LLMs\n",
      "published: 2024-10-29 15:19:13+00:00\n",
      "abstruct: Last few years have seen unprecedented advances in capabilities of Large\n",
      "Language Models (LLMs). These advancements promise to deeply benefit a vast\n",
      "array of application domains. However, due to their immense size, performing\n",
      "inference with LLMs is both costly and slow. Consequently, a plethora of recent\n",
      "work has proposed strategies to enhance inference efficiency, e.g.,\n",
      "quantization, pruning, and caching. These acceleration strategies reduce the\n",
      "inference cost and latency, often by several factors, while maintaining much of\n",
      "the predictive performance measured via common benchmarks. In this work, we\n",
      "explore another critical aspect of LLM performance: demographic bias in model\n",
      "generations due to inference acceleration optimizations. Using a wide range of\n",
      "metrics, we probe bias in model outputs from a number of angles. Analysis of\n",
      "outputs before and after inference acceleration shows significant change in\n",
      "bias. Worryingly, these bias effects are complex and unpredictable. A\n",
      "combination of an acceleration strategy and bias type may show little bias\n",
      "change in one model but may lead to a large effect in another. Our results\n",
      "highlight a need for in-depth and case-by-case evaluation of model bias after\n",
      "it has been modified to accelerate inference.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22118v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"近年、Large Language Models (LLMs) の能力が前例のない進展を見せており、さまざまなアプリケーション分野に深く利益をもたらすことが期待されています。\n",
      "しかし、その巨大なサイズにより、LLMs での推論は高コストかつ遅延が発生します。\n",
      "これに対処するため、量子化、プルーニング、キャッシングなどの推論効率を向上させる戦略が提案されています。\n",
      "これらの戦略は、推論コストとレイテンシを大幅に削減しながら、一般的なベンチマークで測定される予測性能の多くを維持します。\n",
      "\",\n",
      "    \"Novelty\": \"この研究の新規性は、推論加速最適化によるモデル生成における人口統計的バイアスの重要な側面を探求することにあります。\n",
      "従来の研究が推論効率に焦点を当てる一方で、本研究はモデル出力のバイアスに注目しています。\n",
      "\",\n",
      "    \"Methodology\": \"さまざまなメトリックを使用して、推論加速の前後でのモデル出力のバイアスを複数の角度から調査します。\n",
      "これにより、異なる加速戦略とバイアスタイプの組み合わせによるバイアスの変化を分析します。\n",
      "\",\n",
      "    \"Results\": \"推論加速の前後での出力分析から、バイアスに顕著な変化が見られることが分かりました。\n",
      "また、これらのバイアスの影響は複雑で予測不可能です。\n",
      "あるモデルではバイアスの変化が少ない場合でも、別のモデルでは大きな影響を与えることがあることが示されました。\n",
      "これにより、推論を加速させた後のモデルバイアスの詳細な評価が必要であることが強調されます。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"推論加速最適化\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: Protecting Privacy in Multimodal Large Language Models with MLLMU-Bench\n",
      "published: 2024-10-29 15:07:23+00:00\n",
      "abstruct: Generative models such as Large Language Models (LLM) and Multimodal Large\n",
      "Language models (MLLMs) trained on massive web corpora can memorize and\n",
      "disclose individuals' confidential and private data, raising legal and ethical\n",
      "concerns. While many previous works have addressed this issue in LLM via\n",
      "machine unlearning, it remains largely unexplored for MLLMs. To tackle this\n",
      "challenge, we introduce Multimodal Large Language Model Unlearning Benchmark\n",
      "(MLLMU-Bench), a novel benchmark aimed at advancing the understanding of\n",
      "multimodal machine unlearning. MLLMU-Bench consists of 500 fictitious profiles\n",
      "and 153 profiles for public celebrities, each profile feature over 14\n",
      "customized question-answer pairs, evaluated from both multimodal (image+text)\n",
      "and unimodal (text) perspectives. The benchmark is divided into four sets to\n",
      "assess unlearning algorithms in terms of efficacy, generalizability, and model\n",
      "utility. Finally, we provide baseline results using existing generative model\n",
      "unlearning algorithms. Surprisingly, our experiments show that unimodal\n",
      "unlearning algorithms excel in generation and cloze tasks, while multimodal\n",
      "unlearning approaches perform better in classification tasks with multimodal\n",
      "inputs.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22108v1\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"本研究では、大規模言語モデル（LLM）やマルチモーダル大規模言語モデル（MLLM）が個人の機密データを記憶し開示する可能性があることから、法的および倫理的な問題が提起されています。\n",
      "この問題は主にLLMに対して機械的な忘却（マシンアンラーニング）を通じて対処されていますが、MLLMに関してはあまり探求されていません。\n",
      "これに対処するために、マルチモーダル大規模言語モデルの忘却ベンチマーク（MLLMU-Bench）を紹介します。\n",
      "\",\n",
      "    \"Novelty\": \"MLLMU-Benchは500の架空のプロフィールと153の公共のセレブリティのプロフィールを含み、各プロフィールには14以上のカスタマイズされた質問と回答のペアがあります。\n",
      "これにより、マルチモーダル（画像+テキスト）およびユニモーダル（テキスト）の観点から評価が可能です。\n",
      "このベンチマークは、忘却アルゴリズムの効果、一般化能力、モデルの有用性を評価するために四つのセットに分かれています。\n",
      "\",\n",
      "    \"Methodology\": \"最終的に、既存の生成モデルの忘却アルゴリズムを用いてベースライン結果を提供します。\n",
      "また、ユニモーダルな忘却アルゴリズムが生成やクローズタスクに優れているのに対し、マルチモーダルな忘却アプローチはマルチモーダル入力を使用した分類タスクでより良い結果を示すことがわかりました。\n",
      "\",\n",
      "    \"Results\": \"実験の結果、ユニモーダルな忘却アルゴリズムが生成タスクやクローズタスクにおいて優れている一方で、マルチモーダルな忘却アプローチはマルチモーダル入力を用いた分類タスクでより良いパフォーマンスを示しました。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"マルチモーダル大規模言語モデルの忘却ベンチマーク（MLLMU-Bench）\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "title: Unlearning as multi-task optimization: A normalized gradient difference approach with an adaptive learning rate\n",
      "published: 2024-10-29 14:41:44+00:00\n",
      "abstruct: Machine unlearning has been used to remove unwanted knowledge acquired by\n",
      "large language models (LLMs). In this paper, we examine machine unlearning from\n",
      "an optimization perspective, framing it as a regularized multi-task\n",
      "optimization problem, where one task optimizes a forgetting objective and\n",
      "another optimizes the model performance. In particular, we introduce a\n",
      "normalized gradient difference (NGDiff) algorithm, enabling us to have better\n",
      "control over the trade-off between the objectives, while integrating a new,\n",
      "automatic learning rate scheduler. We provide a theoretical analysis and\n",
      "empirically demonstrate the superior performance of NGDiff among\n",
      "state-of-the-art unlearning methods on the TOFU and MUSE datasets while\n",
      "exhibiting stable training.\n",
      "PDFリンク: http://arxiv.org/pdf/2410.22086v2\n",
      "summary:\n",
      "```json\n",
      "{\n",
      "  \"extract_summary\": {\n",
      "    \"Overview\": \"本稿では、機械学習における不要な知識の除去に関する研究を行い、特に大規模言語モデル（LLMs）における機械忘却の最適化の観点からのアプローチを提案しています。\n",
      "\",\n",
      "    \"Novelty\": \"新たに提案するNGDiffアルゴリズムは、忘却目標とモデル性能のトレードオフをより良く制御し、さらに新しい自動学習率スケジューラを統合しています。\n",
      "\",\n",
      "    \"Methodology\": \"忘却目標を最適化するタスクとモデル性能を最適化するタスクを持つ正則化されたマルチタスク最適化問題として機械忘却を定式化し、理論的な分析を行っています。\n",
      "\",\n",
      "    \"Results\": \"NGDiffの実験結果は、TOFUおよびMUSEデータセットにおいて、最先端の忘却手法の中でも優れた性能を示し、安定したトレーニングを実現しています。\n",
      "\"\n",
      "  },\n",
      "  \"method_name\": \"NGDiffアルゴリズム\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# CATEGORIES = {\n",
    "#     \"cs.AI\",  # 例: コンピュータサイエンスのAI分野\n",
    "#     # \"stat.ML\",  # 例: 統計学の機械学習分野\n",
    "#     # 必要に応じて他のカテゴリーを追加\n",
    "# }\n",
    "\n",
    "keyword = \"LLM\"\n",
    "# keyword = \"LLM zero\"\n",
    "# keyword = \"LLM prompt\"\n",
    "# keyword = \"prompt optimization\"\n",
    "# keyword = \"Prompt Generation\"\n",
    "# keyword = \"LLM code\"\n",
    "\n",
    "results = search_arxiv(keyword)\n",
    "\n",
    "for result in results:\n",
    "    summary = get_summary(result)\n",
    "    # summaryの中の\".\"を改行\"\\n\"に置き換える\n",
    "    formatted_summary = summary.replace('。', '。\\n')\n",
    "\n",
    "    print(f\"title: {result.title}\")\n",
    "    print(f\"published: {result.published}\")\n",
    "    print(f\"abstruct: {result.summary}\")\n",
    "    print(f\"PDFリンク: {result.pdf_url}\")\n",
    "    # print(f\"summary: {summary}\")\n",
    "    print(f\"summary:\\n{formatted_summary}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58f4ef02-fff2-4190-8c63-7339a3593e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keyword = \"LLM Agent\"\n",
    "# # keyword = \"Document LLM\"\n",
    "\n",
    "# results = search_arxiv(keyword)\n",
    "\n",
    "# for result in results:\n",
    "#     summary = get_summary(result)\n",
    "#     print(f\"title: {result.title}\")\n",
    "#     print(f\"published: {result.published}\")\n",
    "#     print(f\"abstruct: {result.summary}\")\n",
    "#     print(f\"PDFリンク: {result.pdf_url}\")\n",
    "#     print(f\"summary: {summary}\")\n",
    "#     print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8f2b362-5a33-4c31-8f71-5cd22462449c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keyword = \"RAG\"\n",
    "\n",
    "# results = search_arxiv(keyword)\n",
    "\n",
    "# for result in results:\n",
    "#     summary = get_summary(result)\n",
    "#     print(f\"title: {result.title}\")\n",
    "#     print(f\"published: {result.published}\")\n",
    "#     print(f\"abstruct: {result.summary}\")\n",
    "#     print(f\"PDFリンク: {result.pdf_url}\")\n",
    "#     print(f\"summary: {summary}\")\n",
    "#     print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a1cc269-62ee-45e3-af02-4f5ebcbc51fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keyword = \"LLM write\"\n",
    "# # keyword = \"Document LLM\"\n",
    "\n",
    "# results = search_arxiv(keyword)\n",
    "\n",
    "# for result in results:\n",
    "#     summary = get_summary(result)\n",
    "#     print(f\"title: {result.title}\")\n",
    "#     print(f\"published: {result.published}\")\n",
    "#     print(f\"abstruct: {result.summary}\")\n",
    "#     print(f\"PDFリンク: {result.pdf_url}\")\n",
    "#     print(f\"summary: {summary}\")\n",
    "#     print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f456a539-c6e2-479a-8b34-04342e7ba370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keyword = \"text writing\"\n",
    "# # keyword = \"Document LLM\"\n",
    "\n",
    "# results = search_arxiv(keyword)\n",
    "\n",
    "# for result in results:\n",
    "#     summary = get_summary(result)\n",
    "#     print(f\"title: {result.title}\")\n",
    "#     print(f\"published: {result.published}\")\n",
    "#     print(f\"abstruct: {result.summary}\")\n",
    "#     print(f\"PDFリンク: {result.pdf_url}\")\n",
    "#     print(f\"summary: {summary}\")\n",
    "#     print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7eba86e9-d252-4323-b119-08cebb959ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keyword = \"Knowledge graph\"\n",
    "# # keyword = \"Document LLM\"\n",
    "\n",
    "# results = search_arxiv(keyword)\n",
    "\n",
    "# for result in results:\n",
    "#     summary = get_summary(result)\n",
    "#     print(f\"title: {result.title}\")\n",
    "#     print(f\"published: {result.published}\")\n",
    "#     print(f\"abstruct: {result.summary}\")\n",
    "#     print(f\"PDFリンク: {result.pdf_url}\")\n",
    "#     print(f\"summary: {summary}\")\n",
    "#     print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a4e89a-ff7a-4e57-89ed-ed4d347844b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
