{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea115d51-1e79-4b7c-823c-bdf893acc69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b085596-462a-4b2a-bd55-dbca435e3561",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai==1.3.4 in /usr/local/lib/python3.10/dist-packages (1.3.4)\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.3.4) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.3.4) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.3.4) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.3.4) (1.10.13)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.3.4) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai==1.3.4) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai==1.3.4) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai==1.3.4) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai==1.3.4) (1.2.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.3.4) (2022.12.7)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.3.4) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.3.4) (0.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: arxiv==2.1.0 in /usr/local/lib/python3.10/dist-packages (2.1.0)\n",
      "Requirement already satisfied: feedparser==6.0.10 in /usr/local/lib/python3.10/dist-packages (from arxiv==2.1.0) (6.0.10)\n",
      "Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (from arxiv==2.1.0) (2.31.0)\n",
      "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.10/dist-packages (from feedparser==6.0.10->arxiv==2.1.0) (1.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->arxiv==2.1.0) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->arxiv==2.1.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->arxiv==2.1.0) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->arxiv==2.1.0) (2022.12.7)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: duckduckgo-search==4.4 in /usr/local/lib/python3.10/dist-packages (4.4)\n",
      "Requirement already satisfied: docstring-inheritance>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search==4.4) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search==4.4) (8.1.7)\n",
      "Requirement already satisfied: curl-cffi>=0.6.0b7 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search==4.4) (0.6.3b1)\n",
      "Requirement already satisfied: lxml>=4.9.3 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search==4.4) (4.9.4)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search==4.4) (1.6.0)\n",
      "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from curl-cffi>=0.6.0b7->duckduckgo-search==4.4) (1.16.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from curl-cffi>=0.6.0b7->duckduckgo-search==4.4) (2022.12.7)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12.0->curl-cffi>=0.6.0b7->duckduckgo-search==4.4) (2.21)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pdfplumber in /usr/local/lib/python3.10/dist-packages (0.11.0)\n",
      "Requirement already satisfied: pdfminer.six==20231228 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (20231228)\n",
      "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (9.3.0)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (4.28.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (2.1.1)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (41.0.7)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.21)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# !pip install openai==1.2.3\n",
    "!pip install openai==1.3.4\n",
    "!pip3 install arxiv==2.1.0\n",
    "!pip install -U duckduckgo-search==4.4\n",
    "\n",
    "!pip install python-dotenv tiktoken\n",
    "!pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b75d57c-a97c-4ceb-91d0-a972d89e25a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "class Timer:\n",
    "    def __init__(self, logger=None, format_str=\"{:.3f}[s]\", prefix=None, suffix=None, sep=\" \"):\n",
    "\n",
    "        if prefix: format_str = str(prefix) + sep + format_str\n",
    "        if suffix: format_str = format_str + sep + str(suffix)\n",
    "        self.format_str = format_str\n",
    "        self.logger = logger\n",
    "        self.start = None\n",
    "        self.end = None\n",
    "\n",
    "    @property\n",
    "    def duration(self):\n",
    "        if self.end is None:\n",
    "            return 0\n",
    "        return self.end - self.start\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.start = time()\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        self.end = time()\n",
    "        out_str = self.format_str.format(self.duration)\n",
    "        if self.logger:\n",
    "            self.logger.info(out_str)\n",
    "        else:\n",
    "            print(out_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55c5901a-0961-4108-b1c2-a482dd7e2f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "from time import time\n",
    "\n",
    "class Timer:\n",
    "    \"\"\"処理時間を表示するクラス\n",
    "    with Timer(prefix=f'pred cv={i}'):\n",
    "        y_pred_i = predict(model, loader=test_loader)\n",
    "    \n",
    "    with Timer(prefix='fit fold={} '.format(i)):\n",
    "        clf.fit(x_train, y_train, \n",
    "                eval_set=[(x_valid, y_valid)],  \n",
    "                early_stopping_rounds=100,\n",
    "                verbose=verbose)\n",
    "\n",
    "    with Timer(prefix='fit fold={} '.format(i), verbose=500):\n",
    "        clf.fit(x_train, y_train, \n",
    "                eval_set=[(x_valid, y_valid)],  \n",
    "                early_stopping_rounds=100,\n",
    "                verbose=verbose)\n",
    "    \"\"\"\n",
    "    def __init__(self, logger=None, format_str='{:.3f}[s]', prefix=None, suffix=None, sep=' ', verbose=0):\n",
    "\n",
    "        if prefix: format_str = str(prefix) + sep + format_str\n",
    "        if suffix: format_str = format_str + sep + str(suffix)\n",
    "        self.format_str = format_str\n",
    "        self.logger = logger\n",
    "        self.start = None\n",
    "        self.end = None\n",
    "        self.verbose = verbose\n",
    "\n",
    "    @property\n",
    "    def duration(self):\n",
    "        if self.end is None:\n",
    "            return 0\n",
    "        return self.end - self.start\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.start = time()\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        self.end = time()\n",
    "        out_str = self.format_str.format(self.duration)\n",
    "        if self.logger:\n",
    "            self.logger.info(out_str)\n",
    "        else:\n",
    "            print(out_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f160c11-8fbe-429f-a134-61a213f163bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "import pdfplumber\n",
    "from openai import OpenAI\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "import arxiv\n",
    "import datetime as dt\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed525556-b987-41a9-9178-87ab0baeab11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_NAME = \"gpt-3.5-turbo-0125\"\n",
    "# MODEL_NAME = \"gpt-3.5-turbo-instruct\"\n",
    "MODEL_NAME = \"gpt-4-0125-preview\"\n",
    "TEMPERATURE = 0.7\n",
    "# OpenAIクライアントの初期化\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aec15818-d645-49b4-bd32-f1ab5d0ca14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_research_questions_and_purpose_with_gpt(objective, num_questions, client):\n",
    "    # プランナーエージェント: 研究目的から研究質問と検索文字列を生成します\n",
    "    # Construct the prompt dynamically\n",
    "    prompt_content = f\"You are a helpful assistant capable of generating research questions along with their purposes for a systematic literature review.\\n\"\n",
    "    prompt_content = f\"Given the research objective: '{objective}', generate {num_questions} distinct research questions, each followed by its specific purpose. 'To examine', or 'To investigate'.\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        # model=\"gpt-3.5-turbo\",\n",
    "        model=\"gpt-3.5-turbo-0125\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant capable of generating research questions along with their purposes for a systematic literature review.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt_content}\n",
    "        ],\n",
    "        # response_format={ \"type\": \"json_object\" },\n",
    "        temperature=TEMPERATURE,\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    return {\"research_questions\": result}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5a9431f-c898-41de-b521-7f911b820616",
   "metadata": {},
   "outputs": [],
   "source": [
    "objective = \"RAG Evaluation Methods\"\n",
    "# objective = \"RAG検証方法\"\n",
    "\n",
    "num_questions = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f35b655-bfb3-4e33-b63d-b2a9ad53cd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'research_questions': 'Research Question 1: What are the existing methods for evaluating RAG (Red, Amber, Green) status in project management?\\nPurpose: To examine the different evaluation techniques and approaches used to assess RAG status in project management and identify their strengths and limitations.\\n\\nResearch Question 2: How do different industries utilize RAG evaluation methods in project management?\\nPurpose: To investigate the application of RAG evaluation methods across various industries and determine any sector-specific adaptations or best practices.\\n\\nResearch Question 3: What are the key factors influencing the accuracy and reliability of RAG evaluations in project management?\\nPurpose: To examine the factors that impact the precision and dependability of RAG assessments in project management and suggest potential strategies for improvement.\\n\\nResearch Question 4: How do stakeholders perceive the effectiveness of RAG evaluation methods in project management?\\nPurpose: To investigate the perspectives and feedback of project stakeholders on the utility and efficacy of RAG evaluation methods to enhance project monitoring and decision-making processes.\\n\\nResearch Question 5: What are the emerging trends and advancements in RAG evaluation methods for project management?\\nPurpose: To explore the latest developments and innovations in RAG evaluation techniques and tools within project management practices and identify potential areas for future research and application.'}\n"
     ]
    }
   ],
   "source": [
    "questions_and_purposes = generate_research_questions_and_purpose_with_gpt(objective, num_questions, client)\n",
    "print(questions_and_purposes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7692df6a-846b-40ad-a0fa-e254501225c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research Question 1: What are the existing methods for evaluating RAG (Red, Amber, Green) status in project management?\n",
      "Purpose: To examine the different evaluation techniques and approaches used to assess RAG status in project management and identify their strengths and limitations.\n",
      "\n",
      "Research Question 2: How do different industries utilize RAG evaluation methods in project management?\n",
      "Purpose: To investigate the application of RAG evaluation methods across various industries and determine any sector-specific adaptations or best practices.\n",
      "\n",
      "Research Question 3: What are the key factors influencing the accuracy and reliability of RAG evaluations in project management?\n",
      "Purpose: To examine the factors that impact the precision and dependability of RAG assessments in project management and suggest potential strategies for improvement.\n",
      "\n",
      "Research Question 4: How do stakeholders perceive the effectiveness of RAG evaluation methods in project management?\n",
      "Purpose: To investigate the perspectives and feedback of project stakeholders on the utility and efficacy of RAG evaluation methods to enhance project monitoring and decision-making processes.\n",
      "\n",
      "Research Question 5: What are the emerging trends and advancements in RAG evaluation methods for project management?\n",
      "Purpose: To explore the latest developments and innovations in RAG evaluation techniques and tools within project management practices and identify potential areas for future research and application.\n"
     ]
    }
   ],
   "source": [
    "print(questions_and_purposes['research_questions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ae4b29c-a23f-4188-9d87-42d417d6de76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_search_strings(content):\n",
    "    possible_operators = ['AND', 'OR', 'NOT', '\"']\n",
    "    search_strings = []\n",
    "    for line in content.split('\\n'):\n",
    "        if any(op in line for op in possible_operators):\n",
    "            search_strings.append(line.strip())  # strip()を追加して余分な空白を削除\n",
    "    return search_strings if search_strings else [content]\n",
    "\n",
    "def generate_search_string_with_gpt(objective, research_questions, client):\n",
    "    # 生成された検索文字列を使用して学術データベースをクエリし、関連論文の初期セットを取得します。\n",
    "    # Removed the explicit instruction for logical operators\n",
    "    combined_prompt = f\"Given the research objective: '{objective}', and the following research questions: {research_questions['research_questions']}, generate two concise search string for identifying relevant literature for literature review.Do not include OR. Use AND if needed.\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        # model=\"gpt-3.5-turbo\",\n",
    "        model=\"gpt-3.5-turbo-0125\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": combined_prompt}\n",
    "        ],\n",
    "        # response_format={ \"type\": \"json_object\" },\n",
    "        temperature=TEMPERATURE,\n",
    "    )\n",
    "    \n",
    "    content = response.choices[0].message.content\n",
    "    search_string = extract_search_strings(content)\n",
    "    return search_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23dbb875-c96c-4fa6-9402-6bf362bc7cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Search String 1: (\"evaluating RAG status\" OR \"RAG evaluation methods\") AND (\"project management\" OR \"project monitoring\")', 'Search String 2: (\"RAG evaluation methods\" OR \"Red Amber Green assessment techniques\") AND (\"industry applications\" OR \"sector-specific adaptations\")']\n"
     ]
    }
   ],
   "source": [
    "generate_search_string = generate_search_string_with_gpt(objective, questions_and_purposes, client)\n",
    "print(generate_search_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ae357bc-0f53-4882-b597-c2e9a34223ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # キーワードの入力\n",
    "# search_strings = [\n",
    "#     '\"Risk Assessment and Governance evaluation methods\"',\n",
    "#     '\"Organizations measure success outcomes Risk Assessment Governance initiatives\"'\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a8ef8b1-d239-4904-8715-75b2f947c028",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM = \"\"\"\n",
    "### 指示 ###\n",
    "論文の内容を理解した上で，重要なポイントを箇条書きで3点書いてください。\n",
    "\n",
    "### 箇条書きの制約 ###\n",
    "- 最大3個\n",
    "- 日本語\n",
    "- 箇条書き1個を50文字以内\n",
    "\n",
    "### 対象とする論文の内容 ###\n",
    "{text}\n",
    "\n",
    "### 出力形式 ###\n",
    "タイトル(和名)\n",
    "\n",
    "- 箇条書き1\n",
    "- 箇条書き2\n",
    "- 箇条書き3\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7ead26b-91ce-4e35-bf5b-8d7c36e921c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arXivの更新頻度を加味して、365日前の論文を検索\n",
    "N_DAYS =365\n",
    "\n",
    "MAX_RESULT = 10  # 取得する論文数の上限\n",
    "# MODEL_NAME = \"gpt-3.5-turbo-0613\"\n",
    "# MODEL_NAME = \"gpt-3.5-turbo-1106\"\n",
    "MODEL_NAME = \"gpt-3.5-turbo-0125\"\n",
    "\n",
    "# MODEL_NAME = \"gpt-3.5-turbo-instruct\"\n",
    "TEMPERATURE = 0.7\n",
    "# OpenAIクライアントの初期化\n",
    "client = OpenAI()\n",
    "\n",
    "# テンプレートを用意\n",
    "QUERY_TEMPLATE = '%28 ti:%22{}%22 OR abs:%22{}%22 %29 AND submittedDate: [{} TO {}]'\n",
    "\n",
    "# 検索を行い、結果を取得する関数\n",
    "def search_arxiv(keyword):\n",
    "    # Construct the default API client.\n",
    "    client = arxiv.Client()\n",
    "    # 2日前からN_DAYS前までの論文を検索\n",
    "    today = dt.datetime.today() - dt.timedelta(days=2)\n",
    "    # today = dt.datetime.today()\n",
    "    \n",
    "    base_date = today - dt.timedelta(days=N_DAYS)\n",
    "    query = QUERY_TEMPLATE.format(keyword, keyword, base_date.strftime(\"%Y%m%d%H%M%S\"), today.strftime(\"%Y%m%d%H%M%S\"))\n",
    "\n",
    "    search = arxiv.Search(\n",
    "        query=query,\n",
    "        max_results=MAX_RESULT,\n",
    "        sort_by=arxiv.SortCriterion.SubmittedDate,\n",
    "        sort_order=arxiv.SortOrder.Descending,\n",
    "    )\n",
    "\n",
    "    results = client.results(search)\n",
    "    return results\n",
    "\n",
    "# 論文の要約を取得する関数\n",
    "def get_summary(result):\n",
    "    text = f\"title: {result.title}\\nbody: {result.summary}\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\" : \"system\", \"content\" : SYSTEM},\n",
    "        {\"role\": \"user\", \"content\": text}\n",
    "    ]\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages=messages,\n",
    "        temperature=TEMPERATURE,\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0644d259-87e3-4e19-bac4-b5b17dc5837c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def simplify_search_queries(complex_queries):\n",
    "    simplified_queries = []\n",
    "\n",
    "    for query in complex_queries:\n",
    "        # 数字とピリオドを除去して、クエリの本体だけを抽出\n",
    "        clean_query = re.sub(r'^\\d+\\.\\s*', '', query)\n",
    "        \n",
    "        # 括弧を除去\n",
    "        clean_query = re.sub(r'[()\"]', '', clean_query)\n",
    "        \n",
    "        # 'AND' と 'OR' で分割\n",
    "        split_queries = re.split(r'\\sAND\\s|\\sOR\\s', clean_query)\n",
    "        \n",
    "        # 分割したクエリをリストに追加\n",
    "        for sub_query in split_queries:\n",
    "            sub_query = sub_query.strip()\n",
    "            if sub_query and sub_query not in simplified_queries:\n",
    "                simplified_queries.append(sub_query)\n",
    "                \n",
    "    return simplified_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd6c9c87-d991-4b65-af2e-510d219975cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search_String_1:_evaluating_RAG_status\n",
      "RAG_evaluation_methods\n",
      "project_management\n",
      "project_monitoring\n",
      "Search_String_2:_RAG_evaluation_methods\n",
      "Red_Amber_Green_assessment_techniques\n",
      "industry_applications\n",
      "sector-specific_adaptations\n"
     ]
    }
   ],
   "source": [
    "simplified_queries = simplify_search_queries(generate_search_string)\n",
    "# 複数の単語の間のスペースをハイフンに置換\n",
    "# modified_queries = [query.replace(\" \", \"\") for query in simplified_queries]\n",
    "modified_queries = [query.replace(\" \", \"_\") for query in simplified_queries]\n",
    "# modified_queries = [query.split(\" \") for query in simplified_queries]\n",
    "\n",
    "for query in modified_queries:\n",
    "    print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc1d1b75-4d59-4b64-8efe-8d30a8402729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Search String 1: evaluating RAG status',\n",
       " 'RAG evaluation methods',\n",
       " 'project management',\n",
       " 'project monitoring',\n",
       " 'Search String 2: RAG evaluation methods',\n",
       " 'Red Amber Green assessment techniques',\n",
       " 'industry applications',\n",
       " 'sector-specific adaptations']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simplified_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f040ae97-b03e-43ce-8e2f-85e4928c35a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search String 1: evaluating RAG status\n",
      "\n",
      "Holo-Relighting: Controllable Volumetric Portrait Relighting from a Single Image\n",
      "ホロ・リライティング: 単一画像から制御可能なボリューメトリックポートレートのリライティング\n",
      "\n",
      "- 単一画像から新しい視点と照明を合成可能\n",
      "- ヘッドポーズに依存した照明効果の生成\n",
      "- 物理的な照明の事前知識なしで非ランバート照明効果を生成\n",
      "http://arxiv.org/abs/2403.09632v1\n",
      "\n",
      "Generating functional of correlators of twist-$2$ operators in $\\mathcal{N} = 1$ SUSY Yang-Mills theory, I\n",
      "$\\mathcal{N} = 1$ SUSY Yang-Mills理論におけるtwist-$2$演算子の相関関数の生成汎関数\n",
      "\n",
      "- twist-$2$演算子の相関関数の生成汎関数を計算\n",
      "- 大$N$展開のleadingとnext-to-leading orderで計算\n",
      "- 非摂動解への強いUV漸近制約を設定\n",
      "http://arxiv.org/abs/2403.09617v1\n",
      "\n",
      "pARam: Leveraging Parametric Design in Extended Reality to Support the Personalization of Artifacts for Personal Fabrication\n",
      "pARam: パラメトリックデザインを拡張現実に活用して、個人製作用のアーティファクトのパーソナライゼーションをサポートする\n",
      "\n",
      "- 拡張現実とパラメトリックデザインを組み合わせたpARamは、複雑な3Dモデリングの必要性を排除し、ジェスチャーや照明推定などの実践的な入力を通じて、個人製作のためのアーティファクトのインタラクティブな構成を可能にする。\n",
      "- pARamを使用したユーザーは、コンテキストに関連するパラメータを選択し、環境を考慮して設定を行うことに成功し、その効果を示した。\n",
      "- パラメトリックデザインの拡張現実における活用は、個人製作のための複雑なデザイン手法を合理化する一方、適切な表現性を保持する上での見通しと課題について示唆している。\n",
      "http://arxiv.org/abs/2403.09607v1\n",
      "\n",
      "Multi-Fidelity Bayesian Optimization With Across-Task Transferable Max-Value Entropy Search\n",
      "多重信頼性ベイズ最適化において、将来のタスクにも適用可能な新しい情報理論的取得関数が導入された。\n",
      "\n",
      "- 多重信頼性ブラックボックス最適化戦略は、最適な値や解に関する情報を最大化することを目的としている。\n",
      "- 未来のタスクに適用可能な情報を収集する必要性と現在のタスクに関する情報を取得する必要性をバランスさせる。\n",
      "- 提案手法は、未来のタスクに対応するための取得戦略を含み、最適化効率を大幅に改善できることが示された。\n",
      "http://arxiv.org/abs/2403.09570v1\n",
      "\n",
      "A perturbative approach to the non-relativistic string spectrum\n",
      "A非相対論的な文字列のスペクトルに対する摂動論的アプローチ\n",
      "\n",
      "- 非相対論的文字列のスペクトルを見つけるために摂動論的手法を使用\n",
      "- アクションのボソンセクターを摂動し、BMN様の折り畳まれた文字列解を考える\n",
      "- 相互作用項がフィールド再定義により消失し、AdSバックグラウンドでの質量と質量なしの自由場の組み合わせで記述されることを示す\n",
      "http://arxiv.org/abs/2403.09563v1\n",
      "\n",
      "A targeted radio pulsar survey of redback candidates with MeerKAT\n",
      "タイトル：MeerKATを用いたレッドバック候補のターゲテッドな電波パルサー調査\n",
      "\n",
      "- レッドバック候補のうち3つの新たな電波ミリ秒パルサーを発見\n",
      "- レッドバック候補の1つが長期間にわたり電波放射を吸収することが確認され、その対象の移り変わりを明らかに\n",
      "- 電波タイミングによって、3つのパルサーからガンマ線パルスが検出され、15年間のタイミング解が得られる\n",
      "http://arxiv.org/abs/2403.09553v1\n",
      "\n",
      "How do Machine Learning Projects use Continuous Integration Practices? An Empirical Study on GitHub Actions\n",
      "機械学習プロジェクトにおける継続的インテグレーションの実践について：GitHub Actionsに関する実証的研究\n",
      "\n",
      "- MLプロジェクトは通常よりも長いビルド時間を必要とし、中規模のMLプロジェクトは非MLプロジェクトよりも低いテストカバレッジを示す。\n",
      "- 小規模および中規模のMLプロジェクトは、非MLプロジェクトと比較してビルド時間が増加する傾向が高い。\n",
      "- MLプロジェクトにおけるCIの実践に関する定性的分析では、CIビルド実行と状態、CIテスト、CIインフラストラクチャなどのテーマが含まれる。\n",
      "http://arxiv.org/abs/2403.09547v1\n",
      "\n",
      "Artificial Bugs for Crowdsearch\n",
      "人工バグによるクラウドサーチ(和名)\n",
      "\n",
      "- バグ報奨金プログラムに人工バグを挿入することで、本物のバグを探すインセンティブを高める\n",
      "- 人工バグは1つ挿入するだけで効率的な利益をもたらす\n",
      "- デザイナーが本物のバグを見つけることに高い評価を置く場合や、予算が不十分な場合に特に有益\n",
      "http://arxiv.org/abs/2403.09484v1\n",
      "\n",
      "Edge-apexing in hereditary classes of graphs\n",
      "エッジ-エーペキシングにおけるグラフの世代的クラス\n",
      "\n",
      "- エッジ-エーペキシングは、クラス$\\mathcal{G}$が禁止された誘導部分グラフを有限個持つ場合、エーペックスからの距離が1以下のグラフのクラス$G^{epex}$も有限個の禁止誘導部分グラフを持つことを示す。\n",
      "- コーグラフの世代的クラスは、補集合と直和から生成されるすべてのグラフからなる。エッジ-エーペキシングコーグラフの禁止誘導部分グラフの個数は8に制限され、コンピュータ検索によってそれらのすべてが見つかる。\n",
      "http://arxiv.org/abs/2403.09456v1\n",
      "\n",
      "Search for Higgs boson pair production in the bbWW decay mode in proton-proton collisions at $\\sqrt{s}$ = 13 TeV\n",
      "ヒッグス粒子対生成の検索: $bbWW$崩壊モードにおける13 TeVプロトン-プロトン衝突\n",
      "\n",
      "- HH生成断面積の上限値が標準模型の予測値の14(18)倍となり、非共鳴HH生成の断面積に制限を設定。\n",
      "- ヒッグス粒子結合変調子や異常ヒッグス粒子結合シナリオに関する断面積の制限値を提示。\n",
      "- 質量範囲250-900 GeVのスピン0およびスピン2共鳴を介したHH生成に対する制限を設定。\n",
      "http://arxiv.org/abs/2403.09430v1\n",
      "--------------------------------------------------\n",
      "RAG evaluation methods\n",
      "\n",
      "SCP-Diff: Photo-Realistic Semantic Image Synthesis with Spatial-Categorical Joint Prior\n",
      "SCP-Diff: 空間カテゴリー共同事前分布を用いた写真実在的な意味画像合成\n",
      "\n",
      "- 現在の最良手法であるGANに基づくSemantic image synthesis (SIS) は、望ましい品質レベルにまだ達していない。\n",
      "- ControlNetの結果には、大きな意味領域内の奇妙なサブ構造の存在と、内容が意味マスクとの整合性が欠けるという2つの主要な問題がある。\n",
      "- SCP-Diffは、空間、カテゴリー、そして新しい空間カテゴリー共同事前分布を含むSIS向けの特定のノイズ事前分布を開発し、その結果、CityscapesでFID 10.53、ADE20Kで12.66を達成した。\n",
      "http://arxiv.org/abs/2403.09638v1\n",
      "\n",
      "GaussianGrasper: 3D Language Gaussian Splatting for Open-vocabulary Robotic Grasping\n",
      "GaussianGrasper: 3D言語ガウス散乱を用いたロボットの掴むためのオープンボキャブラリー\n",
      "\n",
      "- 3Dシーンをガウスプリミティブのコレクションとして明示的に表現する\n",
      "- Efficient Feature Distillation (EFD)モジュールによる言語埋め込みの効率的な抽出\n",
      "- ノーマルに誘導された掴むモジュールを使用して最適な掴む姿勢を選択\n",
      "http://arxiv.org/abs/2403.09637v1\n",
      "\n",
      "Dynamic Memory Compression: Retrofitting LLMs for Accelerated Inference\n",
      "動的メモリ圧縮：高速推論のためのLLMの後付け\n",
      "\n",
      "- Dynamic Memory Compression (DMC)はオンラインのキー・バリューキャッシュ圧縮を提案\n",
      "- DMCは異なるヘッドやレイヤーで異なる圧縮率を適用することを学習\n",
      "- DMCは元のダウンストリームパフォーマンスを保持しつつ、最大4倍のキャッシュ圧縮を実現\n",
      "http://arxiv.org/abs/2403.09636v1\n",
      "\n",
      "OneTracker: Unifying Visual Object Tracking with Foundation Models and Efficient Tuning\n",
      "OneTracker: Foundationモデルと効率的なチューニングで視覚オブジェクトトラッキングを統合\n",
      "\n",
      "- 視覚オブジェクトトラッキングは、初期フレームでの外観に基づいて各フレームの対象オブジェクトをローカライズすることを目指す。\n",
      "- OneTrackerは、Foundation TrackerとPrompt Trackerから構成され、他のモデルを凌駕し、最先端のパフォーマンスを達成。\n",
      "- OneTrackerは、大規模なプリトレーニングを行い、安定した能力を持つFoundation Trackerを構築し、パラメーター効率の良いファインチューニングを実現。\n",
      "http://arxiv.org/abs/2403.09634v1\n",
      "\n",
      "Holo-Relighting: Controllable Volumetric Portrait Relighting from a Single Image\n",
      "Holo-Relighting: 単一画像からの制御可能な体積的ポートレート・リライティング\n",
      "\n",
      "- Holo-Relightingは単一画像から新しい視点と照明を合成できる。\n",
      "- EG3Dを活用して、３次元のジオメトリと外観を復元する。\n",
      "- ホロ・リライティングは、照明、視点、ヘッドポーズを制御可能にする。\n",
      "http://arxiv.org/abs/2403.09632v1\n",
      "\n",
      "Quiet-STaR: Language Models Can Teach Themselves to Think Before Speaking\n",
      "Quiet-STaR: 言語モデルは話す前に考えることを自己学習できる\n",
      "\n",
      "- STaRでは少数の例から合理的思考を学ぶが、Quiet-STaRは任意のテキストで合理的思考を推論する\n",
      "- LMが内部思考を生成・使用する方法を学ぶ課題を解決し、難しいトークンの予測精度向上に貢献\n",
      "- Internetテキストでの事前学習後、GSM8KやCommonsenseQAでゼロショットで改善し、難しいトークンのperplexityも向上\n",
      "http://arxiv.org/abs/2403.09629v1\n",
      "\n",
      "Video Mamba Suite: State Space Model as a Versatile Alternative for Video Understanding\n",
      "動画理解におけるState Space Modelの重要性\n",
      "\n",
      "- State Space Model(Mamba)は長いシーケンスのモデリングに成功しており、動画モデリングにも有望な特性を示す。\n",
      "- MambaはTransformersに代わる動画理解の選択肢として優れている可能性がある。\n",
      "- Mambaは動画専用および動画-言語タスクの両方で強力な潜在能力を示し、効率性と性能のトレードオフも期待される。\n",
      "http://arxiv.org/abs/2403.09626v1\n",
      "\n",
      "Make-Your-3D: Fast and Consistent Subject-Driven 3D Content Generation\n",
      "Make-Your-3D: 3Dコンテンツの迅速で一貫性のある主題駆動生成\n",
      "\n",
      "- 既存の3D生成手法では、異なるプロンプト間で主題駆動の3Dコンテンツを生成することが難しい。\n",
      "- Make-Your-3Dは、単一の画像とテキスト記述からわずか5分で高品質かつ一貫した3Dコンテンツを個人化できる。\n",
      "- 著者らの手法は、主題に合った分布への調整を行い、未知の主題画像からのテキスト駆動変更が可能。\n",
      "http://arxiv.org/abs/2403.09625v1\n",
      "\n",
      "Score-Guided Diffusion for 3D Human Recovery\n",
      "Score-Guided Diffusion for 3D Human Recovery\n",
      "\n",
      "- 3D人体ポーズと形状再構築のための逆問題解決手法\n",
      "- 画像観測に人体モデルを適合させるが、スコアガイダンスによって逆問題を解決\n",
      "- ScoreHMRは最適化手法に比べて、3つの設定/アプリケーションで優れた性能を示す\n",
      "http://arxiv.org/abs/2403.09623v1\n",
      "\n",
      "Glyph-ByT5: A Customized Text Encoder for Accurate Visual Text Rendering\n",
      "カスタマイズされたテキストエンコーダーによる正確な視覚テキストレンダリング\n",
      "\n",
      "- テキストエンコーダーの不足による視覚テキストレンダリングの課題\n",
      "- Glyph-ByT5の開発により、デザイン画像生成におけるテキストレンダリングの正確性が大幅に向上\n",
      "- Glyph-SDXLモデルの登場により、自動多行レイアウトでの高いスペル精度を実現\n",
      "http://arxiv.org/abs/2403.09622v1\n",
      "--------------------------------------------------\n",
      "project management\n",
      "\n",
      "SCP-Diff: Photo-Realistic Semantic Image Synthesis with Spatial-Categorical Joint Prior\n",
      "SCP-Diff: 空間カテゴリー共同事前分布を用いた写真リアルな意味画像合成\n",
      "\n",
      "- 現在の最高水準であるGANに基づくSISは、望ましい品質には至っていない。\n",
      "- ControlNetの結果には、大きな意味領域内の奇妙なサブ構造と意味マスクとのコンテンツの不一致がある。\n",
      "- SCP-Diffは、特定のノイズ事前分布を開発し、優れた成果を上げている。\n",
      "http://arxiv.org/abs/2403.09638v1\n",
      "\n",
      "3D-VLA: A 3D Vision-Language-Action Generative World Model\n",
      "3D-VLA: 3D Vision-Language-Action Generative World Model\n",
      "\n",
      "- 2D入力に頼らず、3D世界との統合を実現する\n",
      "- 3D知覚、推論、アクションを結びつける\n",
      "- 実世界の計画における理由付け、多様な生成、計画能力を向上\n",
      "http://arxiv.org/abs/2403.09631v1\n",
      "\n",
      "Make-Your-3D: Fast and Consistent Subject-Driven 3D Content Generation\n",
      "Make-Your-3D: 高速で一貫した主題駆動の3Dコンテンツ生成\n",
      "\n",
      "- 既存の3D生成手法では、異なるプロンプトを使って主題駆動の3Dコンテンツを生成するのが難しい\n",
      "- Make-Your-3Dは、一枚の画像とテキストの説明から5分以内で高品質で一貫性のある3Dコンテンツを作成する\n",
      "- マルチビューディフュージョンモデルと特定の2D生成モデルの分布を調和させ、望ましい3D主題の分布に合わせる\n",
      "http://arxiv.org/abs/2403.09625v1\n",
      "\n",
      "Score-Guided Diffusion for 3D Human Recovery\n",
      "Score-Guided Diffusionによる3D人体復元\n",
      "\n",
      "- 画像観測に対するスコア誘導により、拡散モデルの潜在空間でモデルと画像の整合を達成。\n",
      "- 画像からの人体モデルパラメータの条件付き分布を捉えた拡散モデルを使用。\n",
      "- ScoreHMRは再トレーニング不要で逆問題を解決し、3つの応用設定で最適化手法を凌駕する。\n",
      "http://arxiv.org/abs/2403.09623v1\n",
      "\n",
      "PosSAM: Panoptic Open-vocabulary Segment Anything\n",
      "PosSAM: Panoptic Open-vocabulary Segment Anything\n",
      "\n",
      "- SAMの制限を解決するために、PosSAMはLDPモジュールとMASEアルゴリズムを提案\n",
      "- PosSAMはSAMとCLIPの特徴を組み合わせ、高い汎化性能を実現\n",
      "- COCO to ADE20KとADE20K to COCOの両方で、既存手法を大幅に上回る性能\n",
      "http://arxiv.org/abs/2403.09620v1\n",
      "\n",
      "PrompTHis: Visualizing the Process and Influence of Prompt Editing during Text-to-Image Creation\n",
      "PrompTHis: テキストから画像への生成過程とプロンプト編集の影響を可視化\n",
      "\n",
      "- プロンプト編集の過程を可視化するためのImage Variant Graphの提案\n",
      "- ユーザーがプロンプト履歴を通じて探索し、プロンプト変更が出力画像に与える影響を理解\n",
      "- PrompTHisはプロンプト履歴のレビューと分析を通じて、ユーザーが出力画像の生成を効果的に制御\n",
      "http://arxiv.org/abs/2403.09615v1\n",
      "\n",
      "Network-Controlled Repeater -- An Introduction\n",
      "ネットワーク制御中継器--導入\n",
      "\n",
      "- 5Gネットワークでは、ミリ波スペクトルがスループット、信頼性、遅延などの向上をもたらすが、ブロッキングの影響も高まり、カバレッジを制限する課題も。\n",
      "- ネットワーク制御中継器(NCR)は、カバレッジ問題を克服する手法として低複雑性のネットワークノードであり、適切なネットワーク計画とビームフォーミング設計により、BSの死角をカバーする魅力的な解決策となる。\n",
      "- 3GPP Rel-18で合意されたNCRの主要仕様を提示し、都市シナリオでの異なるNCR展開を分析し、その性能を他の展開と比較。\n",
      "http://arxiv.org/abs/2403.09601v1\n",
      "\n",
      "DungeonMaker: Embedding Tangible Creation and Destruction in Hybrid Board Games through Personal Fabrication Technology\n",
      "DungeonMaker: ハイブリッドボードゲームにおける物質的な創造と破壊を個人製作技術を通じて組み込む\n",
      "\n",
      "- DungeonMakerは物語を語り、デジタルゲームボードをレーザーカッターに投影する。\n",
      "- プレイヤーが作成したアーティファクトを評価する。\n",
      "- レーザーがプレイヤーや非プレイヤーのフィギュアを移動させ、物理的に損傷させる。\n",
      "http://arxiv.org/abs/2403.09592v1\n",
      "\n",
      "Are you a robot? Detecting Autonomous Vehicles from Behavior Analysis\n",
      "ロボットかどうかを検出するための行動分析から自律車両を特定\n",
      "\n",
      "- 自律車両と人間運転車両を自動的に識別する必要性\n",
      "- カメラ画像と状態情報を活用して自律車両を特定するフレームワークの提案\n",
      "- 動画クリップの分析により自律車両を80%の精度で識別可能であり、状態情報がある場合には93%まで向上\n",
      "http://arxiv.org/abs/2403.09571v1\n",
      "\n",
      "PaperBot: Learning to Design Real-World Tools Using Paper\n",
      "PaperBot: 紙を使用して実世界のツールを設計する方法を学習する\n",
      "\n",
      "- 紙を使用し、ツールを設計・使用する方法を直接学習するアプローチ\n",
      "- 紙飛行機の最大飛行距離や最大把持力を持つペーパーグリッパーを学習する\n",
      "- 折りたたみ、切断、ダイナミックな操作を組み合わせてツールの設計・使用を最適化\n",
      "http://arxiv.org/abs/2403.09566v1\n",
      "--------------------------------------------------\n",
      "project monitoring\n",
      "\n",
      "SCP-Diff: Photo-Realistic Semantic Image Synthesis with Spatial-Categorical Joint Prior\n",
      "SCP-Diff: 空間-カテゴリー共同事前知識を用いた写真リアルな意味画像合成\n",
      "\n",
      "- GANに基づくSISの品質向上課題\n",
      "- 既存手法の問題点の特定と対応\n",
      "- SCP-Diffの高い性能(FID: 10.53 on Cityscapes, 12.66 on ADE20K)\n",
      "http://arxiv.org/abs/2403.09638v1\n",
      "\n",
      "3D-VLA: A 3D Vision-Language-Action Generative World Model\n",
      "3D-VLA: 3Dビジョン・言語・行動生成ワールドモデル\n",
      "\n",
      "- 3D-VLAは3D知覚、推論、行動をシームレスに結びつけるための新しいモデルを提案する。\n",
      "- 3D-VLAは大規模言語モデルをベースに構築され、生成能力を持つ拡散モデルを導入している。\n",
      "- 3D-VLAは実世界応用において、理論、多様な生成、計画能力を大幅に向上させる実験結果を示している。\n",
      "http://arxiv.org/abs/2403.09631v1\n",
      "\n",
      "Make-Your-3D: Fast and Consistent Subject-Driven 3D Content Generation\n",
      "Make-Your-3D: 主体に基づく3Dコンテンツ生成の高速かつ一貫性のある手法\n",
      "\n",
      "- 既存の3D生成方法では、異なるプロンプト間で主体に基づく3Dコンテンツを作成することが困難である\n",
      "- Make-Your-3Dは、単一の画像とテキスト説明から5分以内で高品質かつ一貫性のある3Dコンテンツを個人化できる\n",
      "- 多視点拡散モデルと特定のアイデンティティに基づく2D生成モデルの分布を調和させ、所望の3D主体の分布と整合させる\n",
      "http://arxiv.org/abs/2403.09625v1\n",
      "\n",
      "Score-Guided Diffusion for 3D Human Recovery\n",
      "Score-Guided Diffusionによる3D人物復元\n",
      "\n",
      "- 3D人物ポーズと形状再構築の逆問題を解決するためのScoreHMRアプローチ\n",
      "- 画像観測に人体モデルを適合させる逆問題を、拡散モデルの潜在空間でスコアガイドを用いて解決\n",
      "- ScoreHMRは画像観測との整合性を拡散モデルの潜在空間でスコアガイダンスによって実現\n",
      "http://arxiv.org/abs/2403.09623v1\n",
      "\n",
      "PosSAM: Panoptic Open-vocabulary Segment Anything\n",
      "PosSAM: Panoptic Open-vocabulary Segment Anything\n",
      "\n",
      "- SAMとCLIPを統合したPosSAMは、空間的マスク生成と物体クラス認識の両方に優れ、オーバーセグメンテーションを軽減する。\n",
      "- LDPモジュールは、SAMとCLIPの特徴を活用し、偏見のないオープンボキャブラリー分類を実現する。\n",
      "- MASEアルゴリズムは、マスクの品質を向上させ、推論時の分類性能を向上させる。\n",
      "http://arxiv.org/abs/2403.09620v1\n",
      "\n",
      "PrompTHis: Visualizing the Process and Influence of Prompt Editing during Text-to-Image Creation\n",
      "PrompTHis: テキストから画像を生成する際のプロンプト編集のプロセスと影響を可視化\n",
      "\n",
      "- プロンプト履歴を可視化するImage Variant Graphは、プロンプトと画像の比較や編集履歴の探索をサポートする。\n",
      "- PrompTHisシステムは、プロンプト履歴のレビューや分析を通じて、ユーザーがプロンプト変更の影響を理解し、画像生成を効果的に制御できるようにする。\n",
      "- ユーザースタディによると、PrompTHisはユーザーがプロンプト履歴を確認し、モデルを理解し、創造プロセスを計画するのに役立つことが示された。\n",
      "http://arxiv.org/abs/2403.09615v1\n",
      "\n",
      "Network-Controlled Repeater -- An Introduction\n",
      "ネットワーク制御リピーターの紹介\n",
      "\n",
      "- 5Gネットワークではミリ波スペクトルを活用し、NCRがカバレッジ問題を解決\n",
      "- 3GPP Rel-18でのNCR仕様を提示し、都市シナリオでの性能を検証\n",
      "- 適切なネットワーク計画とビームフォーミング設計により、NCRはBSの死角をカバー\n",
      "http://arxiv.org/abs/2403.09601v1\n",
      "\n",
      "A comprehensive study of orbital evolution of LMC X-4: Existence of a second derivative of the orbital period\n",
      "論文のタイトル: LMC X-4の軌道進化の包括的研究: 軌道周期の2次導関数の存在\n",
      "\n",
      "- LMC X-4の軌道周期が0.8 Myrの時間スケールで進化していることが示された。\n",
      "- 今回初めて、LMC X-4において軌道周期の2次導関数の存在が確認された。\n",
      "- 中間食時刻データとパルスタイミングデータを使用して得られた軌道進化の独立した解析は一致し、連星系の離心率に0.009の上限を設定した。\n",
      "http://arxiv.org/abs/2403.09595v1\n",
      "\n",
      "DungeonMaker: Embedding Tangible Creation and Destruction in Hybrid Board Games through Personal Fabrication Technology\n",
      "DungeonMaker: ハイブリッドボードゲームにおける物理的創造と破壊の組み込みを通じた個人製作技術\n",
      "\n",
      "- DungeonMakerは物理的要素とデジタルゲーム要素を結びつけ、プレイヤーの作成物を評価する\n",
      "- レーザーカッターにデジタルゲーム盤を投影し、フィギュアを物理的にダメージを与える\n",
      "- 評価結果はDungeonMakerが楽しい体験を提供し、プレイヤーのフィギュアへのつながりをサポートし、製作に興味を持つ可能性を示唆\n",
      "http://arxiv.org/abs/2403.09592v1\n",
      "\n",
      "Are you a robot? Detecting Autonomous Vehicles from Behavior Analysis\n",
      "ロボットかどうかを自動的に検出するためのフレームワーク\n",
      "\n",
      "- 自動車が自律車両かどうかをカメラ画像と状態情報を活用して自動的にプロファイリングする必要性\n",
      "- 車両同士の協力に基づいてデータ共有し、機械学習モデルを用いて自律車両を識別するフレームワークを提案\n",
      "- ビデオクリップの分析により、自動的に80%の精度で自律車両と人間運転車両を識別可能であり、状態情報があれば93%に向上する。\n",
      "http://arxiv.org/abs/2403.09571v1\n",
      "--------------------------------------------------\n",
      "Search String 2: RAG evaluation methods\n",
      "\n",
      "SCP-Diff: Photo-Realistic Semantic Image Synthesis with Spatial-Categorical Joint Prior\n",
      "SCP-Diff: 空間カテゴリー共同事前分布を用いた写真実感的な意味画像合成\n",
      "\n",
      "- 現行の最良手法はGANに基づくが、望ましい品質には至っていない。\n",
      "- ControlNetの結果において主に問題となるのは、奇妙なサブ構造と意味的マスクとの不整合。\n",
      "- SCP-Diffアプローチは、空間、カテゴリー、そして新規な空間-カテゴリー共同事前分布を包括し、優れた結果を達成。\n",
      "http://arxiv.org/abs/2403.09638v1\n",
      "\n",
      "GaussianGrasper: 3D Language Gaussian Splatting for Open-vocabulary Robotic Grasping\n",
      "GaussianGrasper: 3D言語ガウススプラッティングによるオープンボキャブラリー・ロボティックグラスピング\n",
      "\n",
      "- 3Dシーンをガウスプリミティブのコレクションとして表現\n",
      "- Efficient Feature Distillation (EFD)モジュールを提案\n",
      "- ノーマルガイドグラスプモジュールによる最適なグラスプ位置の選択\n",
      "http://arxiv.org/abs/2403.09637v1\n",
      "\n",
      "Dynamic Memory Compression: Retrofitting LLMs for Accelerated Inference\n",
      "動的メモリ圧縮：高速推論のためのLLMの改造\n",
      "\n",
      "- 推論時にオンラインでキー・バリューキャッシュを圧縮する方法\n",
      "- 異なるヘッドやレイヤーで異なる圧縮率を適用することを学習\n",
      "- キャッシュ圧縮率を最大4倍にしても元の性能を維持\n",
      "http://arxiv.org/abs/2403.09636v1\n",
      "\n",
      "OneTracker: Unifying Visual Object Tracking with Foundation Models and Efficient Tuning\n",
      "OneTracker: Foundationモデルと効率的なチューニングでビジュアルオブジェクトトラッキングを統一\n",
      "\n",
      "- 初めにFoundation Trackerで大規模な事前トレーニングを行い、安定した能力を獲得\n",
      "- Prompt TrackerはFoundation Trackerを凍結し、追加のトレーニングパラメータを調整してRGB+Xトラッキングタスクに適したパラメータ効率的なfine-tuningを実現\n",
      "- OneTrackerは他のモデルを凌駕し、11のベンチマークを通じて6つの人気トラッキングタスクで最先端の性能を達成\n",
      "http://arxiv.org/abs/2403.09634v1\n",
      "\n",
      "Holo-Relighting: Controllable Volumetric Portrait Relighting from a Single Image\n",
      "Holo-Relighting: 単一画像からの制御可能なボリューメトリック肖像写真のリライティング\n",
      "\n",
      "- 1枚の画像から新しい視点と照明を合成するボリューメトリックリライティング手法\n",
      "- ヘッドポーズに基づいた照明効果を可能にする条件付きのリライティングモジュール\n",
      "- 物理的な照明の事前知識なしで複雑な非ランバーティアン照明効果を生成\n",
      "http://arxiv.org/abs/2403.09632v1\n",
      "\n",
      "Quiet-STaR: Language Models Can Teach Themselves to Think Before Speaking\n",
      "Quiet-STaR: 言語モデルは話す前に考えることを自己学習できる\n",
      "\n",
      "- STaRでは、質問応答の少ない例から合理的な考え方を学ぶが、Quiet-STaRでは文脈に応じて理由を生成するように学習。\n",
      "- 計算コスト、内部思考の生成方法、個々のトークンを超えた予測の必要性など、主要な課題に対処する。\n",
      "- 無Fine-tuningでGSM8KとCommonsenseQAでゼロショット改善を達成し、自然文の難しいトークンのPerplexityも改善。\n",
      "http://arxiv.org/abs/2403.09629v1\n",
      "\n",
      "Video Mamba Suite: State Space Model as a Versatile Alternative for Video Understanding\n",
      "ビデオ理解における状態空間モデルの汎用的代替手段\n",
      "\n",
      "- ビデオモデリングにおいて、状態空間モデル（Mamba）は長いシーケンスのモデリング成功を拡張する有望な特性を示す。\n",
      "- 14のモデル/モジュールからなるVideo Mamba Suiteを導出し、12のビデオ理解タスクで評価。\n",
      "- Mambaはビデオのみならずビデオ-言語タスクでも強力な潜在能力を示し、有望な効率-性能のトレードオフを示す。\n",
      "http://arxiv.org/abs/2403.09626v1\n",
      "\n",
      "Make-Your-3D: Fast and Consistent Subject-Driven 3D Content Generation\n",
      "Make-Your-3D: 高品質かつ一貫した主題駆動型3Dコンテンツ生成\n",
      "\n",
      "- 既存の3D生成手法では多様なプロンプトを用いた主題駆動型3Dコンテンツの作成が困難である\n",
      "- Make-Your-3Dはたった1枚の画像とテキスト説明から5分以内で高品質かつ一貫した3Dコンテンツを生成する\n",
      "- 著者らの手法は、モデルの分布を調和させることで、高品質で主題に特化した3Dコンテンツを生成可能\n",
      "http://arxiv.org/abs/2403.09625v1\n",
      "\n",
      "Score-Guided Diffusion for 3D Human Recovery\n",
      "Score-Guided Diffusionを用いた3Dヒューマンリカバリー\n",
      "\n",
      "- ScoreHMRは、画像観測に対して得られるスコアのガイダンスを介して、拡散モデルの潜在空間でのアライメントにより、3Dヒューマンポーズと形状の再構築の逆問題を解決する手法。\n",
      "- ScoreHMRは、再トレーニングが不要なタスク非特化の拡散モデルにより、様々なアプリケーションにおける逆問題を効果的に解決する。\n",
      "- ScoreHMRは、シングルフレームモデル適合、複数の非キャリブレーションビューからの再構築、ビデオシーケンス内の人物再構築といった3つの設定/アプリケーションにおいて、人気のベンチマークで最適化ベースラインを常に上回る。\n",
      "http://arxiv.org/abs/2403.09623v1\n",
      "\n",
      "Glyph-ByT5: A Customized Text Encoder for Accurate Visual Text Rendering\n",
      "Glyph-ByT5: 正確な視覚テキストレンダリングのためのカスタマイズテキストエンコーダ\n",
      "\n",
      "- テキストエンコーダに必要な要件: 文字認識とグリフとの整合性\n",
      "- Glyph-ByT5はByT5エンコーダを微調整し、グリフ-テキストのデータセットを使用して作成\n",
      "- Glyph-SDXLモデルの導入により、デザイン画像生成におけるテキストの正確性が飛躍的に向上\n",
      "http://arxiv.org/abs/2403.09622v1\n",
      "--------------------------------------------------\n",
      "Red Amber Green assessment techniques\n",
      "\n",
      "GaussianGrasper: 3D Language Gaussian Splatting for Open-vocabulary Robotic Grasping\n",
      "GaussianGrasper: 3D言語ガウススプラッティングによるオープンボキャブラリーロボットグラスピング\n",
      "\n",
      "- ガウススプラッティングを使用して、シーンをガウス原理の集合として明示的に表現\n",
      "- Efficient Feature Distillation (EFD) モジュールを導入し、効率的かつ正確に言語埋め込みを抽出\n",
      "- リアルワールドの実験により、GaussianGrasperが言語指示による物体掴みを可能にし、新しい解決策を提供\n",
      "http://arxiv.org/abs/2403.09637v1\n",
      "\n",
      "Holo-Relighting: Controllable Volumetric Portrait Relighting from a Single Image\n",
      "Holo-Relighting: 単一画像からの制御可能な体積ポートレート照明\n",
      "\n",
      "- 3D GAN（EG3D）を利用して入力ポートレートからジオメトリと外観を再構築し、3D感知特徴の形で照明を生成する。\n",
      "- 三面体形式のリライト3D表現を予測し、任意の視点にレンダリングできる。\n",
      "- ヘッドポーズに応じたライティング効果を可能にし、物理的なライティング先行知識を使用せずに複雑な非ランバート照明効果を生成できる。\n",
      "http://arxiv.org/abs/2403.09632v1\n",
      "\n",
      "Quiet-STaR: Language Models Can Teach Themselves to Think Before Speaking\n",
      "Quiet-STaR: 言語モデルは話す前に考えることを自己学習できる\n",
      "\n",
      "- STaRでは、少数の例から合理的な考え方を学び、正しい答えに至る過程を学習\n",
      "- Quiet-STaRでは、言語モデルが未来のテキストを説明するためにrationalesを生成することを学習\n",
      "- モデルの予測能力を改善し、難しい質問に直接答える能力を向上させる zero-shot 改善を達成\n",
      "http://arxiv.org/abs/2403.09629v1\n",
      "\n",
      "Video Mamba Suite: State Space Model as a Versatile Alternative for Video Understanding\n",
      "ビデオ理解のための状態空間モデルの汎用的代替手段\n",
      "\n",
      "- Mambaは長いシーケンスモデリングの成功をビデオモデリングに拡張する有望な特性を示す。\n",
      "- 14のモデル/モジュールで構成されたビデオMamba Suiteの提案。\n",
      "- ビデオのみおよびビデオ-言語タスクの両方でMambaの強力なポテンシャルと有望な効率性能トレードオフが明らかにされた。\n",
      "http://arxiv.org/abs/2403.09626v1\n",
      "\n",
      "Physically motivated improvements of Variational Quantum Eigensolvers\n",
      "物理的動機に基づく変分量子固有値ソルバーの改善\n",
      "\n",
      "- ADAPT-VQEの効率向上を図るために、状態の準備を最適化し、回路を浅くする。\n",
      "- 電子構造理論から得た知見を活用して、正確な解に収束を早める。\n",
      "- H4モデルや水分子において、物理的動機に基づく戦略がADAPT-VQEの効率を向上させることを実証。\n",
      "http://arxiv.org/abs/2403.09624v1\n",
      "\n",
      "Score-Guided Diffusion for 3D Human Recovery\n",
      "Score-Guided Diffusion for 3D Human Recovery\n",
      "\n",
      "- 3D人物の姿勢と形状再構築の逆問題を解決するScore-Guided Human Mesh Recovery（ScoreHMR）を提案\n",
      "- 画像観測に人体モデルを適合させる逆問題を最適化技術で解決する代わりに、得点による誘導を用いた拡散モデルの潜在空間で画像観測との整合性を実現\n",
      "- ScoreHMRは最適化ベースラインを常に上回り、異なるアプリケーションで逆問題を効果的に解決可能。\n",
      "http://arxiv.org/abs/2403.09623v1\n",
      "\n",
      "Minimax Optimal and Computationally Efficient Algorithms for Distributionally Robust Offline Reinforcement Learning\n",
      "分布的に堅牢なオフライン強化学習のためのミニマックス最適かつ計算効率的なアルゴリズム\n",
      "\n",
      "- 環境の摂動に対して堅牢なポリシー訓練を実現するため、関数近似が必要。\n",
      "- モデルの不確実性により、関数近似に本質的な非線形性と計算負荷が導入され、独自の課題をもたらす。\n",
      "- 堅牢なオフライン強化学習における関数近似は、通常のオフライン強化学習よりも本質的に異なり、おそらく難しい。\n",
      "http://arxiv.org/abs/2403.09621v1\n",
      "\n",
      "PosSAM: Panoptic Open-vocabulary Segment Anything\n",
      "PosSAM: Panoptic Open-vocabulary Segment Anything\n",
      "\n",
      "- SAMの限界を解消し、クラス情報の認識と過剰セグメンテーションを改善\n",
      "- LDPモジュールを導入し、オープンボキャブラリー分類を提案\n",
      "- MASEアルゴリズムを使用してマスクの品質を向上、性能を向上\n",
      "http://arxiv.org/abs/2403.09620v1\n",
      "\n",
      "Optimistic Verifiable Training by Controlling Hardware Nondeterminism\n",
      "最適化された検証可能なトレーニング方法\n",
      "\n",
      "- ハードウェアの非決定性を制御することで信頼性の高いトレーニングを実現\n",
      "- NVIDIA GPUを使用してFP32精度でResNet-50とGPT-2モデルの正確なトレーニング複製を達成\n",
      "- 証明ベースのシステムに比べてストレージと時間コストを大幅に削減\n",
      "http://arxiv.org/abs/2403.09603v1\n",
      "\n",
      "Network-Controlled Repeater -- An Introduction\n",
      "ネットワーク制御中継器--導入\n",
      "\n",
      "- 5G無線セルラーネットワークでは、ミリ波スペクトルがスループット、信頼性、遅延などの向上をもたらす可能性がある。\n",
      "- ネットワーク制御中継器(NCR)は、ブロッキングの影響を低減し、カバレッジ問題を解決するための手法として注目されている。\n",
      "- 3GPP Rel-18で合意されたNCRの主な仕様を提示し、都市シナリオでのNCR展開を分析し、その性能を比較している。\n",
      "http://arxiv.org/abs/2403.09601v1\n",
      "--------------------------------------------------\n",
      "industry applications\n",
      "\n",
      "3D-VLA: A 3D Vision-Language-Action Generative World Model\n",
      "3D-VLA: 3Dビジョン・言語・アクション生成ワールドモデル\n",
      "\n",
      "- 現在のVLAモデルは2D入力に依存しており、3D物理世界との統合が不足している。\n",
      "- 3D-VLAは3D知覚、推論、アクションをリンクする新しい組み込み基盤モデルを導入する。\n",
      "- 3D-VLAは多大な3D関連情報からなる大規模なデータセットを用いて実験を行い、実世界の応用における潜在能力を示す。\n",
      "http://arxiv.org/abs/2403.09631v1\n",
      "\n",
      "Generalized Predictive Model for Autonomous Driving\n",
      "自動運転向け汎用予測モデル\n",
      "\n",
      "- 大規模ビデオ予測モデルを導入\n",
      "- Webから大量データ取得し、高品質なテキストとペアに\n",
      "- GenADは時空間推論ブロックを持ち、ゼロショットで汎用性を示す\n",
      "http://arxiv.org/abs/2403.09630v1\n",
      "\n",
      "Score-Guided Diffusion for 3D Human Recovery\n",
      "Score-Guided Diffusion for 3D Human Recovery\n",
      "\n",
      "- 3D人体姿勢と形状の逆問題を解決するScoreHMRアプローチ\n",
      "- 潜在空間でスコアガイダンスを使用して画像観測との整合性を達成\n",
      "- 画像からの条件付き分布を捉えた拡散モデルにより、逆問題を解決\n",
      "http://arxiv.org/abs/2403.09623v1\n",
      "\n",
      "Compute-first optical detection for noise-resilient visual perception\n",
      "光学信号処理によるノイズ耐性視覚知覚\n",
      "\n",
      "- ノイズの影響を受けやすい状況において、光学信号処理を検出前に行うことで、視覚知覚タスクの性能向上が可能。\n",
      "- 空間的に光学信号を再配分することで、MNIST分類などの視覚認識タスクの検出ノイズ耐性が向上する。\n",
      "- 実装可能な非コヒーレントイメージングシステムにおいて、信号濃度とノイズ耐性の関係を定量的に分析し、提案手法の有効性を示した。\n",
      "http://arxiv.org/abs/2403.09612v1\n",
      "\n",
      "Signal Recovery with Proximal Comixtures\n",
      "信号回復におけるProximal Comixtures\n",
      "\n",
      "- 損失関数と線形演算子を混合したproximal comixturesの代替フォーミュレーションを提案\n",
      "- 結果関数の近接作用素が明示的に計算可能な操作\n",
      "- 画像回復と機械学習へのcomixtureフォーミュレーションの恩恵\n",
      "http://arxiv.org/abs/2403.09610v1\n",
      "\n",
      "Parafermions with symmetry-protected non-Abelian statistics\n",
      "対称性保護された非アーベル統計を持つパラフェルミオン\n",
      "\n",
      "- 対称性保護された非アーベル統計(SPNAS)の概念を拡張\n",
      "- パラフェルミオン零モード(PZM)を保護する一般的なユニタリー対称性\n",
      "- PZMがSPNASを固有に従うことを厳密に証明\n",
      "http://arxiv.org/abs/2403.09602v1\n",
      "\n",
      "ExploRLLM: Guiding Exploration in Reinforcement Learning with Large Language Models\n",
      "ExploRLLM: Guiding Exploration in Reinforcement Learning with Large Language Models\n",
      "\n",
      "- 大観測・行動空間を持つ画像ベースのロボット操作タスクにおいて、ExploRLLMは大規模な言語モデルの帰納バイアスを活用し、探索を誘導する手法を提案。\n",
      "- 基礎モデルを活用して行動と観測空間を再構成し、強化学習のトレーニング効率を向上させる。\n",
      "- 実験結果では、誘導探索がないトレーニングよりもはるかに迅速な収束を可能にし、ExploRLLMはバニラ基礎モデルよりも優れていることが示された。\n",
      "http://arxiv.org/abs/2403.09583v1\n",
      "\n",
      "Universal Definitions of the Roman Factorial: Introduction to Foundational Functions and the Generalization Process\n",
      "Universal Definitions of the Roman Factorial: Foundational Functions and Generalization\n",
      "\n",
      "- ローマ数字階乗を再定義するための普遍的な適用可能な関数の導入\n",
      "- Boolean演算に類似した基礎関数の使用による階乗表現の簡素化\n",
      "- 汎化プロセスを通じて、再帰的および非再帰的なローマ数字階乗の普遍的な定義を目指す\n",
      "http://arxiv.org/abs/2403.09581v1\n",
      "\n",
      "Algorithmic syntactic causal identification\n",
      "アルゴリズミック構文的因果同定\n",
      "\n",
      "- 現在の因果同定手法が適用できない状況を解決するため、古典的確率論の代わりに対称的単位的圏の公理的基盤を使用する方法を提案。\n",
      "- 一般的な因果同定手法を純粋に構文的に記述するアルゴリズムを提供。\n",
      "- 古典的なバックドアおよびフロントドアの因果調整の構文的類似物を導出し、より複雑な因果モデルへの適用を示す。\n",
      "http://arxiv.org/abs/2403.09580v1\n",
      "\n",
      "Commutation principles for nonsmooth variational problems on Euclidean Jordan algebras\n",
      "Euclidean Jordan代数上の滑らかでない変分問題のための交換原理\n",
      "\n",
      "- Ram\\'irez, Seeger, and Sossaによって証明されたEuclidean Jordan代数の設定における交換原理\n",
      "- $\\Theta$が滑らかでなくても、局所最小化子$a$は$\\Theta$の勾配と交換する\n",
      "- 局所最大化子$a$は$\\Theta$の(Fenchel)部分微分の各要素と交換する\n",
      "http://arxiv.org/abs/2403.09578v1\n",
      "--------------------------------------------------\n",
      "sector-specific adaptations\n",
      "\n",
      "Generalized Predictive Model for Autonomous Driving\n",
      "自動運転のための汎用予測モデル\n",
      "\n",
      "- 自動運転向けの大規模ビデオ予測モデルを紹介\n",
      "- 高コストなデータ収集の制約を取り除き、汎用性を高めるために大規模なWebデータを使用\n",
      "- GenADは他のビデオ予測モデルを上回るゼロショット学習で未知のデータに適用可能\n",
      "http://arxiv.org/abs/2403.09630v1\n",
      "\n",
      "Physically motivated improvements of Variational Quantum Eigensolvers\n",
      "物理的なモチベーションに基づくVariational Quantum Eigensolversの改善\n",
      "\n",
      "- ADAPT-VQEの効果を向上させるために、状態準備の最適化とアンサッツの展開を行う。\n",
      "- 新しい手法により、浅い回路と減少した測定要件を実現する。\n",
      "- H4モデルと水分子における性能評価を通じて、物理的な戦略の有効性が示される。\n",
      "http://arxiv.org/abs/2403.09624v1\n",
      "\n",
      "PosSAM: Panoptic Open-vocabulary Segment Anything\n",
      "PosSAM: Panoptic Open-vocabulary Segment Anything\n",
      "\n",
      "- SAMの空間的なマスク生成に優れつつも、物体クラス情報の認識と過分割の課題を解決\n",
      "- PosSAMはSAMの特徴を活用し、インスタンス認識マスクを生成し、CLIPの特徴を利用して効果的なインスタンス分類を実現\n",
      "- MASEアルゴリズムにより生成されたマスクの品質を向上させ、オープンボキャブラリー分類の性能を高める\n",
      "http://arxiv.org/abs/2403.09620v1\n",
      "\n",
      "pARam: Leveraging Parametric Design in Extended Reality to Support the Personalization of Artifacts for Personal Fabrication\n",
      "pARam: Leveraging Parametric Design in Extended Reality to Support the Personalization of Artifacts for Personal Fabrication\n",
      "\n",
      "- XRを使用したPDとの組み合わせによるPF向けアーティファクトのin-situ設定を可能にするpARam\n",
      "- pARamは複雑な3Dモデリングスキルを要求せず、ジェスチャーや照明推定などの実用的な入力でカスタマイズをサポート\n",
      "- ユーザーは環境を考慮してパラメータを選択し、複雑な設計方法を簡素化しながら適切な表現力を保持可能\n",
      "http://arxiv.org/abs/2403.09607v1\n",
      "\n",
      "Optimistic Verifiable Training by Controlling Hardware Nondeterminism\n",
      "最適なハードウェアの非決定性を制御することによる楽観的検証可能なトレーニング\n",
      "\n",
      "- 訓練プロセスのハードウェアの非決定性を制御するために、高い精度で訓練を行い、中間計算ステップ後に丸めを行う手法を提案。\n",
      "- NVIDIAの異なるGPUでの検証を通じて、FP32精度での正確なトレーニング再現を達成。\n",
      "- 証明ベースのシステムと比較して、ストレージおよび時間コストを大幅に削減する検証可能なトレーニング手法を示した。\n",
      "http://arxiv.org/abs/2403.09603v1\n",
      "\n",
      "Iterative Forgetting: Online Data Stream Regression Using Database-Inspired Adaptive Granulation\n",
      "イテレーティブ・フォーゲッティング: データベースに着想を得た適応的な粗粒度を用いたオンラインデータストリーム回帰\n",
      "\n",
      "- 既存データを用いた粗粒度の作成\n",
      "- 情報が古くなった粒を継続的に忘れる\n",
      "- データと粒を利用して低遅延予測を提供\n",
      "http://arxiv.org/abs/2403.09588v1\n",
      "\n",
      "uaMix-MAE: Efficient Tuning of Pretrained Audio Transformers with Unsupervised Audio Mixtures\n",
      "uaMix-MAE: 教師なしオーディオ混合物で事前学習済みオーディオトランスフォーマーを効率的に調整する方法\n",
      "\n",
      "- 教師なしオーディオ混合物を利用した、効率的なInstance Discrimination(ID)調整戦略の導入\n",
      "- 対象セマンティクスへの適応を助けるために、事前学習済みMAEの表現を整列させるコントラスティブ調整の活用\n",
      "- 少量の教師なしデータでモデルを最適化するためのオーディオ混合技術の提案\n",
      "http://arxiv.org/abs/2403.09579v1\n",
      "\n",
      "Eyes Closed, Safety On: Protecting Multimodal LLMs via Image-to-Text Transformation\n",
      "目を閉じて安全を確保：画像からテキストへの変換を通じたマルチモーダルLLMの保護\n",
      "\n",
      "- MLLMは印象的な推論能力を示すが、画像特徴の導入により、安全メカニズムが迂回されやすくなっている。\n",
      "- ECSOはMLLMの内在的な安全意識を活用し、不安全な画像を適応的にテキストに変換して、安全メカニズムを活性化させる。\n",
      "- ECSOは5つのSoTA MLLMで実験を行い、モデルの安全性を大幅に向上させることが示された。\n",
      "http://arxiv.org/abs/2403.09572v1\n",
      "\n",
      "AdaShield: Safeguarding Multimodal Large Language Models from Structure-based Attack via Adaptive Shield Prompting\n",
      "AdaShield: 構造ベース攻撃からマルチモーダル大規模言語モデルを適応的に守る\n",
      "\n",
      "- MLLMに対する構造ベースジェイルブレイク攻撃に対抗するAdaShieldは、MLLMをFine-tuningや追加モジュールのトレーニングなしで防御する。\n",
      "- 手動設計された静的な防御プロンプトと、適応的な自動修正フレームワークにより、悪意のあるクエリに対する防御が可能。\n",
      "- 実験結果は、AdaShieldがMLLMの堅牢性を向上させ、一般的な能力を損なうことなく、構造ベースの攻撃から保護できることを示している。\n",
      "http://arxiv.org/abs/2403.09513v1\n",
      "\n",
      "SkateFormer: Skeletal-Temporal Transformer for Human Action Recognition\n",
      "SkateFormer: 人間の動作認識のためのスケルトン・テンポラル・トランスフォーマー\n",
      "\n",
      "- スケルトンデータにおけるGCNの受容野制約を解決するためにTransformerを導入\n",
      "- SkateFormerはスケルトン-時間的関係に基づくパーティションとself-attentionを用いた新手法\n",
      "- 4つの異なるスケルトン-時間的関係タイプを組み合わせたアプローチで高い性能を達成\n",
      "http://arxiv.org/abs/2403.09508v1\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import arxiv\n",
    "# デフォルトのAPIクライアントを構築する。\n",
    "arxivclient = arxiv.Client()\n",
    "\n",
    "# 検索条件を指定する。\n",
    "# query: 検索キーワードを指定する。ここでは \"GPT-4\" を指定。\n",
    "# max_results: 取得する論文の最大件数を指定する。ここでは 10 件。\n",
    "# sort_by: 論文の並び替え条件を指定する。ここでは投稿日時の降順（最新順）。\n",
    "\n",
    "# for query in modified_queries:\n",
    "for query in simplified_queries:\n",
    "    print(query)\n",
    "    search = arxiv.Search(\n",
    "        query = query,\n",
    "        max_results = 10,\n",
    "        sort_by = arxiv.SortCriterion.SubmittedDate\n",
    "    )\n",
    "\n",
    "    # 検索を実行し、結果を取得する。\n",
    "    results = arxivclient.results(search)\n",
    "    # 取得した論文のタイトルを1件ずつ表示する。\n",
    "    for r in results:\n",
    "        print(f\"\\n{str(r.title)}\\n{get_summary(r)}\\n{r}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5f0c970-b1a7-431d-b462-8165c13e0667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search String 1: (\"evaluating RAG status\" OR \"RAG evaluation methods\") AND (\"project management\" OR \"project monitoring\")\n",
      "--------------------------------------------------\n",
      "Search String 2: (\"RAG evaluation methods\" OR \"Red Amber Green assessment techniques\") AND (\"industry applications\" OR \"sector-specific adaptations\")\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "generate_search_string\n",
    "\n",
    "\n",
    "# デフォルトのAPIクライアントを構築する。\n",
    "arxivclient = arxiv.Client()\n",
    "\n",
    "# 検索条件を指定する。\n",
    "# query: 検索キーワードを指定する。ここでは \"GPT-4\" を指定。\n",
    "# max_results: 取得する論文の最大件数を指定する。ここでは 10 件。\n",
    "# sort_by: 論文の並び替え条件を指定する。ここでは投稿日時の降順（最新順）。\n",
    "for query in generate_search_string:\n",
    "    print(query)\n",
    "    search = arxiv.Search(\n",
    "        query = query,\n",
    "        max_results = 10,\n",
    "        sort_by = arxiv.SortCriterion.SubmittedDate\n",
    "    )\n",
    "\n",
    "    # 検索を実行し、結果を取得する。\n",
    "    results = arxivclient.results(search)\n",
    "    # 取得した論文のタイトルを1件ずつ表示する。\n",
    "    for r in results:\n",
    "        print(f\"\\n{str(r.title)}\\n{get_summary(r)}\\n{r}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1967aec-5803-4bb2-a8ac-f3941da2b83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = arxiv.Client()\n",
    "# for query in modified_queries:\n",
    "#     search = arxiv.Search(\n",
    "#         query = query,\n",
    "#         max_results = 10,\n",
    "#         sort_by = arxiv.SortCriterion.SubmittedDate\n",
    "#     )\n",
    "\n",
    "#     # 検索を実行し、結果を取得する。\n",
    "#     results = client.results(search)\n",
    "#     # 取得した論文のタイトルを1件ずつ表示する。\n",
    "#     for r in results:\n",
    "#         print(r.title)\n",
    "#         print(r)\n",
    "        \n",
    "#         print(r.summary)\n",
    "#     print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee3a573-d2b3-438f-93da-c2cb66fee615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = arxiv.Search(\n",
    "#         query = \"AI\",\n",
    "#         max_results = 10,\n",
    "#         sort_by = arxiv.SortCriterion.SubmittedDate\n",
    "#     )\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140cbe5a-da0b-4780-9398-0d7204528f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in modified_queries:\n",
    "#     for keyword in k:\n",
    "#         print(f\"Searching for: {keyword}\\n\")\n",
    "#         try:\n",
    "#             results = search_arxiv(str(keyword))\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error searching for keyword '{keyword}': {e}\")\n",
    "#             continue  # 検索中にエラーが発生した場合、次のキーワードの検索に進む\n",
    "\n",
    "#         for result in results:\n",
    "#             try:\n",
    "#                 # summary = get_summary(result)\n",
    "#                 print()\n",
    "#             except KeyboardInterrupt:\n",
    "#                 print(\"KeyboardInterrupt detected, skipping to the next result.\")\n",
    "#                 continue  # KeyboardInterruptが発生した場合、次の論文の処理に進む\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error getting summary for result '{result.title}': {e}\")\n",
    "#                 continue  # その他のエラーが発生した場合、次の論文の処理に進む\n",
    "\n",
    "#             # エラーが発生しなかった場合の処理をここに記述\n",
    "#             print(f\"title: {result.title}\")\n",
    "#             print(f\"published: {result.published}\")\n",
    "#             # print(f\"abstract: {result.summary}\")\n",
    "#             print(f\"PDF link: {result.pdf_url}\")\n",
    "#             # print(f\"summary: {summary}\")\n",
    "#         print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4719f5c2-9614-4b3a-a4e9-d6ec5870e2cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a34f16-86c3-4b14-875a-ae6a9592eb2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07cdf2db-e3de-4806-bd2b-9362eaf36d50",
   "metadata": {},
   "source": [
    "```\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "\n",
    "def get_search_results(keyword, number=5):\n",
    "    # Google Scholarの検索URLを構築\n",
    "    html_doc = requests.get(f\"https://scholar.google.co.jp/scholar?hl=ja&num={number}&q=\" + keyword).text\n",
    "    soup = BeautifulSoup(html_doc, \"html.parser\")  # BeautifulSoupの初期化\n",
    "    \n",
    "    # 必要な情報を抽出\n",
    "    tags_title_url = soup.find_all(\"h3\", {\"class\": \"gs_rt\"})  # タイトル&URL\n",
    "    tags_author_year = soup.find_all(\"div\", {\"class\": \"gs_a\"})  # 著者&年\n",
    "    tags_citations = soup.find_all(\"div\", {\"class\": \"gs_fl\"})  # 引用元リンクが含まれるセクション\n",
    "\n",
    "    for tag_title, tag_author_year, tag_citation in zip(tags_title_url, tags_author_year, tags_citations):\n",
    "        title = tag_title.text.replace(\"[HTML]\", \"\").replace(\"[PDF]\", \"\")\n",
    "        url = tag_title.find('a')['href']\n",
    "        \n",
    "        citation_link = None\n",
    "        for a in tag_citation.find_all('a'):\n",
    "            if \"引用\" in a.text:\n",
    "                citation_link = a['href']\n",
    "                break\n",
    "                \n",
    "        citations = re.search(r'\\d+', a.text) if citation_link else '0'\n",
    "        citations = citations.group(0) if citations else '0'\n",
    "\n",
    "        print(f\"Title: {title}\\nURL: {url}\\nCitations: {citations}\")\n",
    "        \n",
    "        # 引用元リンクがあれば、そのURLを表示（引用元ページからさらに情報を取得する場合に使用）\n",
    "        if citation_link:\n",
    "            print(f\"Citation URL: https://scholar.google.co.jp{citation_link}\")\n",
    "\n",
    "        # 概要の取得はGoogle ScholarのHTML構造に依存するため、概要を直接取得することは推奨されていません。\n",
    "        # 代わりに、論文のURLを訪れて内容を確認してください。\n",
    "        \n",
    "        print(\"--------------------------------------------------\\n\")\n",
    "\n",
    "search_strings = [\n",
    "    '\"Risk Assessment and Governance evaluation methods\"',\n",
    "    '\"Organizations measure success outcomes Risk Assessment Governance initiatives\"'\n",
    "]\n",
    "\n",
    "for keyword in search_strings:\n",
    "    print(f\"Searching for: {keyword}\\n\")\n",
    "    get_search_results(keyword, number=2)\n",
    "\n",
    "# search_strings = [\n",
    "#     '1. \"Risk Assessment and Governance evaluation methods\"',\n",
    "#     '2. \"Organizations measure success outcomes Risk Assessment Governance initiatives\"'\n",
    "# ]\n",
    "\n",
    "\n",
    "for keyword in generate_search_string:\n",
    "    print(f\"Searching for: {keyword}\\n\")\n",
    "    get_search_results(keyword, number=2)\n",
    "\n",
    "\n",
    "\n",
    "def get_title_and_url(soup):\n",
    "    \"\"\"obtain title and url from soup\n",
    "    :param soup: parsed html by BeautifulSoup\n",
    "    :return: title_list, url_list\n",
    "    \"\"\"\n",
    "    tags1 = soup.find_all(\"h3\", {\"class\": \"gs_rt\"})\n",
    "    title_list = []\n",
    "    url_list = []\n",
    "    for tag1 in tags1:\n",
    "        # タイトル取得\n",
    "        # PDF, 書籍, B, HTML, 引用, Cのタグを除去\n",
    "        title = re.sub(r\"\\[(PDF|書籍|B|HTML|引用|C)\\]\", \"\", tag1.text)\n",
    "        # 空白区切りを廃止\n",
    "        title = \"_\".join(title.split(\" \"))\n",
    "        if title[0] == \"_\":\n",
    "            title = title[1:]\n",
    "        title_list.append(title)\n",
    "\n",
    "        # url取得\n",
    "        try:\n",
    "            url = tag1.select(\"a\")[0].get(\"href\")\n",
    "            url_list.append(url)\n",
    "        except IndexError:\n",
    "            url_list.append(None)\n",
    "    return title_list, url_list\n",
    "\n",
    "\n",
    "def get_writer_and_year(soup):\n",
    "    \"\"\"obtain writer(author) and year from soup\n",
    "    :param soup: parsed html by BeautifulSoup\n",
    "    :return: writer_list, year_list\n",
    "    \"\"\"\n",
    "    tags2 = soup.find_all(\"div\", {\"class\": \"gs_a\"})\n",
    "    writer_list = []\n",
    "    year_list = []\n",
    "    for tag2 in tags2:\n",
    "        # 著者取得\n",
    "        \"\"\"\n",
    "        writer = tag2.text\n",
    "        writer = re.sub(r\"\\d\", \"\", writer)\n",
    "        for char in range(0, len(writer)):\n",
    "            if writer[char] == \"-\":\n",
    "                writer = writer[2 : char - 1]\n",
    "                break\n",
    "        \"\"\"\n",
    "        writer = tag2.text.split(\"\\xa0- \")[0]\n",
    "        writer_list.append(writer)\n",
    "\n",
    "        # 論文発行年取得\n",
    "        year = tag2.text\n",
    "        year = re.sub(r\"\\D\", \"\", year)\n",
    "        # yearが5桁以上だった場合の例外処理\n",
    "        if len(year) > 4:\n",
    "            year_list.append(year[len(year) - 4 : len(year)])\n",
    "        else:\n",
    "            year_list.append(year)\n",
    "    return writer_list, year_list\n",
    "\n",
    "\n",
    "def get_citations(soup):\n",
    "    \"\"\"obtain number of citations from soup\n",
    "    :param soup: parsed html by BeautifulSoup\n",
    "    :return: ci_num_list\n",
    "    \"\"\"\n",
    "    tags3 = soup.find_all(text=re.compile(\"引用元\"))\n",
    "    ci_num_list = []\n",
    "    for tag3 in tags3:\n",
    "        # 被引用数取得\n",
    "        citation = tag3.replace(\"引用元\", \"\")\n",
    "        ci_num_list.append(int(citation))\n",
    "    return ci_num_list\n",
    "\n",
    "\n",
    "def get_id(soup):\n",
    "    \"\"\"obtain paper id from soup\n",
    "    :param soup: parsed html by BeautifulSoup\n",
    "    :return: ci_num_list\n",
    "    \"\"\"\n",
    "    tags4 = soup.find_all(\"div\", {\"class\": \"gs_fl\"})\n",
    "    p_id_list = []\n",
    "    for tag4 in tags4:\n",
    "        # 論文ID取得\n",
    "        try:\n",
    "            elem = tag4.find_all(\"a\")[2][\"href\"]\n",
    "            a = 15\n",
    "            while True:\n",
    "                if elem[a] == \"&\":\n",
    "                    break\n",
    "                a += 1\n",
    "            p_id_list.append(elem[15:a])\n",
    "        except:\n",
    "            print(\"\")\n",
    "    return p_id_list\n",
    "\n",
    "def year_list_to_cite_years(year_list,p_year):\n",
    "    \"\"\"convert year_list into cite_years\n",
    "    :param year_list,p_year:\n",
    "    :return: cite_years\n",
    "    \"\"\"\n",
    "    year_list_int = []\n",
    "    for s in year_list:\n",
    "        try:\n",
    "            year_list_int.append(int(s))\n",
    "        except:\n",
    "            pass\n",
    "    y = [p_year+i for i in range(2021 - p_year + 1)]\n",
    "    cite_years = [0 for _ in range(2021 - p_year + 1)]\n",
    "    for year in year_list_int:\n",
    "        if year >= p_year and year <= 2021:\n",
    "            cite_years[year - p_year] += 1\n",
    "    list_return = [y, cite_years]\n",
    "#    cite_years = pd.DataFrame(cite_years,\n",
    "#                       index=y,\n",
    "#                       columns=['total'])\n",
    "#    cite_years  = cite_years.T\n",
    "    return list_return\n",
    "\n",
    "\n",
    "\n",
    "def make_url(keyword, conf, author, year, paper_id=None):\n",
    "    \"\"\"make url for search papers\n",
    "    normal search (keyword, conf, author, year) or target search (paper_id)\n",
    "    :param keyword: str or None\n",
    "    :param conf: str or None, conference information\n",
    "    :param author: str or None, author information\n",
    "    :param year: int or None, published year\n",
    "    :param paper_id: None or int, paper information\n",
    "    :return: url\n",
    "    \"\"\"\n",
    "    assert (\n",
    "        keyword is not None\n",
    "        or conf is not None\n",
    "        or author is not None\n",
    "        or year is not None\n",
    "        or paper_id is not None\n",
    "    ), \"KeywordNotFoundError\"\n",
    "    url = \"https://scholar.google.co.jp/scholar?\"\n",
    "    if paper_id is not None:\n",
    "        url += f\"&cites={paper_id}\"\n",
    "    else:\n",
    "        url += \"&as_sdt=0%2C5\"\n",
    "        if keyword is not None:\n",
    "            url += f\"&as_q={'%20'.join(keyword.split())}\"\n",
    "        else:\n",
    "            url += \"&as_q=\"\n",
    "        if conf is not None:\n",
    "            url += f\"&as_publication={'%20'.join(conf.split())}\"\n",
    "        if author is not None:\n",
    "            author = \"+\".join(author.split())\n",
    "            url += f\"&as_sauthors={'%20'.join(author.split())}\"\n",
    "        if year is not None:\n",
    "            url += f\"&as_ylo={year}\"\n",
    "    return url\n",
    "\n",
    "\n",
    "\n",
    "def get_snippet(soup):\n",
    "    \"\"\"obtain snippet from soup\n",
    "    :param soup: parsed html by BeautifulSoup\n",
    "    :return: snippet_list\n",
    "    \"\"\"\n",
    "    tags = soup.find_all(\"div\", {\"class\": \"gs_rs\"})\n",
    "    snippet_list = [tags[i].text for i in range(len(tags))]\n",
    "    return snippet_list\n",
    "\n",
    "\n",
    "def grep_candidate_papers(url):\n",
    "    html_doc = requests.get(url).text\n",
    "    soup = BeautifulSoup(html_doc, \"html.parser\")\n",
    "\n",
    "    title_list, url_list = get_title_and_url(soup)\n",
    "    writer_list, year_list = get_writer_and_year(soup)\n",
    "    ci_num_list = get_citations(soup)\n",
    "    p_id_list = get_id(soup)\n",
    "    snippet_list = get_snippet(soup)\n",
    "\n",
    "    for i in range(len(title_list)):\n",
    "        print(\"-\" * 20)\n",
    "        print(f\"paper number: {i}\")\n",
    "        print(f\"paper title: {title_list[i]}\")\n",
    "        print(f\"published year: {year_list[i]}\")\n",
    "        print(f\"citations: {ci_num_list[i]}\")\n",
    "\n",
    "    print(f\"\\nSelect a paper number between 0 and {len(title_list)-1}\")\n",
    "    while True:\n",
    "        try:\n",
    "            target_paper_num = int(input(\"Select paper number: \"))\n",
    "            if 0 <= target_paper_num < len(title_list):\n",
    "                break\n",
    "            else:\n",
    "                print(f\"Please enter a number between 0 and {len(title_list)-1}.\")\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter a valid number.\")\n",
    "    \n",
    "    target_paper = {\n",
    "        \"title\": title_list[target_paper_num],\n",
    "        \"writer\": writer_list[target_paper_num],\n",
    "        \"year\": year_list[target_paper_num],\n",
    "        \"citations\": ci_num_list[target_paper_num],\n",
    "        \"url\": url_list[target_paper_num],\n",
    "        \"paper_id\": p_id_list[target_paper_num],\n",
    "        \"snippet\": snippet_list[target_paper_num],\n",
    "    }\n",
    "    return target_paper\n",
    "\n",
    "\n",
    "\n",
    "def scraping_papers(url):\n",
    "    \"\"\"scrape 100 papers\n",
    "    :param url: target url\n",
    "    :return: title_list, url_list, writer_list, year_list, ci_num_list, p_id_list, snippet_list\n",
    "    \"\"\"\n",
    "    url_each = url.split(\"&\")\n",
    "    url_each[0] = url_each[0] + \"start={}\"\n",
    "    url_base = \"&\".join(url_each)\n",
    "\n",
    "    title_list = []\n",
    "    url_list = []\n",
    "    writer_list = []\n",
    "    year_list = []\n",
    "    ci_num_list = []\n",
    "    p_id_list = []\n",
    "    snippet_list = []\n",
    "\n",
    "    for page in range(0, 100, 10):\n",
    "        print(\"Loading next {} results\".format(page + 10))\n",
    "        url_tmp = url_base.format(page)\n",
    "        html_doc = requests.get(url_tmp).text\n",
    "        soup = BeautifulSoup(html_doc, \"html.parser\")\n",
    "\n",
    "        title_list_tmp, url_list_tmp = get_title_and_url(soup)\n",
    "        writer_list_tmp, year_list_tmp = get_writer_and_year(soup)\n",
    "        ci_num_list_tmp = get_citations(soup)\n",
    "        p_id_list_tmp = get_id(soup)\n",
    "        snippet_list_tmp = get_snippet(soup)\n",
    "\n",
    "        title_list.extend(title_list_tmp)\n",
    "        url_list.extend(url_list_tmp)\n",
    "        writer_list.extend(writer_list_tmp)\n",
    "        year_list.extend(year_list_tmp)\n",
    "        ci_num_list.extend(ci_num_list_tmp)\n",
    "        p_id_list.extend(p_id_list_tmp)\n",
    "        snippet_list.extend(snippet_list_tmp)\n",
    "\n",
    "        sleep(np.random.randint(5, 10))\n",
    "    return (\n",
    "        title_list,\n",
    "        url_list,\n",
    "        writer_list,\n",
    "        year_list,\n",
    "        ci_num_list,\n",
    "        p_id_list,\n",
    "        snippet_list,\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e48ecb-4d93-4d6c-ad72-3bd795643fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_paper_relevance_and_keywords(title, search_string, client):\n",
    "    # Adjust the prompt to ask for relevance and keywords\n",
    "    prompt = (f\"Determine if the paper titled '{title}' is relevant to the topic '{search_string}'. \"\n",
    "              \"and in return just informed paper is relevant or paper is not relevant, to the point.\")\n",
    "\n",
    "    data = {\n",
    "        \"model\": \"gpt-3.5-turbo\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a knowledgeable assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    }\n",
    "    response = client.chat.completions.create(\n",
    "        # model=\"gpt-3.5-turbo\",\n",
    "        model=\"gpt-3.5-turbo-0125\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a knowledgeable assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        # response_format={ \"type\": \"json_object\" },\n",
    "        temperature=TEMPERATURE,\n",
    "    )\n",
    "    content = response.choices[0].message.content.strip().lower()\n",
    "    \n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62df350-3d1c-4395-a823-aa94ad2413aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b625d6fa-22bb-4c62-913d-1c67c67a7a09",
   "metadata": {},
   "source": [
    "```\n",
    "# キーワードの入力\n",
    "search_strings = [\n",
    "    '\"Risk Assessment and Governance evaluation methods\"',\n",
    "    '\"Organizations measure success outcomes Risk Assessment Governance initiatives\"'\n",
    "]\n",
    "\n",
    "for keyword in search_strings:\n",
    "    print(f\"Searching for: {keyword}\\n\")\n",
    "    \n",
    "    # 検索用URLの作成\n",
    "    url = make_url(keyword=keyword, conf=None, author=None, year=None)\n",
    "    \n",
    "    # 候補となる論文の選択\n",
    "    print(\"Please select a paper\")\n",
    "    selected_paper = grep_candidate_papers(url)\n",
    "    \n",
    "    # 選択された論文の情報を表示\n",
    "    print(f\"Selected Paper: {selected_paper['title']}\")\n",
    "    print(f\"URL: {selected_paper['url']}\")\n",
    "    print(f\"Citations: {selected_paper['citations']}\")\n",
    "    print(f\"Snippet: {selected_paper['snippet']}\\n\")\n",
    "    \n",
    "    # 選択された論文の引用論文情報の取得\n",
    "    url_cite = make_url(paper_id=selected_paper[\"paper_id\"])\n",
    "    cited_papers_info = scraping_papers(url_cite)\n",
    "    \n",
    "    # 引用論文情報の表示 (例: タイトルとURL)\n",
    "    for title, url in zip(cited_papers_info[0], cited_papers_info[1]):\n",
    "        print(f\"Cited Paper Title: {title}\")\n",
    "        print(f\"Cited Paper URL: {url}\\n\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae41662-74b9-4669-83a9-a220c783eddd",
   "metadata": {},
   "source": [
    "```\n",
    "# 検索パラメータを設定\n",
    "# N_DAYS = 365  # 過去30日間の論文を検索\n",
    "N_DAYS = 30  # 過去30日間の論文を検索\n",
    "\n",
    "MAX_RESULT = 5  # 最大結果数\n",
    "QUERY_TEMPLATE = 'all:{} AND submittedDate:[{} TO {}]'  # 検索クエリテンプレート\n",
    "\n",
    "# 検索を行い、結果を取得する関数\n",
    "def search_arxiv_with_keywords(keywords):\n",
    "    client = arxiv.Client()\n",
    "    results_list = []\n",
    "\n",
    "    today = dt.datetime.today() - dt.timedelta(days=2)\n",
    "    base_date = today - dt.timedelta(days=N_DAYS)\n",
    "\n",
    "    for keyword in keywords:\n",
    "        query = QUERY_TEMPLATE.format(keyword, base_date.strftime(\"%Y-%m-%d\"), today.strftime(\"%Y-%m-%d\"))\n",
    "        \n",
    "        search = arxiv.Search(\n",
    "            query=query,\n",
    "            max_results=MAX_RESULT,\n",
    "            sort_by=arxiv.SortCriterion.SubmittedDate,\n",
    "            sort_order=arxiv.SortOrder.Descending,\n",
    "        )\n",
    "\n",
    "        results = client.results(search)\n",
    "        \n",
    "        for result in results:\n",
    "            # 特定の条件に基づいてフィルタリングを行う場合はここに追加\n",
    "            results_list.append({\n",
    "                'title': result.title,\n",
    "                'summary': result.summary,\n",
    "                'url': result.entry_id  # arXivへのリンク\n",
    "            })\n",
    "\n",
    "    return results_list\n",
    "\n",
    "search_results = search_arxiv_with_keywords(generate_search_string)\n",
    "for result in search_results:\n",
    "    print(f\"Title: {result['title']}\\nSummary: {result['summary']}\\nURL: {result['url']}\\n\")\n",
    "\n",
    "# うまくいかないのでクエリを小さくする(本ちゃんではこれ使いたくねーな)\n",
    "\n",
    "import re\n",
    "\n",
    "def simplify_search_queries(complex_queries):\n",
    "    simplified_queries = []\n",
    "\n",
    "    for query in complex_queries:\n",
    "        # 数字とピリオドを除去して、クエリの本体だけを抽出\n",
    "        clean_query = re.sub(r'^\\d+\\.\\s*', '', query)\n",
    "        \n",
    "        # 括弧を除去\n",
    "        clean_query = re.sub(r'[()\"]', '', clean_query)\n",
    "        \n",
    "        # 'AND' と 'OR' で分割\n",
    "        split_queries = re.split(r'\\sAND\\s|\\sOR\\s', clean_query)\n",
    "        \n",
    "        # 分割したクエリをリストに追加\n",
    "        for sub_query in split_queries:\n",
    "            sub_query = sub_query.strip()\n",
    "            if sub_query and sub_query not in simplified_queries:\n",
    "                simplified_queries.append(sub_query)\n",
    "                \n",
    "    return simplified_queries\n",
    "\n",
    "\n",
    "simplified_queries = simplify_search_queries(generate_search_string)\n",
    "for query in simplified_queries:\n",
    "    print(query)\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# for query in tqdm(simplified_queries, desc=\"Searching\"):\n",
    "#     print(f\"Query: {query}\")\n",
    "#     search_results = search_arxiv_with_keywords(query)\n",
    "#     for result in search_results:\n",
    "#         print(f\"Title: {result['title']}\\nSummary: {result['summary']}\\nURL: {result['url']}\\n\")\n",
    "#     time.sleep(2)  # 検索ごとに2秒間待機します。\n",
    "\n",
    "\n",
    "\n",
    "from duckduckgo_search import DDGS\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# テキスト検索用の関数\n",
    "def search_text(keywords, region='wt-wt', safesearch='moderate', timelimit=None, max_results=3):\n",
    "    with DDGS() as ddgs:\n",
    "        results = [r for r in ddgs.text(keywords, region=region, safesearch=safesearch, timelimit=timelimit, max_results=max_results)]\n",
    "        time.sleep(2)\n",
    "    return results\n",
    "\n",
    "# BeautifulSoupを使ってウェブページから情報を抽出する関数\n",
    "def extract_info_from_url(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # 必要な情報を抽出するためのコードをここに追加します。\n",
    "        # 例えば、ページの全ての段落テキストを取得する場合:\n",
    "        paragraphs = soup.find_all('p')\n",
    "        text = ' '.join([p.text for p in paragraphs])\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting information from {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for query in tqdm(simplified_queries, desc=\"Searching\"):\n",
    "    print(query)\n",
    "    text_results = search_text(query)\n",
    "    print(text_results)\n",
    "    for result in text_results:\n",
    "        print(f\"Title: {result['title']}\\nURL: {result['href']}\\n\")\n",
    "        # # URLから情報を抽出\n",
    "        # extracted_info = extract_info_from_url(result['href'])\n",
    "        # print(f\"Extracted Info: {extracted_info}\\n\")\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from duckduckgo_search import DDGS  # あるいは適切なモジュール名\n",
    "\n",
    "# テキスト検索用の関数\n",
    "def search_text(keywords, max_results=3):\n",
    "    with DDGS() as ddgs:\n",
    "        results = [r for r in ddgs.text(keywords, max_results=max_results)]\n",
    "        time.sleep(2)  # 検索ごとに2秒間待機\n",
    "    return results\n",
    "\n",
    "# 検索クエリを簡略化する関数\n",
    "def simplify_search_queries(complex_queries):\n",
    "    simplified_queries = []\n",
    "    # (クエリを簡略化するロジック)\n",
    "    return simplified_queries\n",
    "\n",
    "# 複雑なクエリのリスト\n",
    "complex_queries = [\n",
    "    '1. (\"RAG evaluation methods\" OR \"risk assurance governance evaluation methods\") AND (\"accuracy\" AND \"efficiency\")',\n",
    "    '2. (\"RAG evaluation methods\" OR \"risk assurance governance evaluation methods\") AND (\"factors influencing\" AND \"development\" AND \"implementation\")'\n",
    "]\n",
    "\n",
    "# 簡略化されたクエリのリストを取得\n",
    "simplified_queries = simplify_search_queries(complex_queries)\n",
    "\n",
    "# tqdmを使用して進捗状況を表示しながら検索を実行\n",
    "for query in tqdm(simplified_queries, desc=\"Searching\"):\n",
    "    print(f\"Query: {query}\")\n",
    "    search_results = search_text(query)\n",
    "    for result in search_results:\n",
    "        print(f\"Title: {result['title']}\\nSummary: {result['summary']}\\nURL: {result['url']}\\n\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d49a713-1479-4854-aa1a-b5d37b751acf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
